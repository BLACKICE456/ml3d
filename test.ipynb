{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCP Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import gc\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "import sys\n",
    "sys.path.append(\"dcp-master\")\n",
    "# from data import ModelNet40\n",
    "from model import DCP\n",
    "from util import transform_point_cloud, npmat2euler, quat2mat\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Part of the code is referred from: https://github.com/floodsung/LearningToCompare_FSL\n",
    "\n",
    "class IOStream:\n",
    "    def __init__(self, path):\n",
    "        self.f = open(path, 'a')\n",
    "\n",
    "    def cprint(self, text):\n",
    "        print(text)\n",
    "        self.f.write(text + '\\n')\n",
    "        self.f.flush()\n",
    "\n",
    "    def close(self):\n",
    "        self.f.close()\n",
    "\n",
    "\n",
    "def _init_(args):\n",
    "    if not os.path.exists('checkpoints'):\n",
    "        os.makedirs('checkpoints')\n",
    "    if not os.path.exists('checkpoints/' + args.exp_name):\n",
    "        os.makedirs('checkpoints/' + args.exp_name)\n",
    "    if not os.path.exists('checkpoints/' + args.exp_name + '/' + 'models'):\n",
    "        os.makedirs('checkpoints/' + args.exp_name + '/' + 'models')\n",
    "    os.system('cp main.py checkpoints' + '/' + args.exp_name + '/' + 'main.py.backup')\n",
    "    os.system('cp model.py checkpoints' + '/' + args.exp_name + '/' + 'model.py.backup')\n",
    "    os.system('cp data.py checkpoints' + '/' + args.exp_name + '/' + 'data.py.backup')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(args, net, train_loader, opt):\n",
    "    net.train()\n",
    "\n",
    "    mse_ab = 0\n",
    "    mae_ab = 0\n",
    "    mse_ba = 0\n",
    "    mae_ba = 0\n",
    "\n",
    "    total_loss = 0\n",
    "    total_cycle_loss = 0\n",
    "    num_examples = 0\n",
    "    rotations_ab = []\n",
    "    translations_ab = []\n",
    "    rotations_ab_pred = []\n",
    "    translations_ab_pred = []\n",
    "\n",
    "    rotations_ba = []\n",
    "    translations_ba = []\n",
    "    rotations_ba_pred = []\n",
    "    translations_ba_pred = []\n",
    "\n",
    "    eulers_ab = []\n",
    "    eulers_ba = []\n",
    "\n",
    "    net = net.cuda()\n",
    "\n",
    "    for src, target, rotation_ab, translation_ab, rotation_ba, translation_ba, euler_ab, euler_ba, _ in train_loader:\n",
    "        # src = torch.tensor(src)\n",
    "        # target = torch.tensor(target)\n",
    "        src = src.cuda()\n",
    "        target = target.cuda()\n",
    "        rotation_ab = rotation_ab.cuda()\n",
    "        translation_ab = translation_ab.cuda()\n",
    "        rotation_ba = rotation_ba.cuda()\n",
    "        translation_ba = translation_ba.cuda()\n",
    "\n",
    "        batch_size = src.size(0)\n",
    "        opt.zero_grad()\n",
    "        num_examples += batch_size\n",
    "        rotation_ab_pred, translation_ab_pred, rotation_ba_pred, translation_ba_pred = net(src, target)\n",
    "\n",
    "        ## save rotation and translation\n",
    "        rotations_ab.append(rotation_ab.detach().cpu().numpy())\n",
    "        translations_ab.append(translation_ab.detach().cpu().numpy())\n",
    "        rotations_ab_pred.append(rotation_ab_pred.detach().cpu().numpy())\n",
    "        translations_ab_pred.append(translation_ab_pred.detach().cpu().numpy())\n",
    "        eulers_ab.append(euler_ab.numpy())\n",
    "        ##\n",
    "        rotations_ba.append(rotation_ba.detach().cpu().numpy())\n",
    "        translations_ba.append(translation_ba.detach().cpu().numpy())\n",
    "        rotations_ba_pred.append(rotation_ba_pred.detach().cpu().numpy())\n",
    "        translations_ba_pred.append(translation_ba_pred.detach().cpu().numpy())\n",
    "        eulers_ba.append(euler_ba.numpy())\n",
    "\n",
    "        transformed_src = transform_point_cloud(src, rotation_ab_pred, translation_ab_pred)\n",
    "\n",
    "        transformed_target = transform_point_cloud(target, rotation_ba_pred, translation_ba_pred)\n",
    "        ###########################\n",
    "        identity = torch.eye(3).cuda().unsqueeze(0).repeat(batch_size, 1, 1)\n",
    "        loss = F.mse_loss(torch.matmul(rotation_ab_pred.transpose(2, 1), rotation_ab), identity) \\\n",
    "               + F.mse_loss(translation_ab_pred, translation_ab)\n",
    "        if args['cycle']:\n",
    "            rotation_loss = F.mse_loss(torch.matmul(rotation_ba_pred, rotation_ab_pred), identity.clone())\n",
    "            translation_loss = torch.mean((torch.matmul(rotation_ba_pred.transpose(2, 1),\n",
    "                                                        translation_ab_pred.view(batch_size, 3, 1)).view(batch_size, 3)\n",
    "                                           + translation_ba_pred) ** 2, dim=[0, 1])\n",
    "            cycle_loss = rotation_loss + translation_loss\n",
    "\n",
    "            loss = loss + cycle_loss * 0.1\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total_loss += loss.item() * batch_size\n",
    "\n",
    "        if args['cycle']:\n",
    "            total_cycle_loss = total_cycle_loss + cycle_loss.item() * 0.1 * batch_size\n",
    "\n",
    "        mse_ab += torch.mean((transformed_src - target) ** 2, dim=[0, 1, 2]).item() * batch_size\n",
    "        mae_ab += torch.mean(torch.abs(transformed_src - target), dim=[0, 1, 2]).item() * batch_size\n",
    "\n",
    "        mse_ba += torch.mean((transformed_target - src) ** 2, dim=[0, 1, 2]).item() * batch_size\n",
    "        mae_ba += torch.mean(torch.abs(transformed_target - src), dim=[0, 1, 2]).item() * batch_size\n",
    "\n",
    "    rotations_ab = np.concatenate(rotations_ab, axis=0)\n",
    "    translations_ab = np.concatenate(translations_ab, axis=0)\n",
    "    rotations_ab_pred = np.concatenate(rotations_ab_pred, axis=0)\n",
    "    translations_ab_pred = np.concatenate(translations_ab_pred, axis=0)\n",
    "\n",
    "    rotations_ba = np.concatenate(rotations_ba, axis=0)\n",
    "    translations_ba = np.concatenate(translations_ba, axis=0)\n",
    "    rotations_ba_pred = np.concatenate(rotations_ba_pred, axis=0)\n",
    "    translations_ba_pred = np.concatenate(translations_ba_pred, axis=0)\n",
    "\n",
    "    eulers_ab = np.concatenate(eulers_ab, axis=0)\n",
    "    eulers_ba = np.concatenate(eulers_ba, axis=0)\n",
    "\n",
    "    return total_loss * 1.0 / num_examples, total_cycle_loss / num_examples, \\\n",
    "           mse_ab * 1.0 / num_examples, mae_ab * 1.0 / num_examples, \\\n",
    "           mse_ba * 1.0 / num_examples, mae_ba * 1.0 / num_examples, rotations_ab, \\\n",
    "           translations_ab, rotations_ab_pred, translations_ab_pred, rotations_ba, \\\n",
    "           translations_ba, rotations_ba_pred, translations_ba_pred, eulers_ab, eulers_ba\n",
    "\n",
    "def train(args, net, train_loader, test_loader, boardio, textio):\n",
    "    if args['use_sgd']:\n",
    "        print(\"Use SGD\")\n",
    "        opt = optim.SGD(net.parameters(), lr=args['lr'] * 100, momentum=args.momentum, weight_decay=1e-4)\n",
    "    else:\n",
    "        print(\"Use Adam\")\n",
    "        opt = optim.Adam(net.parameters(), lr=args['lr'], weight_decay=1e-4)\n",
    "    scheduler = MultiStepLR(opt, milestones=[75, 150, 200], gamma=0.1)\n",
    "\n",
    "\n",
    "    best_test_loss = np.inf\n",
    "    best_test_cycle_loss = np.inf\n",
    "    best_test_mse_ab = np.inf\n",
    "    best_test_rmse_ab = np.inf\n",
    "    best_test_mae_ab = np.inf\n",
    "\n",
    "    best_test_r_mse_ab = np.inf\n",
    "    best_test_r_rmse_ab = np.inf\n",
    "    best_test_r_mae_ab = np.inf\n",
    "    best_test_t_mse_ab = np.inf\n",
    "    best_test_t_rmse_ab = np.inf\n",
    "    best_test_t_mae_ab = np.inf\n",
    "\n",
    "    best_test_mse_ba = np.inf\n",
    "    best_test_rmse_ba = np.inf\n",
    "    best_test_mae_ba = np.inf\n",
    "\n",
    "    best_test_r_mse_ba = np.inf\n",
    "    best_test_r_rmse_ba = np.inf\n",
    "    best_test_r_mae_ba = np.inf\n",
    "    best_test_t_mse_ba = np.inf\n",
    "    best_test_t_rmse_ba = np.inf\n",
    "    best_test_t_mae_ba = np.inf\n",
    "\n",
    "    for epoch in tqdm(range(args['epochs'])):\n",
    "        scheduler.step()\n",
    "        train_loss, train_cycle_loss, \\\n",
    "        train_mse_ab, train_mae_ab, train_mse_ba, train_mae_ba, train_rotations_ab, train_translations_ab, \\\n",
    "        train_rotations_ab_pred, \\\n",
    "        train_translations_ab_pred, train_rotations_ba, train_translations_ba, train_rotations_ba_pred, \\\n",
    "        train_translations_ba_pred, train_eulers_ab, train_eulers_ba = train_one_epoch(args, net, train_loader, opt)\n",
    "        test_loss, test_cycle_loss, \\\n",
    "        test_mse_ab, test_mae_ab, test_mse_ba, test_mae_ba, test_rotations_ab, test_translations_ab, \\\n",
    "        test_rotations_ab_pred, \\\n",
    "        test_translations_ab_pred, test_rotations_ba, test_translations_ba, test_rotations_ba_pred, \\\n",
    "        test_translations_ba_pred, test_eulers_ab, test_eulers_ba = test_one_epoch(args, net, test_loader)\n",
    "        train_rmse_ab = np.sqrt(train_mse_ab)\n",
    "        test_rmse_ab = np.sqrt(test_mse_ab)\n",
    "\n",
    "        train_rmse_ba = np.sqrt(train_mse_ba)\n",
    "        test_rmse_ba = np.sqrt(test_mse_ba)\n",
    "\n",
    "        train_rotations_ab_pred_euler = npmat2euler(train_rotations_ab_pred)\n",
    "        train_r_mse_ab = np.mean((train_rotations_ab_pred_euler - np.degrees(train_eulers_ab)) ** 2)\n",
    "        train_r_rmse_ab = np.sqrt(train_r_mse_ab)\n",
    "        train_r_mae_ab = np.mean(np.abs(train_rotations_ab_pred_euler - np.degrees(train_eulers_ab)))\n",
    "        train_t_mse_ab = np.mean((train_translations_ab - train_translations_ab_pred) ** 2)\n",
    "        train_t_rmse_ab = np.sqrt(train_t_mse_ab)\n",
    "        train_t_mae_ab = np.mean(np.abs(train_translations_ab - train_translations_ab_pred))\n",
    "\n",
    "        train_rotations_ba_pred_euler = npmat2euler(train_rotations_ba_pred, 'xyz')\n",
    "        train_r_mse_ba = np.mean((train_rotations_ba_pred_euler - np.degrees(train_eulers_ba)) ** 2)\n",
    "        train_r_rmse_ba = np.sqrt(train_r_mse_ba)\n",
    "        train_r_mae_ba = np.mean(np.abs(train_rotations_ba_pred_euler - np.degrees(train_eulers_ba)))\n",
    "        train_t_mse_ba = np.mean((train_translations_ba - train_translations_ba_pred) ** 2)\n",
    "        train_t_rmse_ba = np.sqrt(train_t_mse_ba)\n",
    "        train_t_mae_ba = np.mean(np.abs(train_translations_ba - train_translations_ba_pred))\n",
    "\n",
    "        test_rotations_ab_pred_euler = npmat2euler(test_rotations_ab_pred)\n",
    "        test_r_mse_ab = np.mean((test_rotations_ab_pred_euler - np.degrees(test_eulers_ab)) ** 2)\n",
    "        test_r_rmse_ab = np.sqrt(test_r_mse_ab)\n",
    "        test_r_mae_ab = np.mean(np.abs(test_rotations_ab_pred_euler - np.degrees(test_eulers_ab)))\n",
    "        test_t_mse_ab = np.mean((test_translations_ab - test_translations_ab_pred) ** 2)\n",
    "        test_t_rmse_ab = np.sqrt(test_t_mse_ab)\n",
    "        test_t_mae_ab = np.mean(np.abs(test_translations_ab - test_translations_ab_pred))\n",
    "\n",
    "        test_rotations_ba_pred_euler = npmat2euler(test_rotations_ba_pred, 'xyz')\n",
    "        test_r_mse_ba = np.mean((test_rotations_ba_pred_euler - np.degrees(test_eulers_ba)) ** 2)\n",
    "        test_r_rmse_ba = np.sqrt(test_r_mse_ba)\n",
    "        test_r_mae_ba = np.mean(np.abs(test_rotations_ba_pred_euler - np.degrees(test_eulers_ba)))\n",
    "        test_t_mse_ba = np.mean((test_translations_ba - test_translations_ba_pred) ** 2)\n",
    "        test_t_rmse_ba = np.sqrt(test_t_mse_ba)\n",
    "        test_t_mae_ba = np.mean(np.abs(test_translations_ba - test_translations_ba_pred))\n",
    "\n",
    "        if best_test_loss >= test_loss:\n",
    "            best_test_loss = test_loss\n",
    "            best_test_cycle_loss = test_cycle_loss\n",
    "\n",
    "            best_test_mse_ab = test_mse_ab\n",
    "            best_test_rmse_ab = test_rmse_ab\n",
    "            best_test_mae_ab = test_mae_ab\n",
    "\n",
    "            best_test_r_mse_ab = test_r_mse_ab\n",
    "            best_test_r_rmse_ab = test_r_rmse_ab\n",
    "            best_test_r_mae_ab = test_r_mae_ab\n",
    "\n",
    "            best_test_t_mse_ab = test_t_mse_ab\n",
    "            best_test_t_rmse_ab = test_t_rmse_ab\n",
    "            best_test_t_mae_ab = test_t_mae_ab\n",
    "\n",
    "            best_test_mse_ba = test_mse_ba\n",
    "            best_test_rmse_ba = test_rmse_ba\n",
    "            best_test_mae_ba = test_mae_ba\n",
    "\n",
    "            best_test_r_mse_ba = test_r_mse_ba\n",
    "            best_test_r_rmse_ba = test_r_rmse_ba\n",
    "            best_test_r_mae_ba = test_r_mae_ba\n",
    "\n",
    "            best_test_t_mse_ba = test_t_mse_ba\n",
    "            best_test_t_rmse_ba = test_t_rmse_ba\n",
    "            best_test_t_mae_ba = test_t_mae_ba\n",
    "\n",
    "            if torch.cuda.device_count() > 1:\n",
    "                torch.save(net.module.state_dict(), 'checkpoints/%s/models/model.best.t7' % args['exp_name'])\n",
    "            else:\n",
    "                torch.save(net.state_dict(), 'checkpoints/%s/models/model.best.t7' % args['exp_name'])\n",
    "\n",
    "        # textio.cprint('==TRAIN==')\n",
    "        # textio.cprint('A--------->B')\n",
    "        # textio.cprint('EPOCH:: %d, Loss: %f, Cycle Loss:, %f, MSE: %f, RMSE: %f, MAE: %f, rot_MSE: %f, rot_RMSE: %f, '\n",
    "        #               'rot_MAE: %f, trans_MSE: %f, trans_RMSE: %f, trans_MAE: %f'\n",
    "        #               % (epoch, train_loss, train_cycle_loss, train_mse_ab, train_rmse_ab, train_mae_ab, train_r_mse_ab,\n",
    "        #                  train_r_rmse_ab, train_r_mae_ab, train_t_mse_ab, train_t_rmse_ab, train_t_mae_ab))\n",
    "        # textio.cprint('B--------->A')\n",
    "        # textio.cprint('EPOCH:: %d, Loss: %f, MSE: %f, RMSE: %f, MAE: %f, rot_MSE: %f, rot_RMSE: %f, '\n",
    "        #               'rot_MAE: %f, trans_MSE: %f, trans_RMSE: %f, trans_MAE: %f'\n",
    "        #               % (epoch, train_loss, train_mse_ba, train_rmse_ba, train_mae_ba, train_r_mse_ba, train_r_rmse_ba,\n",
    "        #                  train_r_mae_ba, train_t_mse_ba, train_t_rmse_ba, train_t_mae_ba))\n",
    "\n",
    "        # textio.cprint('==TEST==')\n",
    "        # textio.cprint('A--------->B')\n",
    "        # textio.cprint('EPOCH:: %d, Loss: %f, Cycle Loss: %f, MSE: %f, RMSE: %f, MAE: %f, rot_MSE: %f, rot_RMSE: %f, '\n",
    "        #               'rot_MAE: %f, trans_MSE: %f, trans_RMSE: %f, trans_MAE: %f'\n",
    "        #               % (epoch, test_loss, test_cycle_loss, test_mse_ab, test_rmse_ab, test_mae_ab, test_r_mse_ab,\n",
    "        #                  test_r_rmse_ab, test_r_mae_ab, test_t_mse_ab, test_t_rmse_ab, test_t_mae_ab))\n",
    "        # textio.cprint('B--------->A')\n",
    "        # textio.cprint('EPOCH:: %d, Loss: %f, MSE: %f, RMSE: %f, MAE: %f, rot_MSE: %f, rot_RMSE: %f, '\n",
    "        #               'rot_MAE: %f, trans_MSE: %f, trans_RMSE: %f, trans_MAE: %f'\n",
    "        #               % (epoch, test_loss, test_mse_ba, test_rmse_ba, test_mae_ba, test_r_mse_ba, test_r_rmse_ba,\n",
    "        #                  test_r_mae_ba, test_t_mse_ba, test_t_rmse_ba, test_t_mae_ba))\n",
    "\n",
    "        # textio.cprint('==BEST TEST==')\n",
    "        # textio.cprint('A--------->B')\n",
    "        # textio.cprint('EPOCH:: %d, Loss: %f, Cycle Loss: %f, MSE: %f, RMSE: %f, MAE: %f, rot_MSE: %f, rot_RMSE: %f, '\n",
    "        #               'rot_MAE: %f, trans_MSE: %f, trans_RMSE: %f, trans_MAE: %f'\n",
    "        #               % (epoch, best_test_loss, best_test_cycle_loss, best_test_mse_ab, best_test_rmse_ab,\n",
    "        #                  best_test_mae_ab, best_test_r_mse_ab, best_test_r_rmse_ab,\n",
    "        #                  best_test_r_mae_ab, best_test_t_mse_ab, best_test_t_rmse_ab, best_test_t_mae_ab))\n",
    "        # textio.cprint('B--------->A')\n",
    "        # textio.cprint('EPOCH:: %d, Loss: %f, MSE: %f, RMSE: %f, MAE: %f, rot_MSE: %f, rot_RMSE: %f, '\n",
    "        #               'rot_MAE: %f, trans_MSE: %f, trans_RMSE: %f, trans_MAE: %f'\n",
    "        #               % (epoch, best_test_loss, best_test_mse_ba, best_test_rmse_ba, best_test_mae_ba,\n",
    "        #                  best_test_r_mse_ba, best_test_r_rmse_ba,\n",
    "        #                  best_test_r_mae_ba, best_test_t_mse_ba, best_test_t_rmse_ba, best_test_t_mae_ba))\n",
    "\n",
    "        # boardio.add_scalar('A->B/train/loss', train_loss, epoch)\n",
    "        # boardio.add_scalar('A->B/train/MSE', train_mse_ab, epoch)\n",
    "        # boardio.add_scalar('A->B/train/RMSE', train_rmse_ab, epoch)\n",
    "        # boardio.add_scalar('A->B/train/MAE', train_mae_ab, epoch)\n",
    "        # boardio.add_scalar('A->B/train/rotation/MSE', train_r_mse_ab, epoch)\n",
    "        # boardio.add_scalar('A->B/train/rotation/RMSE', train_r_rmse_ab, epoch)\n",
    "        # boardio.add_scalar('A->B/train/rotation/MAE', train_r_mae_ab, epoch)\n",
    "        # boardio.add_scalar('A->B/train/translation/MSE', train_t_mse_ab, epoch)\n",
    "        # boardio.add_scalar('A->B/train/translation/RMSE', train_t_rmse_ab, epoch)\n",
    "        # boardio.add_scalar('A->B/train/translation/MAE', train_t_mae_ab, epoch)\n",
    "\n",
    "        # boardio.add_scalar('B->A/train/loss', train_loss, epoch)\n",
    "        # boardio.add_scalar('B->A/train/MSE', train_mse_ba, epoch)\n",
    "        # boardio.add_scalar('B->A/train/RMSE', train_rmse_ba, epoch)\n",
    "        # boardio.add_scalar('B->A/train/MAE', train_mae_ba, epoch)\n",
    "        # boardio.add_scalar('B->A/train/rotation/MSE', train_r_mse_ba, epoch)\n",
    "        # boardio.add_scalar('B->A/train/rotation/RMSE', train_r_rmse_ba, epoch)\n",
    "        # boardio.add_scalar('B->A/train/rotation/MAE', train_r_mae_ba, epoch)\n",
    "        # boardio.add_scalar('B->A/train/translation/MSE', train_t_mse_ba, epoch)\n",
    "        # boardio.add_scalar('B->A/train/translation/RMSE', train_t_rmse_ba, epoch)\n",
    "        # boardio.add_scalar('B->A/train/translation/MAE', train_t_mae_ba, epoch)\n",
    "\n",
    "        # ############TEST\n",
    "        # boardio.add_scalar('A->B/test/loss', test_loss, epoch)\n",
    "        # boardio.add_scalar('A->B/test/MSE', test_mse_ab, epoch)\n",
    "        # boardio.add_scalar('A->B/test/RMSE', test_rmse_ab, epoch)\n",
    "        # boardio.add_scalar('A->B/test/MAE', test_mae_ab, epoch)\n",
    "        # boardio.add_scalar('A->B/test/rotation/MSE', test_r_mse_ab, epoch)\n",
    "        # boardio.add_scalar('A->B/test/rotation/RMSE', test_r_rmse_ab, epoch)\n",
    "        # boardio.add_scalar('A->B/test/rotation/MAE', test_r_mae_ab, epoch)\n",
    "        # boardio.add_scalar('A->B/test/translation/MSE', test_t_mse_ab, epoch)\n",
    "        # boardio.add_scalar('A->B/test/translation/RMSE', test_t_rmse_ab, epoch)\n",
    "        # boardio.add_scalar('A->B/test/translation/MAE', test_t_mae_ab, epoch)\n",
    "\n",
    "        # boardio.add_scalar('B->A/test/loss', test_loss, epoch)\n",
    "        # boardio.add_scalar('B->A/test/MSE', test_mse_ba, epoch)\n",
    "        # boardio.add_scalar('B->A/test/RMSE', test_rmse_ba, epoch)\n",
    "        # boardio.add_scalar('B->A/test/MAE', test_mae_ba, epoch)\n",
    "        # boardio.add_scalar('B->A/test/rotation/MSE', test_r_mse_ba, epoch)\n",
    "        # boardio.add_scalar('B->A/test/rotation/RMSE', test_r_rmse_ba, epoch)\n",
    "        # boardio.add_scalar('B->A/test/rotation/MAE', test_r_mae_ba, epoch)\n",
    "        # boardio.add_scalar('B->A/test/translation/MSE', test_t_mse_ba, epoch)\n",
    "        # boardio.add_scalar('B->A/test/translation/RMSE', test_t_rmse_ba, epoch)\n",
    "        # boardio.add_scalar('B->A/test/translation/MAE', test_t_mae_ba, epoch)\n",
    "\n",
    "        # ############BEST TEST\n",
    "        # boardio.add_scalar('A->B/best_test/loss', best_test_loss, epoch)\n",
    "        # boardio.add_scalar('A->B/best_test/MSE', best_test_mse_ab, epoch)\n",
    "        # boardio.add_scalar('A->B/best_test/RMSE', best_test_rmse_ab, epoch)\n",
    "        # boardio.add_scalar('A->B/best_test/MAE', best_test_mae_ab, epoch)\n",
    "        # boardio.add_scalar('A->B/best_test/rotation/MSE', best_test_r_mse_ab, epoch)\n",
    "        # boardio.add_scalar('A->B/best_test/rotation/RMSE', best_test_r_rmse_ab, epoch)\n",
    "        # boardio.add_scalar('A->B/best_test/rotation/MAE', best_test_r_mae_ab, epoch)\n",
    "        # boardio.add_scalar('A->B/best_test/translation/MSE', best_test_t_mse_ab, epoch)\n",
    "        # boardio.add_scalar('A->B/best_test/translation/RMSE', best_test_t_rmse_ab, epoch)\n",
    "        # boardio.add_scalar('A->B/best_test/translation/MAE', best_test_t_mae_ab, epoch)\n",
    "\n",
    "        # boardio.add_scalar('B->A/best_test/loss', best_test_loss, epoch)\n",
    "        # boardio.add_scalar('B->A/best_test/MSE', best_test_mse_ba, epoch)\n",
    "        # boardio.add_scalar('B->A/best_test/RMSE', best_test_rmse_ba, epoch)\n",
    "        # boardio.add_scalar('B->A/best_test/MAE', best_test_mae_ba, epoch)\n",
    "        # boardio.add_scalar('B->A/best_test/rotation/MSE', best_test_r_mse_ba, epoch)\n",
    "        # boardio.add_scalar('B->A/best_test/rotation/RMSE', best_test_r_rmse_ba, epoch)\n",
    "        # boardio.add_scalar('B->A/best_test/rotation/MAE', best_test_r_mae_ba, epoch)\n",
    "        # boardio.add_scalar('B->A/best_test/translation/MSE', best_test_t_mse_ba, epoch)\n",
    "        # boardio.add_scalar('B->A/best_test/translation/RMSE', best_test_t_rmse_ba, epoch)\n",
    "        # boardio.add_scalar('B->A/best_test/translation/MAE', best_test_t_mae_ba, epoch)\n",
    "\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            torch.save(net.module.state_dict(), 'checkpoints/%s/models/model.%d.t7' % (args['exp_name'], epoch))\n",
    "        else:\n",
    "            torch.save(net.state_dict(), 'checkpoints/%s/models/model.%d.t7' % (args['exp_name'], epoch))\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_one_epoch(args, net, test_loader):\n",
    "    net.eval()\n",
    "    mse_ab = 0\n",
    "    mae_ab = 0\n",
    "    mse_ba = 0\n",
    "    mae_ba = 0\n",
    "\n",
    "    total_loss = 0\n",
    "    total_cycle_loss = 0\n",
    "    num_examples = 0\n",
    "    rotations_ab = []\n",
    "    translations_ab = []\n",
    "    rotations_ab_pred = []\n",
    "    translations_ab_pred = []\n",
    "\n",
    "    rotations_ba = []\n",
    "    translations_ba = []\n",
    "    rotations_ba_pred = []\n",
    "    translations_ba_pred = []\n",
    "\n",
    "    eulers_ab = []\n",
    "    eulers_ba = []\n",
    "\n",
    "    net = net.cuda()\n",
    "\n",
    "    for src, target, rotation_ab, translation_ab, rotation_ba, translation_ba, euler_ab, euler_ba, _ in test_loader:\n",
    "        src = src.cuda()\n",
    "        target = target.cuda()\n",
    "        rotation_ab = rotation_ab.cuda()\n",
    "        translation_ab = translation_ab.cuda()\n",
    "        rotation_ba = rotation_ba.cuda()\n",
    "        translation_ba = translation_ba.cuda()\n",
    "        # print(rotation_ab.shape)\n",
    "\n",
    "        batch_size = src.size(0)\n",
    "        num_examples += batch_size\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            rotation_ab_pred, translation_ab_pred, rotation_ba_pred, translation_ba_pred = net(src, target)\n",
    "\n",
    "        ## save rotation and translation\n",
    "        rotations_ab.append(rotation_ab.detach().cpu().numpy())\n",
    "        translations_ab.append(translation_ab.detach().cpu().numpy())\n",
    "        rotations_ab_pred.append(rotation_ab_pred.detach().cpu().numpy())\n",
    "        translations_ab_pred.append(translation_ab_pred.detach().cpu().numpy())\n",
    "        eulers_ab.append(euler_ab.numpy())\n",
    "        ##\n",
    "        rotations_ba.append(rotation_ba.detach().cpu().numpy())\n",
    "        translations_ba.append(translation_ba.detach().cpu().numpy())\n",
    "        rotations_ba_pred.append(rotation_ba_pred.detach().cpu().numpy())\n",
    "        translations_ba_pred.append(translation_ba_pred.detach().cpu().numpy())\n",
    "        eulers_ba.append(euler_ba.numpy())\n",
    "\n",
    "        transformed_src = transform_point_cloud(src, rotation_ab_pred, translation_ab_pred)\n",
    "\n",
    "        transformed_target = transform_point_cloud(target, rotation_ba_pred, translation_ba_pred)\n",
    "\n",
    "        ###########################\n",
    "        identity = torch.eye(3).cuda().unsqueeze(0).repeat(batch_size, 1, 1)\n",
    "        loss = F.mse_loss(torch.matmul(rotation_ab_pred.transpose(2, 1), rotation_ab), identity) \\\n",
    "               + F.mse_loss(translation_ab_pred, translation_ab)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        mse_ab += torch.mean((transformed_src - target) ** 2, dim=[0, 1, 2]).item() * batch_size\n",
    "        mae_ab += torch.mean(torch.abs(transformed_src - target), dim=[0, 1, 2]).item() * batch_size\n",
    "\n",
    "        mse_ba += torch.mean((transformed_target - src) ** 2, dim=[0, 1, 2]).item() * batch_size\n",
    "        mae_ba += torch.mean(torch.abs(transformed_target - src), dim=[0, 1, 2]).item() * batch_size\n",
    "\n",
    "    rotations_ab = np.concatenate(rotations_ab, axis=0)\n",
    "    translations_ab = np.concatenate(translations_ab, axis=0)\n",
    "    rotations_ab_pred = np.concatenate(rotations_ab_pred, axis=0)\n",
    "    translations_ab_pred = np.concatenate(translations_ab_pred, axis=0)\n",
    "\n",
    "    rotations_ba = np.concatenate(rotations_ba, axis=0)\n",
    "    translations_ba = np.concatenate(translations_ba, axis=0)\n",
    "    rotations_ba_pred = np.concatenate(rotations_ba_pred, axis=0)\n",
    "    translations_ba_pred = np.concatenate(translations_ba_pred, axis=0)\n",
    "\n",
    "    eulers_ab = np.concatenate(eulers_ab, axis=0)\n",
    "    eulers_ba = np.concatenate(eulers_ba, axis=0)\n",
    "\n",
    "    return total_loss * 1.0 / num_examples, total_cycle_loss / num_examples, \\\n",
    "           mse_ab * 1.0 / num_examples, mae_ab * 1.0 / num_examples, \\\n",
    "           mse_ba * 1.0 / num_examples, mae_ba * 1.0 / num_examples, rotations_ab, \\\n",
    "           translations_ab, rotations_ab_pred, translations_ab_pred, rotations_ba, \\\n",
    "           translations_ba, rotations_ba_pred, translations_ba_pred, eulers_ab, eulers_ba\n",
    "\n",
    "\n",
    "def test(args, net, test_loader, boardio, textio):\n",
    "\n",
    "    test_loss, test_cycle_loss, \\\n",
    "    test_mse_ab, test_mae_ab, test_mse_ba, test_mae_ba, test_rotations_ab, test_translations_ab, \\\n",
    "    test_rotations_ab_pred, \\\n",
    "    test_translations_ab_pred, test_rotations_ba, test_translations_ba, test_rotations_ba_pred, \\\n",
    "    test_translations_ba_pred, test_eulers_ab, test_eulers_ba = test_one_epoch(args, net, test_loader)\n",
    "    test_rmse_ab = np.sqrt(test_mse_ab)\n",
    "    test_rmse_ba = np.sqrt(test_mse_ba)\n",
    "\n",
    "    test_rotations_ab_pred_euler = npmat2euler(test_rotations_ab_pred)\n",
    "    test_r_mse_ab = np.mean((test_rotations_ab_pred_euler - np.degrees(test_eulers_ab)) ** 2)\n",
    "    test_r_rmse_ab = np.sqrt(test_r_mse_ab)\n",
    "    test_r_mae_ab = np.mean(np.abs(test_rotations_ab_pred_euler - np.degrees(test_eulers_ab)))\n",
    "    test_t_mse_ab = np.mean((test_translations_ab - test_translations_ab_pred) ** 2)\n",
    "    test_t_rmse_ab = np.sqrt(test_t_mse_ab)\n",
    "    test_t_mae_ab = np.mean(np.abs(test_translations_ab - test_translations_ab_pred))\n",
    "\n",
    "    test_rotations_ba_pred_euler = npmat2euler(test_rotations_ba_pred, 'xyz')\n",
    "    test_r_mse_ba = np.mean((test_rotations_ba_pred_euler - np.degrees(test_eulers_ba)) ** 2)\n",
    "    test_r_rmse_ba = np.sqrt(test_r_mse_ba)\n",
    "    test_r_mae_ba = np.mean(np.abs(test_rotations_ba_pred_euler - np.degrees(test_eulers_ba)))\n",
    "    test_t_mse_ba = np.mean((test_translations_ba - test_translations_ba_pred) ** 2)\n",
    "    test_t_rmse_ba = np.sqrt(test_t_mse_ba)\n",
    "    test_t_mae_ba = np.mean(np.abs(test_translations_ba - test_translations_ba_pred))\n",
    "\n",
    "    textio.cprint('==FINAL TEST==')\n",
    "    textio.cprint('A--------->B')\n",
    "    textio.cprint('EPOCH:: %d, Loss: %f, Cycle Loss: %f, MSE: %f, RMSE: %f, MAE: %f, rot_MSE: %f, rot_RMSE: %f, '\n",
    "                  'rot_MAE: %f, trans_MSE: %f, trans_RMSE: %f, trans_MAE: %f'\n",
    "                  % (-1, test_loss, test_cycle_loss, test_mse_ab, test_rmse_ab, test_mae_ab,\n",
    "                     test_r_mse_ab, test_r_rmse_ab,\n",
    "                     test_r_mae_ab, test_t_mse_ab, test_t_rmse_ab, test_t_mae_ab))\n",
    "    textio.cprint('B--------->A')\n",
    "    textio.cprint('EPOCH:: %d, Loss: %f, MSE: %f, RMSE: %f, MAE: %f, rot_MSE: %f, rot_RMSE: %f, '\n",
    "                  'rot_MAE: %f, trans_MSE: %f, trans_RMSE: %f, trans_MAE: %f'\n",
    "                  % (-1, test_loss, test_mse_ba, test_rmse_ba, test_mae_ba, test_r_mse_ba, test_r_rmse_ba,\n",
    "                     test_r_mae_ba, test_t_mse_ba, test_t_rmse_ba, test_t_mae_ba))\n",
    "\n",
    "    return test_rotations_ab_pred, test_translations_ab_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] [CheckHeader] PCD has no data.\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] Read PCD failed: unable to parse header.\u001b[0;m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "high <= 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/hang/Desktop/Master/S2/ML 3D Geometry/project/ml3d/test.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 62>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hang/Desktop/Master/S2/ML%203D%20Geometry/project/ml3d/test.ipynb#ch0000007?line=58'>59</a>\u001b[0m         \u001b[39mdef\u001b[39;00m \u001b[39m__len__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hang/Desktop/Master/S2/ML%203D%20Geometry/project/ml3d/test.ipynb#ch0000007?line=59'>60</a>\u001b[0m                 \u001b[39mreturn\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpoints1)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/hang/Desktop/Master/S2/ML%203D%20Geometry/project/ml3d/test.ipynb#ch0000007?line=61'>62</a>\u001b[0m points \u001b[39m=\u001b[39m TUM(\u001b[39m20000\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hang/Desktop/Master/S2/ML%203D%20Geometry/project/ml3d/test.ipynb#ch0000007?line=63'>64</a>\u001b[0m \u001b[39m# define the dataloader\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hang/Desktop/Master/S2/ML%203D%20Geometry/project/ml3d/test.ipynb#ch0000007?line=64'>65</a>\u001b[0m \u001b[39m# pc = ModelNet40(num_points=1024, partition='test', gaussian_noise=False, unseen=False, factor=4)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hang/Desktop/Master/S2/ML%203D%20Geometry/project/ml3d/test.ipynb#ch0000007?line=65'>66</a>\u001b[0m \u001b[39m# src, target, rotation_ab, translation_ab, rotation_ba, translation_ba, euler_ab, euler_ba = pc[6]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hang/Desktop/Master/S2/ML%203D%20Geometry/project/ml3d/test.ipynb#ch0000007?line=67'>68</a>\u001b[0m args \u001b[39m=\u001b[39m {\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hang/Desktop/Master/S2/ML%203D%20Geometry/project/ml3d/test.ipynb#ch0000007?line=68'>69</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmodel_path\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mcheckpoints/dcp_v1/models/model.best.t7\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hang/Desktop/Master/S2/ML%203D%20Geometry/project/ml3d/test.ipynb#ch0000007?line=69'>70</a>\u001b[0m         \u001b[39m# \"model_path\": 'dcp-master/pretrained/dcp_v1.t7',\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hang/Desktop/Master/S2/ML%203D%20Geometry/project/ml3d/test.ipynb#ch0000007?line=84'>85</a>\u001b[0m          \u001b[39m'\u001b[39m\u001b[39mn_heads\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m4\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hang/Desktop/Master/S2/ML%203D%20Geometry/project/ml3d/test.ipynb#ch0000007?line=85'>86</a>\u001b[0m         }\n",
      "\u001b[1;32m/Users/hang/Desktop/Master/S2/ML 3D Geometry/project/ml3d/test.ipynb Cell 8\u001b[0m in \u001b[0;36mTUM.__init__\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hang/Desktop/Master/S2/ML%203D%20Geometry/project/ml3d/test.ipynb#ch0000007?line=4'>5</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, size):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hang/Desktop/Master/S2/ML%203D%20Geometry/project/ml3d/test.ipynb#ch0000007?line=5'>6</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpcd1 \u001b[39m=\u001b[39m o3d\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mread_point_cloud(\u001b[39m\"\u001b[39m\u001b[39mscenenet/val/0/0/3800_after_filtering.pcd\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/hang/Desktop/Master/S2/ML%203D%20Geometry/project/ml3d/test.ipynb#ch0000007?line=6'>7</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mrandint(\u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpcd1\u001b[39m.\u001b[39;49mpoints),size\u001b[39m=\u001b[39;49msize)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hang/Desktop/Master/S2/ML%203D%20Geometry/project/ml3d/test.ipynb#ch0000007?line=7'>8</a>\u001b[0m         \u001b[39m# print(self.index)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hang/Desktop/Master/S2/ML%203D%20Geometry/project/ml3d/test.ipynb#ch0000007?line=8'>9</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpoints1 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpcd1\u001b[39m.\u001b[39mpoints)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex] \u001b[39m#转为矩阵\u001b[39;00m\n",
      "File \u001b[0;32mmtrand.pyx:748\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_bounded_integers.pyx:1247\u001b[0m, in \u001b[0;36mnumpy.random._bounded_integers._rand_int64\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: high <= 0"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "class TUM(Dataset):\n",
    "        def __init__(self, size):\n",
    "                self.pcd1 = o3d.io.read_point_cloud(\"scenenet/val/0/0/3800_after_filtering.pcd\")\n",
    "                self.index = np.random.randint(len(self.pcd1.points),size=size)\n",
    "                # print(self.index)\n",
    "                self.points1 = np.array(self.pcd1.points)[self.index] #转为矩阵\n",
    "\n",
    "                self.pcd2 = o3d.io.read_point_cloud(\"scenenet/val/0/0/3800_after_filtering.pcd\")\n",
    "                self.points2 = np.array(self.pcd2.points)[self.index]\n",
    "\n",
    "                self.points1 = self.points1[np.newaxis,:]\n",
    "    \n",
    "        def __getitem__(self, index):\n",
    "                points1 = self.points1[index]\n",
    "                anglex = np.random.uniform() * np.pi / 20\n",
    "                angley = np.random.uniform() * np.pi / 20\n",
    "                anglez = np.random.uniform() * np.pi / 20\n",
    "\n",
    "                anglex = 0.10750457315556647\n",
    "                angley = -0.16308165329963306\n",
    "                anglez = 0.011883495138386518\n",
    "\n",
    "                cosx = np.cos(anglex)\n",
    "                cosy = np.cos(angley)\n",
    "                cosz = np.cos(anglez)\n",
    "                sinx = np.sin(anglex)\n",
    "                siny = np.sin(angley)\n",
    "                sinz = np.sin(anglez)\n",
    "                Rx = np.array([[1, 0, 0],\n",
    "                                [0, cosx, -sinx],\n",
    "                                [0, sinx, cosx]])\n",
    "                Ry = np.array([[cosy, 0, siny],\n",
    "                                [0, 1, 0],\n",
    "                                [-siny, 0, cosy]])\n",
    "                Rz = np.array([[cosz, -sinz, 0],\n",
    "                                [sinz, cosz, 0],\n",
    "                                [0, 0, 1]])\n",
    "                R_ab = Rx.dot(Ry).dot(Rz)\n",
    "                R_ba = R_ab.T\n",
    "                translation_ab = np.array([np.random.uniform(-0.5, 0.5), np.random.uniform(-0.5, 0.5),\n",
    "                                                np.random.uniform(-0.5, 0.5)])\n",
    "                tx = 1.0953829982311267\n",
    "                ty = 0.4325993321892744\n",
    "                tz = 0.4725850417356405\n",
    "                translation_ab = np.array([tx, ty, tz])\n",
    "                translation_ba = -R_ba.dot(translation_ab)\n",
    "\n",
    "\n",
    "                euler_ab = np.asarray([anglez, angley, anglex])\n",
    "                euler_ba = -euler_ab[::-1]\n",
    "                \n",
    "                return points1.T.astype('float32'), self.points2.T.astype('float32'), R_ab.astype('float32'), \\\n",
    "        translation_ab.astype('float32'), R_ba.astype('float32'), translation_ba.astype('float32'), \\\n",
    "        euler_ab.astype('float32'), euler_ba.astype('float32'), self.index\n",
    "\n",
    "        def __len__(self):\n",
    "                return len(self.points1)\n",
    "\n",
    "points = TUM(20000)\n",
    "\n",
    "# define the dataloader\n",
    "# pc = ModelNet40(num_points=1024, partition='test', gaussian_noise=False, unseen=False, factor=4)\n",
    "# src, target, rotation_ab, translation_ab, rotation_ba, translation_ba, euler_ab, euler_ba = pc[6]\n",
    "\n",
    "args = {\n",
    "        \"model_path\": 'checkpoints/dcp_v1/models/model.best.t7',\n",
    "        # \"model_path\": 'dcp-master/pretrained/dcp_v1.t7',\n",
    "        \"exp_name\":\"dcp_v1\",\n",
    "         \"model\":\"dcp\", \n",
    "         \"emb_nn\":\"dgcnn\", \n",
    "         \"pointer\":\"identity\", \n",
    "         \"head\":\"svd\", \n",
    "         \"eval\": True,\n",
    "         'emb_dims': 512,\n",
    "         'cycle': False,\n",
    "         'use_sgd': False,\n",
    "         'lr': 0.001,\n",
    "         'epochs': 250,\n",
    "         'n_blocks': 1,\n",
    "         'dropout': 0.0,\n",
    "         'ff_dims': 1024,\n",
    "         'n_heads': 4,\n",
    "        }\n",
    "\n",
    "train_loader = DataLoader(points, batch_size=32, shuffle=True, drop_last=False)\n",
    "test_loader = DataLoader(points, batch_size=1, shuffle=False, drop_last=False)\n",
    "\n",
    "# test_loader = DataLoader(\n",
    "#             ModelNet40(num_points=args.num_points, partition='test', gaussian_noise=args.gaussian_noise,\n",
    "#                        unseen=args.unseen, factor=args.factor),\n",
    "#             batch_size=args.test_batch_size, shuffle=False, drop_last=False)\n",
    "boardio = SummaryWriter(log_dir='checkpoints/' + args['exp_name'])\n",
    "textio = IOStream('checkpoints/' + args['exp_name'] + '/run.log')\n",
    "textio.cprint(str(args))\n",
    "net = DCP(args)\n",
    "\n",
    "net.train()\n",
    "train(args, net, train_loader, test_loader, boardio, textio)\n",
    "\n",
    "net.load_state_dict(torch.load(args['model_path']), strict=False)\n",
    "net.eval()\n",
    "r, t = test(args, net, test_loader, boardio, textio)\n",
    "\n",
    "print(r)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 20000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cz/1xlnx7y504g5_dyp82wtzxhc0000gn/T/ipykernel_68646/3921062681.py:39: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matricesor `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at  /Users/distiller/project/pytorch/aten/src/ATen/native/TensorShape.cpp:2318.)\n",
      "  transformed_src = transform_point_cloud(torch.tensor(src), r, t).T\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3748506ac4f483b820415b4974430dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a334b9658bc412293f937076881dad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6bb9c0401b04a029f42ec43c1ecb9af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import k3d\n",
    "\n",
    "def visualize_pointcloud(point_cloud1, point_size, point_cloud2=None, flip_axes=False, name='point_cloud', R=None, t=None):\n",
    "    plot = k3d.plot(name=name, grid_visible=False, grid=(-0.55, -0.55, -0.55, 0.55, 0.55, 0.55))\n",
    "    # if flip_axes:\n",
    "    #     point_cloud[:, 2] = point_cloud[:, 2] * -1\n",
    "    #     point_cloud[:, [0, 1, 2]] = point_cloud[:, [0, 2, 1]]\n",
    "    # t_broadcast = np.broadcast_to(t[:, np.newaxis], (3, point_cloud1.X.shape[0]))\n",
    "    # point_cloud1 = (R @ point_cloud1.X.T + t_broadcast).T\n",
    "    plt_points1 = k3d.points(positions=point_cloud1, point_size=point_size, color=0xd0d0d0)\n",
    "    plot += plt_points1\n",
    "    plt_points1.shader = '3d'\n",
    "    if point_cloud2 is not None:\n",
    "        plt_points2 = k3d.points(positions=point_cloud2, point_size=point_size, color=0x0dd00d)\n",
    "        plot += plt_points2\n",
    "        plt_points2.shader = '3d'\n",
    "    plot.display()\n",
    "\n",
    "def transform(point_cloud, R=None, t=None):\n",
    "    t_broadcast = np.broadcast_to(t[:, np.newaxis], (3, point_cloud.shape[0]))\n",
    "    return (R @ point_cloud.T + t_broadcast).T\n",
    "\n",
    "\n",
    "src, target, rotation_ab, translation_ab, rotation_ba, translation_ba, euler_ab, euler_ba, index = points[0]\n",
    "print(src.shape)\n",
    "quat = torch.tensor([[0.6574, 0.6126, -0.2949, -0.3248], [0.6579, 0.6161, -0.2932, -0.3189]])\n",
    "r = torch.tensor([[[ 0.99959856, -0.00936801,  0.02673812],\n",
    " [ 0.01243275,  0.9930703,  -0.1168622 ],\n",
    " [-0.02545807,  0.11714771,  0.99278814]]])\n",
    "# print(r)\n",
    "t = torch.tensor([[-0.29480037,  0.11526811,  0.31008014]])\n",
    "\n",
    "r1 = torch.tensor([[[ 0.98670018, -0.01175757, -0.162125],\n",
    " [-0.00559273,  0.99433457, -0.10614836],\n",
    " [ 0.16245453,  0.10564333,  0.98104435]]])\n",
    "t1 = torch.tensor([[1.09464561,  0.43318735,   0.47305842 ]])\n",
    "# print(points1.shape)\n",
    "transformed_src = transform_point_cloud(torch.tensor(src), r, t).T\n",
    "transformed_src1 = transform_point_cloud(torch.tensor(src), r1, t1).T\n",
    "visualize_pointcloud(target.T, .03, transformed_src1)\n",
    "visualize_pointcloud(target.T, .03, transformed_src)\n",
    "visualize_pointcloud(src.T, .03, target.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n",
      "[[[-0.06211722]\n",
      "  [ 0.53723976]\n",
      "  [-0.84113905]]\n",
      "\n",
      " [[ 0.9939852 ]\n",
      "  [-0.04285963]\n",
      "  [-0.10077942]]\n",
      "\n",
      " [[-0.09019362]\n",
      "  [-0.84233992]\n",
      "  [-0.53134601]]]\n",
      "[[ 6.9640594 -3.0607047 12.442743 ]]\n",
      "[[ 0.98666196 -0.01172554 -0.16235974]\n",
      " [-0.00560497  0.99436376 -0.10587395]\n",
      " [ 0.16268607  0.10537182  0.98103518]]\n",
      "[1.095383   0.43259933 0.47258504]\n"
     ]
    }
   ],
   "source": [
    "r = np.array([[ 0.00520319,  0.62180531, -0.00795137],\n",
    " [ 0.61245382,  0.00143963, -0.04598352],\n",
    " [-0.0056224,  -0.05133275,  0.3842194 ]])\n",
    "\n",
    "# r1 = np.array([[ 0.07543147,  0.61393189, -0.78574661],\n",
    "#  [ 0.9970987,  -0.03837025,  0.06574118],\n",
    "#  [ 0.01021131, -0.78842588, -0.61504501]])\n",
    "\n",
    "r2 = np.array([[ 0.06897899,  0.62361461, -0.77868268],\n",
    " [ 0.99759245, -0.03751941,  0.0583232 ],\n",
    " [ 0.00715548, -0.78083104, -0.62470127]])\n",
    "\n",
    "r = np.array([[ 1,  -0.02185709,  0.08722663],\n",
    "  [ 0.08445041,  1,   2.25380598],\n",
    "  [-0.02161435, 1.43743747,  1 ]])\n",
    "print(np.linalg.det(r1))\n",
    "print(np.dot(r2, r1.T))\n",
    "print(npmat2euler(r1)+2*np.pi)\n",
    "rx = 0.10750457315556647\n",
    "ry = -0.16308165329963306\n",
    "rz = 0.011883495138386518\n",
    "tx = 1.0953829982311267\n",
    "ty = 0.4325993321892744\n",
    "tz = 0.4725850417356405\n",
    "def euler_angles_to_rotation_matrix(\n",
    "    alpha1: float, alpha2: float, alpha3: float\n",
    ") -> np.array:\n",
    "    \"\"\"Get Euler angles from rotation matrix.\"\"\"\n",
    "\n",
    "    R = np.array(\n",
    "        [\n",
    "            [\n",
    "                np.cos(alpha2) * np.cos(alpha3),\n",
    "                -np.cos(alpha2) * np.sin(alpha3),\n",
    "                np.sin(alpha2),\n",
    "            ],\n",
    "            [\n",
    "                np.cos(alpha1) * np.sin(alpha3)\n",
    "                + np.sin(alpha1) * np.sin(alpha2) * np.cos(alpha3),\n",
    "                np.cos(alpha1) * np.cos(alpha3)\n",
    "                - np.sin(alpha1) * np.sin(alpha2) * np.sin(alpha3),\n",
    "                -np.sin(alpha1) * np.cos(alpha2),\n",
    "            ],\n",
    "            [\n",
    "                np.sin(alpha1) * np.sin(alpha3)\n",
    "                - np.cos(alpha1) * np.sin(alpha2) * np.cos(alpha3),\n",
    "                np.sin(alpha1) * np.cos(alpha3)\n",
    "                + np.cos(alpha1) * np.sin(alpha2) * np.sin(alpha3),\n",
    "                np.cos(alpha1) * np.cos(alpha2),\n",
    "            ],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return R\n",
    "print(euler_angles_to_rotation_matrix(rx, ry, rz))\n",
    "print(np.array([tx, ty, tz]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.08520717  0.          0.99636326 -4.14955647]\n",
      " [ 0.07206861 -0.99738063  0.00616318  0.79068184]\n",
      " [ 0.99375342  0.07233166  0.08498398  0.66191937]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "[[-0.24603355  0.          0.96926131 -3.11633267]\n",
      " [-0.03334845 -0.99940794 -0.00846504  1.17233533]\n",
      " [ 0.96868745 -0.03440605  0.24588788  0.53184667]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "[[ 0.98670018 -0.01175757 -0.162125    1.09464561]\n",
      " [-0.00559273  0.99433457 -0.10614836  0.43318735]\n",
      " [ 0.16245453  0.10564333  0.98104435  0.47305842]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "viewpose1 = {\n",
    "    'lookat': np.array([4.7825798988342285, 1.166599988937378, 4.573699951171875]),\n",
    "    'camera': np.array([-1.0683399438858032, 0.7407330274581909, 4.073339939117432])\n",
    "}\n",
    "\n",
    "viewpose2 = {\n",
    "    'lookat': np.array([4.7150797843933105, 0.9783260226249695, 4.412020206451416]),\n",
    "    'camera': np.array([-1.2428200244903564, 1.1899399757385254, 2.8996899127960205])\n",
    "}\n",
    "\n",
    "def normalize(v):\n",
    "    return v/np.linalg.norm(v)\n",
    "\n",
    "\n",
    "def world_to_camera_with_pose(view_pose):\n",
    "    lookat_pose = view_pose['lookat']\n",
    "    camera_pose = view_pose['camera']\n",
    "    up = np.array([0,1,0])\n",
    "    R = np.diag(np.ones(4))\n",
    "    R[2,:3] = normalize(lookat_pose - camera_pose)\n",
    "    R[0,:3] = normalize(np.cross(R[2,:3],up))\n",
    "    R[1,:3] = -normalize(np.cross(R[0,:3],R[2,:3]))\n",
    "    T = np.diag(np.ones(4))\n",
    "    T[:3,3] = -camera_pose\n",
    "    return R.dot(T)\n",
    "\n",
    "\n",
    "def camera_to_world_with_pose(view_pose):\n",
    "    return np.linalg.inv(world_to_camera_with_pose(view_pose))\n",
    "\n",
    "r1 = world_to_camera_with_pose(viewpose1)\n",
    "r2 = world_to_camera_with_pose(viewpose2)\n",
    "\n",
    "print(r1)\n",
    "print(r2)\n",
    "\n",
    "print(np.dot(r2, np.linalg.inv(r1)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('python39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "beda123ca6d46414026d3c59f732de1f5fb19d6ba2f32753cc4223591eed0a9d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
