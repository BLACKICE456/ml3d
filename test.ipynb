{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCP Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import gc\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "import sys\n",
    "sys.path.append(\"dcp-master\")\n",
    "from data import ModelNet40\n",
    "from model import DCP\n",
    "from util import transform_point_cloud, npmat2euler\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Part of the code is referred from: https://github.com/floodsung/LearningToCompare_FSL\n",
    "\n",
    "class IOStream:\n",
    "    def __init__(self, path):\n",
    "        self.f = open(path, 'a')\n",
    "\n",
    "    def cprint(self, text):\n",
    "        print(text)\n",
    "        self.f.write(text + '\\n')\n",
    "        self.f.flush()\n",
    "\n",
    "    def close(self):\n",
    "        self.f.close()\n",
    "\n",
    "\n",
    "def _init_(args):\n",
    "    if not os.path.exists('checkpoints'):\n",
    "        os.makedirs('checkpoints')\n",
    "    if not os.path.exists('checkpoints/' + args.exp_name):\n",
    "        os.makedirs('checkpoints/' + args.exp_name)\n",
    "    if not os.path.exists('checkpoints/' + args.exp_name + '/' + 'models'):\n",
    "        os.makedirs('checkpoints/' + args.exp_name + '/' + 'models')\n",
    "    os.system('cp main.py checkpoints' + '/' + args.exp_name + '/' + 'main.py.backup')\n",
    "    os.system('cp model.py checkpoints' + '/' + args.exp_name + '/' + 'model.py.backup')\n",
    "    os.system('cp data.py checkpoints' + '/' + args.exp_name + '/' + 'data.py.backup')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(args, net, train_loader, opt):\n",
    "    net.train()\n",
    "\n",
    "    mse_ab = 0\n",
    "    mae_ab = 0\n",
    "    mse_ba = 0\n",
    "    mae_ba = 0\n",
    "\n",
    "    total_loss = 0\n",
    "    total_cycle_loss = 0\n",
    "    num_examples = 0\n",
    "    rotations_ab = []\n",
    "    translations_ab = []\n",
    "    rotations_ab_pred = []\n",
    "    translations_ab_pred = []\n",
    "\n",
    "    rotations_ba = []\n",
    "    translations_ba = []\n",
    "    rotations_ba_pred = []\n",
    "    translations_ba_pred = []\n",
    "\n",
    "    eulers_ab = []\n",
    "    eulers_ba = []\n",
    "\n",
    "    for src, target, rotation_ab, translation_ab, rotation_ba, translation_ba, euler_ab, euler_ba in tqdm(train_loader):\n",
    "        src = src.cuda()\n",
    "        target = target.cuda()\n",
    "        rotation_ab = rotation_ab.cuda()\n",
    "        translation_ab = translation_ab.cuda()\n",
    "        rotation_ba = rotation_ba.cuda()\n",
    "        translation_ba = translation_ba.cuda()\n",
    "\n",
    "        batch_size = src.size(0)\n",
    "        opt.zero_grad()\n",
    "        num_examples += batch_size\n",
    "        rotation_ab_pred, translation_ab_pred, rotation_ba_pred, translation_ba_pred = net(src, target)\n",
    "\n",
    "        ## save rotation and translation\n",
    "        rotations_ab.append(rotation_ab.detach().cpu().numpy())\n",
    "        translations_ab.append(translation_ab.detach().cpu().numpy())\n",
    "        rotations_ab_pred.append(rotation_ab_pred.detach().cpu().numpy())\n",
    "        translations_ab_pred.append(translation_ab_pred.detach().cpu().numpy())\n",
    "        eulers_ab.append(euler_ab.numpy())\n",
    "        ##\n",
    "        rotations_ba.append(rotation_ba.detach().cpu().numpy())\n",
    "        translations_ba.append(translation_ba.detach().cpu().numpy())\n",
    "        rotations_ba_pred.append(rotation_ba_pred.detach().cpu().numpy())\n",
    "        translations_ba_pred.append(translation_ba_pred.detach().cpu().numpy())\n",
    "        eulers_ba.append(euler_ba.numpy())\n",
    "\n",
    "        transformed_src = transform_point_cloud(src, rotation_ab_pred, translation_ab_pred)\n",
    "\n",
    "        transformed_target = transform_point_cloud(target, rotation_ba_pred, translation_ba_pred)\n",
    "        ###########################\n",
    "        identity = torch.eye(3).cuda().unsqueeze(0).repeat(batch_size, 1, 1)\n",
    "        loss = F.mse_loss(torch.matmul(rotation_ab_pred.transpose(2, 1), rotation_ab), identity) \\\n",
    "               + F.mse_loss(translation_ab_pred, translation_ab)\n",
    "        if args.cycle:\n",
    "            rotation_loss = F.mse_loss(torch.matmul(rotation_ba_pred, rotation_ab_pred), identity.clone())\n",
    "            translation_loss = torch.mean((torch.matmul(rotation_ba_pred.transpose(2, 1),\n",
    "                                                        translation_ab_pred.view(batch_size, 3, 1)).view(batch_size, 3)\n",
    "                                           + translation_ba_pred) ** 2, dim=[0, 1])\n",
    "            cycle_loss = rotation_loss + translation_loss\n",
    "\n",
    "            loss = loss + cycle_loss * 0.1\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total_loss += loss.item() * batch_size\n",
    "\n",
    "        if args.cycle:\n",
    "            total_cycle_loss = total_cycle_loss + cycle_loss.item() * 0.1 * batch_size\n",
    "\n",
    "        mse_ab += torch.mean((transformed_src - target) ** 2, dim=[0, 1, 2]).item() * batch_size\n",
    "        mae_ab += torch.mean(torch.abs(transformed_src - target), dim=[0, 1, 2]).item() * batch_size\n",
    "\n",
    "        mse_ba += torch.mean((transformed_target - src) ** 2, dim=[0, 1, 2]).item() * batch_size\n",
    "        mae_ba += torch.mean(torch.abs(transformed_target - src), dim=[0, 1, 2]).item() * batch_size\n",
    "\n",
    "    rotations_ab = np.concatenate(rotations_ab, axis=0)\n",
    "    translations_ab = np.concatenate(translations_ab, axis=0)\n",
    "    rotations_ab_pred = np.concatenate(rotations_ab_pred, axis=0)\n",
    "    translations_ab_pred = np.concatenate(translations_ab_pred, axis=0)\n",
    "\n",
    "    rotations_ba = np.concatenate(rotations_ba, axis=0)\n",
    "    translations_ba = np.concatenate(translations_ba, axis=0)\n",
    "    rotations_ba_pred = np.concatenate(rotations_ba_pred, axis=0)\n",
    "    translations_ba_pred = np.concatenate(translations_ba_pred, axis=0)\n",
    "\n",
    "    eulers_ab = np.concatenate(eulers_ab, axis=0)\n",
    "    eulers_ba = np.concatenate(eulers_ba, axis=0)\n",
    "\n",
    "    return total_loss * 1.0 / num_examples, total_cycle_loss / num_examples, \\\n",
    "           mse_ab * 1.0 / num_examples, mae_ab * 1.0 / num_examples, \\\n",
    "           mse_ba * 1.0 / num_examples, mae_ba * 1.0 / num_examples, rotations_ab, \\\n",
    "           translations_ab, rotations_ab_pred, translations_ab_pred, rotations_ba, \\\n",
    "           translations_ba, rotations_ba_pred, translations_ba_pred, eulers_ab, eulers_ba\n",
    "\n",
    "def train(args, net, train_loader, test_loader, boardio, textio):\n",
    "    if args.use_sgd:\n",
    "        print(\"Use SGD\")\n",
    "        opt = optim.SGD(net.parameters(), lr=args.lr * 100, momentum=args.momentum, weight_decay=1e-4)\n",
    "    else:\n",
    "        print(\"Use Adam\")\n",
    "        opt = optim.Adam(net.parameters(), lr=args.lr, weight_decay=1e-4)\n",
    "    scheduler = MultiStepLR(opt, milestones=[75, 150, 200], gamma=0.1)\n",
    "\n",
    "\n",
    "    best_test_loss = np.inf\n",
    "    best_test_cycle_loss = np.inf\n",
    "    best_test_mse_ab = np.inf\n",
    "    best_test_rmse_ab = np.inf\n",
    "    best_test_mae_ab = np.inf\n",
    "\n",
    "    best_test_r_mse_ab = np.inf\n",
    "    best_test_r_rmse_ab = np.inf\n",
    "    best_test_r_mae_ab = np.inf\n",
    "    best_test_t_mse_ab = np.inf\n",
    "    best_test_t_rmse_ab = np.inf\n",
    "    best_test_t_mae_ab = np.inf\n",
    "\n",
    "    best_test_mse_ba = np.inf\n",
    "    best_test_rmse_ba = np.inf\n",
    "    best_test_mae_ba = np.inf\n",
    "\n",
    "    best_test_r_mse_ba = np.inf\n",
    "    best_test_r_rmse_ba = np.inf\n",
    "    best_test_r_mae_ba = np.inf\n",
    "    best_test_t_mse_ba = np.inf\n",
    "    best_test_t_rmse_ba = np.inf\n",
    "    best_test_t_mae_ba = np.inf\n",
    "\n",
    "    for epoch in range(args.epochs):\n",
    "        scheduler.step()\n",
    "        train_loss, train_cycle_loss, \\\n",
    "        train_mse_ab, train_mae_ab, train_mse_ba, train_mae_ba, train_rotations_ab, train_translations_ab, \\\n",
    "        train_rotations_ab_pred, \\\n",
    "        train_translations_ab_pred, train_rotations_ba, train_translations_ba, train_rotations_ba_pred, \\\n",
    "        train_translations_ba_pred, train_eulers_ab, train_eulers_ba = train_one_epoch(args, net, train_loader, opt)\n",
    "        test_loss, test_cycle_loss, \\\n",
    "        test_mse_ab, test_mae_ab, test_mse_ba, test_mae_ba, test_rotations_ab, test_translations_ab, \\\n",
    "        test_rotations_ab_pred, \\\n",
    "        test_translations_ab_pred, test_rotations_ba, test_translations_ba, test_rotations_ba_pred, \\\n",
    "        test_translations_ba_pred, test_eulers_ab, test_eulers_ba = test_one_epoch(args, net, test_loader)\n",
    "        train_rmse_ab = np.sqrt(train_mse_ab)\n",
    "        test_rmse_ab = np.sqrt(test_mse_ab)\n",
    "\n",
    "        train_rmse_ba = np.sqrt(train_mse_ba)\n",
    "        test_rmse_ba = np.sqrt(test_mse_ba)\n",
    "\n",
    "        train_rotations_ab_pred_euler = npmat2euler(train_rotations_ab_pred)\n",
    "        train_r_mse_ab = np.mean((train_rotations_ab_pred_euler - np.degrees(train_eulers_ab)) ** 2)\n",
    "        train_r_rmse_ab = np.sqrt(train_r_mse_ab)\n",
    "        train_r_mae_ab = np.mean(np.abs(train_rotations_ab_pred_euler - np.degrees(train_eulers_ab)))\n",
    "        train_t_mse_ab = np.mean((train_translations_ab - train_translations_ab_pred) ** 2)\n",
    "        train_t_rmse_ab = np.sqrt(train_t_mse_ab)\n",
    "        train_t_mae_ab = np.mean(np.abs(train_translations_ab - train_translations_ab_pred))\n",
    "\n",
    "        train_rotations_ba_pred_euler = npmat2euler(train_rotations_ba_pred, 'xyz')\n",
    "        train_r_mse_ba = np.mean((train_rotations_ba_pred_euler - np.degrees(train_eulers_ba)) ** 2)\n",
    "        train_r_rmse_ba = np.sqrt(train_r_mse_ba)\n",
    "        train_r_mae_ba = np.mean(np.abs(train_rotations_ba_pred_euler - np.degrees(train_eulers_ba)))\n",
    "        train_t_mse_ba = np.mean((train_translations_ba - train_translations_ba_pred) ** 2)\n",
    "        train_t_rmse_ba = np.sqrt(train_t_mse_ba)\n",
    "        train_t_mae_ba = np.mean(np.abs(train_translations_ba - train_translations_ba_pred))\n",
    "\n",
    "        test_rotations_ab_pred_euler = npmat2euler(test_rotations_ab_pred)\n",
    "        test_r_mse_ab = np.mean((test_rotations_ab_pred_euler - np.degrees(test_eulers_ab)) ** 2)\n",
    "        test_r_rmse_ab = np.sqrt(test_r_mse_ab)\n",
    "        test_r_mae_ab = np.mean(np.abs(test_rotations_ab_pred_euler - np.degrees(test_eulers_ab)))\n",
    "        test_t_mse_ab = np.mean((test_translations_ab - test_translations_ab_pred) ** 2)\n",
    "        test_t_rmse_ab = np.sqrt(test_t_mse_ab)\n",
    "        test_t_mae_ab = np.mean(np.abs(test_translations_ab - test_translations_ab_pred))\n",
    "\n",
    "        test_rotations_ba_pred_euler = npmat2euler(test_rotations_ba_pred, 'xyz')\n",
    "        test_r_mse_ba = np.mean((test_rotations_ba_pred_euler - np.degrees(test_eulers_ba)) ** 2)\n",
    "        test_r_rmse_ba = np.sqrt(test_r_mse_ba)\n",
    "        test_r_mae_ba = np.mean(np.abs(test_rotations_ba_pred_euler - np.degrees(test_eulers_ba)))\n",
    "        test_t_mse_ba = np.mean((test_translations_ba - test_translations_ba_pred) ** 2)\n",
    "        test_t_rmse_ba = np.sqrt(test_t_mse_ba)\n",
    "        test_t_mae_ba = np.mean(np.abs(test_translations_ba - test_translations_ba_pred))\n",
    "\n",
    "        if best_test_loss >= test_loss:\n",
    "            best_test_loss = test_loss\n",
    "            best_test_cycle_loss = test_cycle_loss\n",
    "\n",
    "            best_test_mse_ab = test_mse_ab\n",
    "            best_test_rmse_ab = test_rmse_ab\n",
    "            best_test_mae_ab = test_mae_ab\n",
    "\n",
    "            best_test_r_mse_ab = test_r_mse_ab\n",
    "            best_test_r_rmse_ab = test_r_rmse_ab\n",
    "            best_test_r_mae_ab = test_r_mae_ab\n",
    "\n",
    "            best_test_t_mse_ab = test_t_mse_ab\n",
    "            best_test_t_rmse_ab = test_t_rmse_ab\n",
    "            best_test_t_mae_ab = test_t_mae_ab\n",
    "\n",
    "            best_test_mse_ba = test_mse_ba\n",
    "            best_test_rmse_ba = test_rmse_ba\n",
    "            best_test_mae_ba = test_mae_ba\n",
    "\n",
    "            best_test_r_mse_ba = test_r_mse_ba\n",
    "            best_test_r_rmse_ba = test_r_rmse_ba\n",
    "            best_test_r_mae_ba = test_r_mae_ba\n",
    "\n",
    "            best_test_t_mse_ba = test_t_mse_ba\n",
    "            best_test_t_rmse_ba = test_t_rmse_ba\n",
    "            best_test_t_mae_ba = test_t_mae_ba\n",
    "\n",
    "            if torch.cuda.device_count() > 1:\n",
    "                torch.save(net.module.state_dict(), 'checkpoints/%s/models/model.best.t7' % args.exp_name)\n",
    "            else:\n",
    "                torch.save(net.state_dict(), 'checkpoints/%s/models/model.best.t7' % args.exp_name)\n",
    "\n",
    "        textio.cprint('==TRAIN==')\n",
    "        textio.cprint('A--------->B')\n",
    "        textio.cprint('EPOCH:: %d, Loss: %f, Cycle Loss:, %f, MSE: %f, RMSE: %f, MAE: %f, rot_MSE: %f, rot_RMSE: %f, '\n",
    "                      'rot_MAE: %f, trans_MSE: %f, trans_RMSE: %f, trans_MAE: %f'\n",
    "                      % (epoch, train_loss, train_cycle_loss, train_mse_ab, train_rmse_ab, train_mae_ab, train_r_mse_ab,\n",
    "                         train_r_rmse_ab, train_r_mae_ab, train_t_mse_ab, train_t_rmse_ab, train_t_mae_ab))\n",
    "        textio.cprint('B--------->A')\n",
    "        textio.cprint('EPOCH:: %d, Loss: %f, MSE: %f, RMSE: %f, MAE: %f, rot_MSE: %f, rot_RMSE: %f, '\n",
    "                      'rot_MAE: %f, trans_MSE: %f, trans_RMSE: %f, trans_MAE: %f'\n",
    "                      % (epoch, train_loss, train_mse_ba, train_rmse_ba, train_mae_ba, train_r_mse_ba, train_r_rmse_ba,\n",
    "                         train_r_mae_ba, train_t_mse_ba, train_t_rmse_ba, train_t_mae_ba))\n",
    "\n",
    "        textio.cprint('==TEST==')\n",
    "        textio.cprint('A--------->B')\n",
    "        textio.cprint('EPOCH:: %d, Loss: %f, Cycle Loss: %f, MSE: %f, RMSE: %f, MAE: %f, rot_MSE: %f, rot_RMSE: %f, '\n",
    "                      'rot_MAE: %f, trans_MSE: %f, trans_RMSE: %f, trans_MAE: %f'\n",
    "                      % (epoch, test_loss, test_cycle_loss, test_mse_ab, test_rmse_ab, test_mae_ab, test_r_mse_ab,\n",
    "                         test_r_rmse_ab, test_r_mae_ab, test_t_mse_ab, test_t_rmse_ab, test_t_mae_ab))\n",
    "        textio.cprint('B--------->A')\n",
    "        textio.cprint('EPOCH:: %d, Loss: %f, MSE: %f, RMSE: %f, MAE: %f, rot_MSE: %f, rot_RMSE: %f, '\n",
    "                      'rot_MAE: %f, trans_MSE: %f, trans_RMSE: %f, trans_MAE: %f'\n",
    "                      % (epoch, test_loss, test_mse_ba, test_rmse_ba, test_mae_ba, test_r_mse_ba, test_r_rmse_ba,\n",
    "                         test_r_mae_ba, test_t_mse_ba, test_t_rmse_ba, test_t_mae_ba))\n",
    "\n",
    "        textio.cprint('==BEST TEST==')\n",
    "        textio.cprint('A--------->B')\n",
    "        textio.cprint('EPOCH:: %d, Loss: %f, Cycle Loss: %f, MSE: %f, RMSE: %f, MAE: %f, rot_MSE: %f, rot_RMSE: %f, '\n",
    "                      'rot_MAE: %f, trans_MSE: %f, trans_RMSE: %f, trans_MAE: %f'\n",
    "                      % (epoch, best_test_loss, best_test_cycle_loss, best_test_mse_ab, best_test_rmse_ab,\n",
    "                         best_test_mae_ab, best_test_r_mse_ab, best_test_r_rmse_ab,\n",
    "                         best_test_r_mae_ab, best_test_t_mse_ab, best_test_t_rmse_ab, best_test_t_mae_ab))\n",
    "        textio.cprint('B--------->A')\n",
    "        textio.cprint('EPOCH:: %d, Loss: %f, MSE: %f, RMSE: %f, MAE: %f, rot_MSE: %f, rot_RMSE: %f, '\n",
    "                      'rot_MAE: %f, trans_MSE: %f, trans_RMSE: %f, trans_MAE: %f'\n",
    "                      % (epoch, best_test_loss, best_test_mse_ba, best_test_rmse_ba, best_test_mae_ba,\n",
    "                         best_test_r_mse_ba, best_test_r_rmse_ba,\n",
    "                         best_test_r_mae_ba, best_test_t_mse_ba, best_test_t_rmse_ba, best_test_t_mae_ba))\n",
    "\n",
    "        boardio.add_scalar('A->B/train/loss', train_loss, epoch)\n",
    "        boardio.add_scalar('A->B/train/MSE', train_mse_ab, epoch)\n",
    "        boardio.add_scalar('A->B/train/RMSE', train_rmse_ab, epoch)\n",
    "        boardio.add_scalar('A->B/train/MAE', train_mae_ab, epoch)\n",
    "        boardio.add_scalar('A->B/train/rotation/MSE', train_r_mse_ab, epoch)\n",
    "        boardio.add_scalar('A->B/train/rotation/RMSE', train_r_rmse_ab, epoch)\n",
    "        boardio.add_scalar('A->B/train/rotation/MAE', train_r_mae_ab, epoch)\n",
    "        boardio.add_scalar('A->B/train/translation/MSE', train_t_mse_ab, epoch)\n",
    "        boardio.add_scalar('A->B/train/translation/RMSE', train_t_rmse_ab, epoch)\n",
    "        boardio.add_scalar('A->B/train/translation/MAE', train_t_mae_ab, epoch)\n",
    "\n",
    "        boardio.add_scalar('B->A/train/loss', train_loss, epoch)\n",
    "        boardio.add_scalar('B->A/train/MSE', train_mse_ba, epoch)\n",
    "        boardio.add_scalar('B->A/train/RMSE', train_rmse_ba, epoch)\n",
    "        boardio.add_scalar('B->A/train/MAE', train_mae_ba, epoch)\n",
    "        boardio.add_scalar('B->A/train/rotation/MSE', train_r_mse_ba, epoch)\n",
    "        boardio.add_scalar('B->A/train/rotation/RMSE', train_r_rmse_ba, epoch)\n",
    "        boardio.add_scalar('B->A/train/rotation/MAE', train_r_mae_ba, epoch)\n",
    "        boardio.add_scalar('B->A/train/translation/MSE', train_t_mse_ba, epoch)\n",
    "        boardio.add_scalar('B->A/train/translation/RMSE', train_t_rmse_ba, epoch)\n",
    "        boardio.add_scalar('B->A/train/translation/MAE', train_t_mae_ba, epoch)\n",
    "\n",
    "        ############TEST\n",
    "        boardio.add_scalar('A->B/test/loss', test_loss, epoch)\n",
    "        boardio.add_scalar('A->B/test/MSE', test_mse_ab, epoch)\n",
    "        boardio.add_scalar('A->B/test/RMSE', test_rmse_ab, epoch)\n",
    "        boardio.add_scalar('A->B/test/MAE', test_mae_ab, epoch)\n",
    "        boardio.add_scalar('A->B/test/rotation/MSE', test_r_mse_ab, epoch)\n",
    "        boardio.add_scalar('A->B/test/rotation/RMSE', test_r_rmse_ab, epoch)\n",
    "        boardio.add_scalar('A->B/test/rotation/MAE', test_r_mae_ab, epoch)\n",
    "        boardio.add_scalar('A->B/test/translation/MSE', test_t_mse_ab, epoch)\n",
    "        boardio.add_scalar('A->B/test/translation/RMSE', test_t_rmse_ab, epoch)\n",
    "        boardio.add_scalar('A->B/test/translation/MAE', test_t_mae_ab, epoch)\n",
    "\n",
    "        boardio.add_scalar('B->A/test/loss', test_loss, epoch)\n",
    "        boardio.add_scalar('B->A/test/MSE', test_mse_ba, epoch)\n",
    "        boardio.add_scalar('B->A/test/RMSE', test_rmse_ba, epoch)\n",
    "        boardio.add_scalar('B->A/test/MAE', test_mae_ba, epoch)\n",
    "        boardio.add_scalar('B->A/test/rotation/MSE', test_r_mse_ba, epoch)\n",
    "        boardio.add_scalar('B->A/test/rotation/RMSE', test_r_rmse_ba, epoch)\n",
    "        boardio.add_scalar('B->A/test/rotation/MAE', test_r_mae_ba, epoch)\n",
    "        boardio.add_scalar('B->A/test/translation/MSE', test_t_mse_ba, epoch)\n",
    "        boardio.add_scalar('B->A/test/translation/RMSE', test_t_rmse_ba, epoch)\n",
    "        boardio.add_scalar('B->A/test/translation/MAE', test_t_mae_ba, epoch)\n",
    "\n",
    "        ############BEST TEST\n",
    "        boardio.add_scalar('A->B/best_test/loss', best_test_loss, epoch)\n",
    "        boardio.add_scalar('A->B/best_test/MSE', best_test_mse_ab, epoch)\n",
    "        boardio.add_scalar('A->B/best_test/RMSE', best_test_rmse_ab, epoch)\n",
    "        boardio.add_scalar('A->B/best_test/MAE', best_test_mae_ab, epoch)\n",
    "        boardio.add_scalar('A->B/best_test/rotation/MSE', best_test_r_mse_ab, epoch)\n",
    "        boardio.add_scalar('A->B/best_test/rotation/RMSE', best_test_r_rmse_ab, epoch)\n",
    "        boardio.add_scalar('A->B/best_test/rotation/MAE', best_test_r_mae_ab, epoch)\n",
    "        boardio.add_scalar('A->B/best_test/translation/MSE', best_test_t_mse_ab, epoch)\n",
    "        boardio.add_scalar('A->B/best_test/translation/RMSE', best_test_t_rmse_ab, epoch)\n",
    "        boardio.add_scalar('A->B/best_test/translation/MAE', best_test_t_mae_ab, epoch)\n",
    "\n",
    "        boardio.add_scalar('B->A/best_test/loss', best_test_loss, epoch)\n",
    "        boardio.add_scalar('B->A/best_test/MSE', best_test_mse_ba, epoch)\n",
    "        boardio.add_scalar('B->A/best_test/RMSE', best_test_rmse_ba, epoch)\n",
    "        boardio.add_scalar('B->A/best_test/MAE', best_test_mae_ba, epoch)\n",
    "        boardio.add_scalar('B->A/best_test/rotation/MSE', best_test_r_mse_ba, epoch)\n",
    "        boardio.add_scalar('B->A/best_test/rotation/RMSE', best_test_r_rmse_ba, epoch)\n",
    "        boardio.add_scalar('B->A/best_test/rotation/MAE', best_test_r_mae_ba, epoch)\n",
    "        boardio.add_scalar('B->A/best_test/translation/MSE', best_test_t_mse_ba, epoch)\n",
    "        boardio.add_scalar('B->A/best_test/translation/RMSE', best_test_t_rmse_ba, epoch)\n",
    "        boardio.add_scalar('B->A/best_test/translation/MAE', best_test_t_mae_ba, epoch)\n",
    "\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            torch.save(net.module.state_dict(), 'checkpoints/%s/models/model.%d.t7' % (args.exp_name, epoch))\n",
    "        else:\n",
    "            torch.save(net.state_dict(), 'checkpoints/%s/models/model.%d.t7' % (args.exp_name, epoch))\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_one_epoch(args, net, test_loader):\n",
    "    net.eval()\n",
    "    mse_ab = 0\n",
    "    mae_ab = 0\n",
    "    mse_ba = 0\n",
    "    mae_ba = 0\n",
    "\n",
    "    total_loss = 0\n",
    "    total_cycle_loss = 0\n",
    "    num_examples = 0\n",
    "    rotations_ab = []\n",
    "    translations_ab = []\n",
    "    rotations_ab_pred = []\n",
    "    translations_ab_pred = []\n",
    "\n",
    "    rotations_ba = []\n",
    "    translations_ba = []\n",
    "    rotations_ba_pred = []\n",
    "    translations_ba_pred = []\n",
    "\n",
    "    eulers_ab = []\n",
    "    eulers_ba = []\n",
    "\n",
    "    for src, target, rotation_ab, translation_ab, rotation_ba, translation_ba, euler_ab, euler_ba in tqdm(test_loader):\n",
    "        src = src.cuda()\n",
    "        target = target.cuda()\n",
    "        rotation_ab = rotation_ab.cuda()\n",
    "        translation_ab = translation_ab.cuda()\n",
    "        rotation_ba = rotation_ba.cuda()\n",
    "        translation_ba = translation_ba.cuda()\n",
    "\n",
    "        batch_size = src.size(0)\n",
    "        num_examples += batch_size\n",
    "        rotation_ab_pred, translation_ab_pred, rotation_ba_pred, translation_ba_pred = net(src, target)\n",
    "\n",
    "        ## save rotation and translation\n",
    "        rotations_ab.append(rotation_ab.detach().cpu().numpy())\n",
    "        translations_ab.append(translation_ab.detach().cpu().numpy())\n",
    "        rotations_ab_pred.append(rotation_ab_pred.detach().cpu().numpy())\n",
    "        translations_ab_pred.append(translation_ab_pred.detach().cpu().numpy())\n",
    "        eulers_ab.append(euler_ab.numpy())\n",
    "        ##\n",
    "        rotations_ba.append(rotation_ba.detach().cpu().numpy())\n",
    "        translations_ba.append(translation_ba.detach().cpu().numpy())\n",
    "        rotations_ba_pred.append(rotation_ba_pred.detach().cpu().numpy())\n",
    "        translations_ba_pred.append(translation_ba_pred.detach().cpu().numpy())\n",
    "        eulers_ba.append(euler_ba.numpy())\n",
    "\n",
    "        transformed_src = transform_point_cloud(src, rotation_ab_pred, translation_ab_pred)\n",
    "\n",
    "        transformed_target = transform_point_cloud(target, rotation_ba_pred, translation_ba_pred)\n",
    "\n",
    "        ###########################\n",
    "        identity = torch.eye(3).cuda().unsqueeze(0).repeat(batch_size, 1, 1)\n",
    "        loss = F.mse_loss(torch.matmul(rotation_ab_pred.transpose(2, 1), rotation_ab), identity) \\\n",
    "               + F.mse_loss(translation_ab_pred, translation_ab)\n",
    "        if args.cycle:\n",
    "            rotation_loss = F.mse_loss(torch.matmul(rotation_ba_pred, rotation_ab_pred), identity.clone())\n",
    "            translation_loss = torch.mean((torch.matmul(rotation_ba_pred.transpose(2, 1),\n",
    "                                                        translation_ab_pred.view(batch_size, 3, 1)).view(batch_size, 3)\n",
    "                                           + translation_ba_pred) ** 2, dim=[0, 1])\n",
    "            cycle_loss = rotation_loss + translation_loss\n",
    "\n",
    "            loss = loss + cycle_loss * 0.1\n",
    "\n",
    "        total_loss += loss.item() * batch_size\n",
    "\n",
    "        if args.cycle:\n",
    "            total_cycle_loss = total_cycle_loss + cycle_loss.item() * 0.1 * batch_size\n",
    "\n",
    "        mse_ab += torch.mean((transformed_src - target) ** 2, dim=[0, 1, 2]).item() * batch_size\n",
    "        mae_ab += torch.mean(torch.abs(transformed_src - target), dim=[0, 1, 2]).item() * batch_size\n",
    "\n",
    "        mse_ba += torch.mean((transformed_target - src) ** 2, dim=[0, 1, 2]).item() * batch_size\n",
    "        mae_ba += torch.mean(torch.abs(transformed_target - src), dim=[0, 1, 2]).item() * batch_size\n",
    "\n",
    "    rotations_ab = np.concatenate(rotations_ab, axis=0)\n",
    "    translations_ab = np.concatenate(translations_ab, axis=0)\n",
    "    rotations_ab_pred = np.concatenate(rotations_ab_pred, axis=0)\n",
    "    translations_ab_pred = np.concatenate(translations_ab_pred, axis=0)\n",
    "\n",
    "    rotations_ba = np.concatenate(rotations_ba, axis=0)\n",
    "    translations_ba = np.concatenate(translations_ba, axis=0)\n",
    "    rotations_ba_pred = np.concatenate(rotations_ba_pred, axis=0)\n",
    "    translations_ba_pred = np.concatenate(translations_ba_pred, axis=0)\n",
    "\n",
    "    eulers_ab = np.concatenate(eulers_ab, axis=0)\n",
    "    eulers_ba = np.concatenate(eulers_ba, axis=0)\n",
    "\n",
    "    return total_loss * 1.0 / num_examples, total_cycle_loss / num_examples, \\\n",
    "           mse_ab * 1.0 / num_examples, mae_ab * 1.0 / num_examples, \\\n",
    "           mse_ba * 1.0 / num_examples, mae_ba * 1.0 / num_examples, rotations_ab, \\\n",
    "           translations_ab, rotations_ab_pred, translations_ab_pred, rotations_ba, \\\n",
    "           translations_ba, rotations_ba_pred, translations_ba_pred, eulers_ab, eulers_ba\n",
    "\n",
    "\n",
    "def test(args, net, test_loader, boardio, textio):\n",
    "\n",
    "    test_loss, test_cycle_loss, \\\n",
    "    test_mse_ab, test_mae_ab, test_mse_ba, test_mae_ba, test_rotations_ab, test_translations_ab, \\\n",
    "    test_rotations_ab_pred, \\\n",
    "    test_translations_ab_pred, test_rotations_ba, test_translations_ba, test_rotations_ba_pred, \\\n",
    "    test_translations_ba_pred, test_eulers_ab, test_eulers_ba = test_one_epoch(args, net, test_loader)\n",
    "    test_rmse_ab = np.sqrt(test_mse_ab)\n",
    "    test_rmse_ba = np.sqrt(test_mse_ba)\n",
    "\n",
    "    test_rotations_ab_pred_euler = npmat2euler(test_rotations_ab_pred)\n",
    "    test_r_mse_ab = np.mean((test_rotations_ab_pred_euler - np.degrees(test_eulers_ab)) ** 2)\n",
    "    test_r_rmse_ab = np.sqrt(test_r_mse_ab)\n",
    "    test_r_mae_ab = np.mean(np.abs(test_rotations_ab_pred_euler - np.degrees(test_eulers_ab)))\n",
    "    test_t_mse_ab = np.mean((test_translations_ab - test_translations_ab_pred) ** 2)\n",
    "    test_t_rmse_ab = np.sqrt(test_t_mse_ab)\n",
    "    test_t_mae_ab = np.mean(np.abs(test_translations_ab - test_translations_ab_pred))\n",
    "\n",
    "    test_rotations_ba_pred_euler = npmat2euler(test_rotations_ba_pred, 'xyz')\n",
    "    test_r_mse_ba = np.mean((test_rotations_ba_pred_euler - np.degrees(test_eulers_ba)) ** 2)\n",
    "    test_r_rmse_ba = np.sqrt(test_r_mse_ba)\n",
    "    test_r_mae_ba = np.mean(np.abs(test_rotations_ba_pred_euler - np.degrees(test_eulers_ba)))\n",
    "    test_t_mse_ba = np.mean((test_translations_ba - test_translations_ba_pred) ** 2)\n",
    "    test_t_rmse_ba = np.sqrt(test_t_mse_ba)\n",
    "    test_t_mae_ba = np.mean(np.abs(test_translations_ba - test_translations_ba_pred))\n",
    "\n",
    "    textio.cprint('==FINAL TEST==')\n",
    "    textio.cprint('A--------->B')\n",
    "    textio.cprint('EPOCH:: %d, Loss: %f, Cycle Loss: %f, MSE: %f, RMSE: %f, MAE: %f, rot_MSE: %f, rot_RMSE: %f, '\n",
    "                  'rot_MAE: %f, trans_MSE: %f, trans_RMSE: %f, trans_MAE: %f'\n",
    "                  % (-1, test_loss, test_cycle_loss, test_mse_ab, test_rmse_ab, test_mae_ab,\n",
    "                     test_r_mse_ab, test_r_rmse_ab,\n",
    "                     test_r_mae_ab, test_t_mse_ab, test_t_rmse_ab, test_t_mae_ab))\n",
    "    textio.cprint('B--------->A')\n",
    "    textio.cprint('EPOCH:: %d, Loss: %f, MSE: %f, RMSE: %f, MAE: %f, rot_MSE: %f, rot_RMSE: %f, '\n",
    "                  'rot_MAE: %f, trans_MSE: %f, trans_RMSE: %f, trans_MAE: %f'\n",
    "                  % (-1, test_loss, test_mse_ba, test_rmse_ba, test_mae_ba, test_r_mse_ba, test_r_rmse_ba,\n",
    "                     test_r_mae_ba, test_t_mse_ba, test_t_rmse_ba, test_t_mae_ba))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76800, 3)\n",
      "(76800, 3)\n",
      "{'model_path': 'dcp-master/pretrained/dcp_v1.t7', 'exp_name': 'exp', 'model': 'dcp', 'emb_nn': 'dgcnn', 'pointer': 'identity', 'head': 'svd', 'eval': True, 'emb_dims': 512, 'cycle': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "need at least one array to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/hang/Desktop/Master/S2/ML 3D Geometry/project/ml3d/test.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 41>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hang/Desktop/Master/S2/ML%203D%20Geometry/project/ml3d/test.ipynb#ch0000007?line=38'>39</a>\u001b[0m textio\u001b[39m.\u001b[39mcprint(\u001b[39mstr\u001b[39m(args))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hang/Desktop/Master/S2/ML%203D%20Geometry/project/ml3d/test.ipynb#ch0000007?line=39'>40</a>\u001b[0m net \u001b[39m=\u001b[39m DCP(args)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/hang/Desktop/Master/S2/ML%203D%20Geometry/project/ml3d/test.ipynb#ch0000007?line=40'>41</a>\u001b[0m test(args, net, test_loader, boardio, textio)\n",
      "\u001b[1;32m/Users/hang/Desktop/Master/S2/ML 3D Geometry/project/ml3d/test.ipynb Cell 6'\u001b[0m in \u001b[0;36mtest\u001b[0;34m(args, net, test_loader, boardio, textio)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hang/Desktop/Master/S2/ML%203D%20Geometry/project/ml3d/test.ipynb#ch0000005?line=96'>97</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtest\u001b[39m(args, net, test_loader, boardio, textio):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hang/Desktop/Master/S2/ML%203D%20Geometry/project/ml3d/test.ipynb#ch0000005?line=98'>99</a>\u001b[0m     test_loss, test_cycle_loss, \\\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/hang/Desktop/Master/S2/ML%203D%20Geometry/project/ml3d/test.ipynb#ch0000005?line=99'>100</a>\u001b[0m     test_mse_ab, test_mae_ab, test_mse_ba, test_mae_ba, test_rotations_ab, test_translations_ab, \\\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/hang/Desktop/Master/S2/ML%203D%20Geometry/project/ml3d/test.ipynb#ch0000005?line=100'>101</a>\u001b[0m     test_rotations_ab_pred, \\\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/hang/Desktop/Master/S2/ML%203D%20Geometry/project/ml3d/test.ipynb#ch0000005?line=101'>102</a>\u001b[0m     test_translations_ab_pred, test_rotations_ba, test_translations_ba, test_rotations_ba_pred, \\\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/hang/Desktop/Master/S2/ML%203D%20Geometry/project/ml3d/test.ipynb#ch0000005?line=102'>103</a>\u001b[0m     test_translations_ba_pred, test_eulers_ab, test_eulers_ba \u001b[39m=\u001b[39m test_one_epoch(args, net, test_loader)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/hang/Desktop/Master/S2/ML%203D%20Geometry/project/ml3d/test.ipynb#ch0000005?line=103'>104</a>\u001b[0m     test_rmse_ab \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqrt(test_mse_ab)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/hang/Desktop/Master/S2/ML%203D%20Geometry/project/ml3d/test.ipynb#ch0000005?line=104'>105</a>\u001b[0m     test_rmse_ba \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqrt(test_mse_ba)\n",
      "\u001b[1;32m/Users/hang/Desktop/Master/S2/ML 3D Geometry/project/ml3d/test.ipynb Cell 6'\u001b[0m in \u001b[0;36mtest_one_epoch\u001b[0;34m(args, net, test_loader)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hang/Desktop/Master/S2/ML%203D%20Geometry/project/ml3d/test.ipynb#ch0000005?line=73'>74</a>\u001b[0m     mse_ba \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmean((transformed_target \u001b[39m-\u001b[39m src) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m, dim\u001b[39m=\u001b[39m[\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m])\u001b[39m.\u001b[39mitem() \u001b[39m*\u001b[39m batch_size\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hang/Desktop/Master/S2/ML%203D%20Geometry/project/ml3d/test.ipynb#ch0000005?line=74'>75</a>\u001b[0m     mae_ba \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmean(torch\u001b[39m.\u001b[39mabs(transformed_target \u001b[39m-\u001b[39m src), dim\u001b[39m=\u001b[39m[\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m])\u001b[39m.\u001b[39mitem() \u001b[39m*\u001b[39m batch_size\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/hang/Desktop/Master/S2/ML%203D%20Geometry/project/ml3d/test.ipynb#ch0000005?line=76'>77</a>\u001b[0m rotations_ab \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mconcatenate(rotations_ab, axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hang/Desktop/Master/S2/ML%203D%20Geometry/project/ml3d/test.ipynb#ch0000005?line=77'>78</a>\u001b[0m translations_ab \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate(translations_ab, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hang/Desktop/Master/S2/ML%203D%20Geometry/project/ml3d/test.ipynb#ch0000005?line=78'>79</a>\u001b[0m rotations_ab_pred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate(rotations_ab_pred, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: need at least one array to concatenate"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "pcd1 = o3d.io.read_point_cloud(\"test.pcd\")\n",
    "pcd2 = o3d.io.read_point_cloud(\"test1.pcd\")\n",
    "\n",
    "points1 = np.array(pcd1.points) #转为矩阵\n",
    "points2 = np.array(pcd2.points)\n",
    "points = points1.T, points2.T\n",
    "print(points1.shape)\n",
    "print(points2.shape)\n",
    "\n",
    "# define the dataloader\n",
    "# pc = ModelNet40(num_points=1024, partition='test', gaussian_noise=False, unseen=False, factor=4)\n",
    "# src, target, rotation_ab, translation_ab, rotation_ba, translation_ba, euler_ab, euler_ba = pc[6]\n",
    "\n",
    "args = {\"model_path\": 'dcp-master/pretrained/dcp_v1.t7',\n",
    "        \"exp_name\":\"dcp_v1\",\n",
    "         \"model\":\"dcp\", \n",
    "         \"emb_nn\":\"dgcnn\", \n",
    "         \"pointer\":\"identity\", \n",
    "         \"head\":\"svd\", \n",
    "         \"eval\": True,\n",
    "         \"exp_name\":\"exp\",\n",
    "         'emb_dims': 512,\n",
    "         'cycle': False,\n",
    "        }\n",
    "\n",
    "test_loader = DataLoader(\n",
    "            points,\n",
    "            batch_size=32, shuffle=True, drop_last=True)\n",
    "\n",
    "# test_loader = DataLoader(\n",
    "#             ModelNet40(num_points=args.num_points, partition='test', gaussian_noise=args.gaussian_noise,\n",
    "#                        unseen=args.unseen, factor=args.factor),\n",
    "#             batch_size=args.test_batch_size, shuffle=False, drop_last=False)\n",
    "boardio = SummaryWriter(log_dir='checkpoints/' + args['exp_name'])\n",
    "textio = IOStream('checkpoints/' + args['exp_name'] + '/run.log')\n",
    "textio.cprint(str(args))\n",
    "net = DCP(args)\n",
    "test(args, net, test_loader, boardio, textio)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e7dab729d554d01ab4f2b736f4bcc00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import k3d\n",
    "\n",
    "def visualize_pointcloud(point_cloud1, point_size, point_cloud2=None, flip_axes=False, name='point_cloud', R=None, t=None):\n",
    "    plot = k3d.plot(name=name, grid_visible=False, grid=(-0.55, -0.55, -0.55, 0.55, 0.55, 0.55))\n",
    "    # if flip_axes:\n",
    "    #     point_cloud[:, 2] = point_cloud[:, 2] * -1\n",
    "    #     point_cloud[:, [0, 1, 2]] = point_cloud[:, [0, 2, 1]]\n",
    "    # t_broadcast = np.broadcast_to(t[:, np.newaxis], (3, point_cloud1.X.shape[0]))\n",
    "    # point_cloud1 = (R @ point_cloud1.X.T + t_broadcast).T\n",
    "    plt_points1 = k3d.points(positions=point_cloud1.astype(np.float32), point_size=point_size, color=0xd0d0d0)\n",
    "    plot += plt_points1\n",
    "    plt_points1.shader = '3d'\n",
    "    if point_cloud2 is not None:\n",
    "        plt_points2 = k3d.points(positions=point_cloud2.astype(np.float32), point_size=point_size, color=0x0dd00d)\n",
    "        plot += plt_points2\n",
    "        plt_points2.shader = '3d'\n",
    "    plot.display()\n",
    "\n",
    "visualize_pointcloud(points, .1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('python39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "beda123ca6d46414026d3c59f732de1f5fb19d6ba2f32753cc4223591eed0a9d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
