{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCP Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import gc\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "import sys\n",
    "sys.path.append(\"dcp-master\")\n",
    "from data import ModelNet40\n",
    "from model import DCP\n",
    "from util import transform_point_cloud, npmat2euler\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Part of the code is referred from: https://github.com/floodsung/LearningToCompare_FSL\n",
    "\n",
    "class IOStream:\n",
    "    def __init__(self, path):\n",
    "        self.f = open(path, 'a')\n",
    "\n",
    "    def cprint(self, text):\n",
    "        print(text)\n",
    "        self.f.write(text + '\\n')\n",
    "        self.f.flush()\n",
    "\n",
    "    def close(self):\n",
    "        self.f.close()\n",
    "\n",
    "\n",
    "def _init_(args):\n",
    "    if not os.path.exists('checkpoints'):\n",
    "        os.makedirs('checkpoints')\n",
    "    if not os.path.exists('checkpoints/' + args.exp_name):\n",
    "        os.makedirs('checkpoints/' + args.exp_name)\n",
    "    if not os.path.exists('checkpoints/' + args.exp_name + '/' + 'models'):\n",
    "        os.makedirs('checkpoints/' + args.exp_name + '/' + 'models')\n",
    "    os.system('cp main.py checkpoints' + '/' + args.exp_name + '/' + 'main.py.backup')\n",
    "    os.system('cp model.py checkpoints' + '/' + args.exp_name + '/' + 'model.py.backup')\n",
    "    os.system('cp data.py checkpoints' + '/' + args.exp_name + '/' + 'data.py.backup')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(args, net, train_loader, opt):\n",
    "    net.train()\n",
    "\n",
    "    mse_ab = 0\n",
    "    mae_ab = 0\n",
    "    mse_ba = 0\n",
    "    mae_ba = 0\n",
    "\n",
    "    total_loss = 0\n",
    "    total_cycle_loss = 0\n",
    "    num_examples = 0\n",
    "    rotations_ab = []\n",
    "    translations_ab = []\n",
    "    rotations_ab_pred = []\n",
    "    translations_ab_pred = []\n",
    "\n",
    "    rotations_ba = []\n",
    "    translations_ba = []\n",
    "    rotations_ba_pred = []\n",
    "    translations_ba_pred = []\n",
    "\n",
    "    eulers_ab = []\n",
    "    eulers_ba = []\n",
    "\n",
    "    for src, target, rotation_ab, translation_ab, rotation_ba, translation_ba, euler_ab, euler_ba in tqdm(train_loader):\n",
    "        src = src.cuda()\n",
    "        target = target.cuda()\n",
    "        rotation_ab = rotation_ab.cuda()\n",
    "        translation_ab = translation_ab.cuda()\n",
    "        rotation_ba = rotation_ba.cuda()\n",
    "        translation_ba = translation_ba.cuda()\n",
    "\n",
    "        batch_size = src.size(0)\n",
    "        opt.zero_grad()\n",
    "        num_examples += batch_size\n",
    "        rotation_ab_pred, translation_ab_pred, rotation_ba_pred, translation_ba_pred = net(src, target)\n",
    "\n",
    "        ## save rotation and translation\n",
    "        rotations_ab.append(rotation_ab.detach().cpu().numpy())\n",
    "        translations_ab.append(translation_ab.detach().cpu().numpy())\n",
    "        rotations_ab_pred.append(rotation_ab_pred.detach().cpu().numpy())\n",
    "        translations_ab_pred.append(translation_ab_pred.detach().cpu().numpy())\n",
    "        eulers_ab.append(euler_ab.numpy())\n",
    "        ##\n",
    "        rotations_ba.append(rotation_ba.detach().cpu().numpy())\n",
    "        translations_ba.append(translation_ba.detach().cpu().numpy())\n",
    "        rotations_ba_pred.append(rotation_ba_pred.detach().cpu().numpy())\n",
    "        translations_ba_pred.append(translation_ba_pred.detach().cpu().numpy())\n",
    "        eulers_ba.append(euler_ba.numpy())\n",
    "\n",
    "        transformed_src = transform_point_cloud(src, rotation_ab_pred, translation_ab_pred)\n",
    "\n",
    "        transformed_target = transform_point_cloud(target, rotation_ba_pred, translation_ba_pred)\n",
    "        ###########################\n",
    "        identity = torch.eye(3).cuda().unsqueeze(0).repeat(batch_size, 1, 1)\n",
    "        loss = F.mse_loss(torch.matmul(rotation_ab_pred.transpose(2, 1), rotation_ab), identity) \\\n",
    "               + F.mse_loss(translation_ab_pred, translation_ab)\n",
    "        if args.cycle:\n",
    "            rotation_loss = F.mse_loss(torch.matmul(rotation_ba_pred, rotation_ab_pred), identity.clone())\n",
    "            translation_loss = torch.mean((torch.matmul(rotation_ba_pred.transpose(2, 1),\n",
    "                                                        translation_ab_pred.view(batch_size, 3, 1)).view(batch_size, 3)\n",
    "                                           + translation_ba_pred) ** 2, dim=[0, 1])\n",
    "            cycle_loss = rotation_loss + translation_loss\n",
    "\n",
    "            loss = loss + cycle_loss * 0.1\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total_loss += loss.item() * batch_size\n",
    "\n",
    "        if args.cycle:\n",
    "            total_cycle_loss = total_cycle_loss + cycle_loss.item() * 0.1 * batch_size\n",
    "\n",
    "        mse_ab += torch.mean((transformed_src - target) ** 2, dim=[0, 1, 2]).item() * batch_size\n",
    "        mae_ab += torch.mean(torch.abs(transformed_src - target), dim=[0, 1, 2]).item() * batch_size\n",
    "\n",
    "        mse_ba += torch.mean((transformed_target - src) ** 2, dim=[0, 1, 2]).item() * batch_size\n",
    "        mae_ba += torch.mean(torch.abs(transformed_target - src), dim=[0, 1, 2]).item() * batch_size\n",
    "\n",
    "    rotations_ab = np.concatenate(rotations_ab, axis=0)\n",
    "    translations_ab = np.concatenate(translations_ab, axis=0)\n",
    "    rotations_ab_pred = np.concatenate(rotations_ab_pred, axis=0)\n",
    "    translations_ab_pred = np.concatenate(translations_ab_pred, axis=0)\n",
    "\n",
    "    rotations_ba = np.concatenate(rotations_ba, axis=0)\n",
    "    translations_ba = np.concatenate(translations_ba, axis=0)\n",
    "    rotations_ba_pred = np.concatenate(rotations_ba_pred, axis=0)\n",
    "    translations_ba_pred = np.concatenate(translations_ba_pred, axis=0)\n",
    "\n",
    "    eulers_ab = np.concatenate(eulers_ab, axis=0)\n",
    "    eulers_ba = np.concatenate(eulers_ba, axis=0)\n",
    "\n",
    "    return total_loss * 1.0 / num_examples, total_cycle_loss / num_examples, \\\n",
    "           mse_ab * 1.0 / num_examples, mae_ab * 1.0 / num_examples, \\\n",
    "           mse_ba * 1.0 / num_examples, mae_ba * 1.0 / num_examples, rotations_ab, \\\n",
    "           translations_ab, rotations_ab_pred, translations_ab_pred, rotations_ba, \\\n",
    "           translations_ba, rotations_ba_pred, translations_ba_pred, eulers_ab, eulers_ba\n",
    "\n",
    "def train(args, net, train_loader, test_loader, boardio, textio):\n",
    "    if args.use_sgd:\n",
    "        print(\"Use SGD\")\n",
    "        opt = optim.SGD(net.parameters(), lr=args.lr * 100, momentum=args.momentum, weight_decay=1e-4)\n",
    "    else:\n",
    "        print(\"Use Adam\")\n",
    "        opt = optim.Adam(net.parameters(), lr=args.lr, weight_decay=1e-4)\n",
    "    scheduler = MultiStepLR(opt, milestones=[75, 150, 200], gamma=0.1)\n",
    "\n",
    "\n",
    "    best_test_loss = np.inf\n",
    "    best_test_cycle_loss = np.inf\n",
    "    best_test_mse_ab = np.inf\n",
    "    best_test_rmse_ab = np.inf\n",
    "    best_test_mae_ab = np.inf\n",
    "\n",
    "    best_test_r_mse_ab = np.inf\n",
    "    best_test_r_rmse_ab = np.inf\n",
    "    best_test_r_mae_ab = np.inf\n",
    "    best_test_t_mse_ab = np.inf\n",
    "    best_test_t_rmse_ab = np.inf\n",
    "    best_test_t_mae_ab = np.inf\n",
    "\n",
    "    best_test_mse_ba = np.inf\n",
    "    best_test_rmse_ba = np.inf\n",
    "    best_test_mae_ba = np.inf\n",
    "\n",
    "    best_test_r_mse_ba = np.inf\n",
    "    best_test_r_rmse_ba = np.inf\n",
    "    best_test_r_mae_ba = np.inf\n",
    "    best_test_t_mse_ba = np.inf\n",
    "    best_test_t_rmse_ba = np.inf\n",
    "    best_test_t_mae_ba = np.inf\n",
    "\n",
    "    for epoch in range(args.epochs):\n",
    "        scheduler.step()\n",
    "        train_loss, train_cycle_loss, \\\n",
    "        train_mse_ab, train_mae_ab, train_mse_ba, train_mae_ba, train_rotations_ab, train_translations_ab, \\\n",
    "        train_rotations_ab_pred, \\\n",
    "        train_translations_ab_pred, train_rotations_ba, train_translations_ba, train_rotations_ba_pred, \\\n",
    "        train_translations_ba_pred, train_eulers_ab, train_eulers_ba = train_one_epoch(args, net, train_loader, opt)\n",
    "        test_loss, test_cycle_loss, \\\n",
    "        test_mse_ab, test_mae_ab, test_mse_ba, test_mae_ba, test_rotations_ab, test_translations_ab, \\\n",
    "        test_rotations_ab_pred, \\\n",
    "        test_translations_ab_pred, test_rotations_ba, test_translations_ba, test_rotations_ba_pred, \\\n",
    "        test_translations_ba_pred, test_eulers_ab, test_eulers_ba = test_one_epoch(args, net, test_loader)\n",
    "        train_rmse_ab = np.sqrt(train_mse_ab)\n",
    "        test_rmse_ab = np.sqrt(test_mse_ab)\n",
    "\n",
    "        train_rmse_ba = np.sqrt(train_mse_ba)\n",
    "        test_rmse_ba = np.sqrt(test_mse_ba)\n",
    "\n",
    "        train_rotations_ab_pred_euler = npmat2euler(train_rotations_ab_pred)\n",
    "        train_r_mse_ab = np.mean((train_rotations_ab_pred_euler - np.degrees(train_eulers_ab)) ** 2)\n",
    "        train_r_rmse_ab = np.sqrt(train_r_mse_ab)\n",
    "        train_r_mae_ab = np.mean(np.abs(train_rotations_ab_pred_euler - np.degrees(train_eulers_ab)))\n",
    "        train_t_mse_ab = np.mean((train_translations_ab - train_translations_ab_pred) ** 2)\n",
    "        train_t_rmse_ab = np.sqrt(train_t_mse_ab)\n",
    "        train_t_mae_ab = np.mean(np.abs(train_translations_ab - train_translations_ab_pred))\n",
    "\n",
    "        train_rotations_ba_pred_euler = npmat2euler(train_rotations_ba_pred, 'xyz')\n",
    "        train_r_mse_ba = np.mean((train_rotations_ba_pred_euler - np.degrees(train_eulers_ba)) ** 2)\n",
    "        train_r_rmse_ba = np.sqrt(train_r_mse_ba)\n",
    "        train_r_mae_ba = np.mean(np.abs(train_rotations_ba_pred_euler - np.degrees(train_eulers_ba)))\n",
    "        train_t_mse_ba = np.mean((train_translations_ba - train_translations_ba_pred) ** 2)\n",
    "        train_t_rmse_ba = np.sqrt(train_t_mse_ba)\n",
    "        train_t_mae_ba = np.mean(np.abs(train_translations_ba - train_translations_ba_pred))\n",
    "\n",
    "        test_rotations_ab_pred_euler = npmat2euler(test_rotations_ab_pred)\n",
    "        test_r_mse_ab = np.mean((test_rotations_ab_pred_euler - np.degrees(test_eulers_ab)) ** 2)\n",
    "        test_r_rmse_ab = np.sqrt(test_r_mse_ab)\n",
    "        test_r_mae_ab = np.mean(np.abs(test_rotations_ab_pred_euler - np.degrees(test_eulers_ab)))\n",
    "        test_t_mse_ab = np.mean((test_translations_ab - test_translations_ab_pred) ** 2)\n",
    "        test_t_rmse_ab = np.sqrt(test_t_mse_ab)\n",
    "        test_t_mae_ab = np.mean(np.abs(test_translations_ab - test_translations_ab_pred))\n",
    "\n",
    "        test_rotations_ba_pred_euler = npmat2euler(test_rotations_ba_pred, 'xyz')\n",
    "        test_r_mse_ba = np.mean((test_rotations_ba_pred_euler - np.degrees(test_eulers_ba)) ** 2)\n",
    "        test_r_rmse_ba = np.sqrt(test_r_mse_ba)\n",
    "        test_r_mae_ba = np.mean(np.abs(test_rotations_ba_pred_euler - np.degrees(test_eulers_ba)))\n",
    "        test_t_mse_ba = np.mean((test_translations_ba - test_translations_ba_pred) ** 2)\n",
    "        test_t_rmse_ba = np.sqrt(test_t_mse_ba)\n",
    "        test_t_mae_ba = np.mean(np.abs(test_translations_ba - test_translations_ba_pred))\n",
    "\n",
    "        if best_test_loss >= test_loss:\n",
    "            best_test_loss = test_loss\n",
    "            best_test_cycle_loss = test_cycle_loss\n",
    "\n",
    "            best_test_mse_ab = test_mse_ab\n",
    "            best_test_rmse_ab = test_rmse_ab\n",
    "            best_test_mae_ab = test_mae_ab\n",
    "\n",
    "            best_test_r_mse_ab = test_r_mse_ab\n",
    "            best_test_r_rmse_ab = test_r_rmse_ab\n",
    "            best_test_r_mae_ab = test_r_mae_ab\n",
    "\n",
    "            best_test_t_mse_ab = test_t_mse_ab\n",
    "            best_test_t_rmse_ab = test_t_rmse_ab\n",
    "            best_test_t_mae_ab = test_t_mae_ab\n",
    "\n",
    "            best_test_mse_ba = test_mse_ba\n",
    "            best_test_rmse_ba = test_rmse_ba\n",
    "            best_test_mae_ba = test_mae_ba\n",
    "\n",
    "            best_test_r_mse_ba = test_r_mse_ba\n",
    "            best_test_r_rmse_ba = test_r_rmse_ba\n",
    "            best_test_r_mae_ba = test_r_mae_ba\n",
    "\n",
    "            best_test_t_mse_ba = test_t_mse_ba\n",
    "            best_test_t_rmse_ba = test_t_rmse_ba\n",
    "            best_test_t_mae_ba = test_t_mae_ba\n",
    "\n",
    "            if torch.cuda.device_count() > 1:\n",
    "                torch.save(net.module.state_dict(), 'checkpoints/%s/models/model.best.t7' % args.exp_name)\n",
    "            else:\n",
    "                torch.save(net.state_dict(), 'checkpoints/%s/models/model.best.t7' % args.exp_name)\n",
    "\n",
    "        textio.cprint('==TRAIN==')\n",
    "        textio.cprint('A--------->B')\n",
    "        textio.cprint('EPOCH:: %d, Loss: %f, Cycle Loss:, %f, MSE: %f, RMSE: %f, MAE: %f, rot_MSE: %f, rot_RMSE: %f, '\n",
    "                      'rot_MAE: %f, trans_MSE: %f, trans_RMSE: %f, trans_MAE: %f'\n",
    "                      % (epoch, train_loss, train_cycle_loss, train_mse_ab, train_rmse_ab, train_mae_ab, train_r_mse_ab,\n",
    "                         train_r_rmse_ab, train_r_mae_ab, train_t_mse_ab, train_t_rmse_ab, train_t_mae_ab))\n",
    "        textio.cprint('B--------->A')\n",
    "        textio.cprint('EPOCH:: %d, Loss: %f, MSE: %f, RMSE: %f, MAE: %f, rot_MSE: %f, rot_RMSE: %f, '\n",
    "                      'rot_MAE: %f, trans_MSE: %f, trans_RMSE: %f, trans_MAE: %f'\n",
    "                      % (epoch, train_loss, train_mse_ba, train_rmse_ba, train_mae_ba, train_r_mse_ba, train_r_rmse_ba,\n",
    "                         train_r_mae_ba, train_t_mse_ba, train_t_rmse_ba, train_t_mae_ba))\n",
    "\n",
    "        textio.cprint('==TEST==')\n",
    "        textio.cprint('A--------->B')\n",
    "        textio.cprint('EPOCH:: %d, Loss: %f, Cycle Loss: %f, MSE: %f, RMSE: %f, MAE: %f, rot_MSE: %f, rot_RMSE: %f, '\n",
    "                      'rot_MAE: %f, trans_MSE: %f, trans_RMSE: %f, trans_MAE: %f'\n",
    "                      % (epoch, test_loss, test_cycle_loss, test_mse_ab, test_rmse_ab, test_mae_ab, test_r_mse_ab,\n",
    "                         test_r_rmse_ab, test_r_mae_ab, test_t_mse_ab, test_t_rmse_ab, test_t_mae_ab))\n",
    "        textio.cprint('B--------->A')\n",
    "        textio.cprint('EPOCH:: %d, Loss: %f, MSE: %f, RMSE: %f, MAE: %f, rot_MSE: %f, rot_RMSE: %f, '\n",
    "                      'rot_MAE: %f, trans_MSE: %f, trans_RMSE: %f, trans_MAE: %f'\n",
    "                      % (epoch, test_loss, test_mse_ba, test_rmse_ba, test_mae_ba, test_r_mse_ba, test_r_rmse_ba,\n",
    "                         test_r_mae_ba, test_t_mse_ba, test_t_rmse_ba, test_t_mae_ba))\n",
    "\n",
    "        textio.cprint('==BEST TEST==')\n",
    "        textio.cprint('A--------->B')\n",
    "        textio.cprint('EPOCH:: %d, Loss: %f, Cycle Loss: %f, MSE: %f, RMSE: %f, MAE: %f, rot_MSE: %f, rot_RMSE: %f, '\n",
    "                      'rot_MAE: %f, trans_MSE: %f, trans_RMSE: %f, trans_MAE: %f'\n",
    "                      % (epoch, best_test_loss, best_test_cycle_loss, best_test_mse_ab, best_test_rmse_ab,\n",
    "                         best_test_mae_ab, best_test_r_mse_ab, best_test_r_rmse_ab,\n",
    "                         best_test_r_mae_ab, best_test_t_mse_ab, best_test_t_rmse_ab, best_test_t_mae_ab))\n",
    "        textio.cprint('B--------->A')\n",
    "        textio.cprint('EPOCH:: %d, Loss: %f, MSE: %f, RMSE: %f, MAE: %f, rot_MSE: %f, rot_RMSE: %f, '\n",
    "                      'rot_MAE: %f, trans_MSE: %f, trans_RMSE: %f, trans_MAE: %f'\n",
    "                      % (epoch, best_test_loss, best_test_mse_ba, best_test_rmse_ba, best_test_mae_ba,\n",
    "                         best_test_r_mse_ba, best_test_r_rmse_ba,\n",
    "                         best_test_r_mae_ba, best_test_t_mse_ba, best_test_t_rmse_ba, best_test_t_mae_ba))\n",
    "\n",
    "        boardio.add_scalar('A->B/train/loss', train_loss, epoch)\n",
    "        boardio.add_scalar('A->B/train/MSE', train_mse_ab, epoch)\n",
    "        boardio.add_scalar('A->B/train/RMSE', train_rmse_ab, epoch)\n",
    "        boardio.add_scalar('A->B/train/MAE', train_mae_ab, epoch)\n",
    "        boardio.add_scalar('A->B/train/rotation/MSE', train_r_mse_ab, epoch)\n",
    "        boardio.add_scalar('A->B/train/rotation/RMSE', train_r_rmse_ab, epoch)\n",
    "        boardio.add_scalar('A->B/train/rotation/MAE', train_r_mae_ab, epoch)\n",
    "        boardio.add_scalar('A->B/train/translation/MSE', train_t_mse_ab, epoch)\n",
    "        boardio.add_scalar('A->B/train/translation/RMSE', train_t_rmse_ab, epoch)\n",
    "        boardio.add_scalar('A->B/train/translation/MAE', train_t_mae_ab, epoch)\n",
    "\n",
    "        boardio.add_scalar('B->A/train/loss', train_loss, epoch)\n",
    "        boardio.add_scalar('B->A/train/MSE', train_mse_ba, epoch)\n",
    "        boardio.add_scalar('B->A/train/RMSE', train_rmse_ba, epoch)\n",
    "        boardio.add_scalar('B->A/train/MAE', train_mae_ba, epoch)\n",
    "        boardio.add_scalar('B->A/train/rotation/MSE', train_r_mse_ba, epoch)\n",
    "        boardio.add_scalar('B->A/train/rotation/RMSE', train_r_rmse_ba, epoch)\n",
    "        boardio.add_scalar('B->A/train/rotation/MAE', train_r_mae_ba, epoch)\n",
    "        boardio.add_scalar('B->A/train/translation/MSE', train_t_mse_ba, epoch)\n",
    "        boardio.add_scalar('B->A/train/translation/RMSE', train_t_rmse_ba, epoch)\n",
    "        boardio.add_scalar('B->A/train/translation/MAE', train_t_mae_ba, epoch)\n",
    "\n",
    "        ############TEST\n",
    "        boardio.add_scalar('A->B/test/loss', test_loss, epoch)\n",
    "        boardio.add_scalar('A->B/test/MSE', test_mse_ab, epoch)\n",
    "        boardio.add_scalar('A->B/test/RMSE', test_rmse_ab, epoch)\n",
    "        boardio.add_scalar('A->B/test/MAE', test_mae_ab, epoch)\n",
    "        boardio.add_scalar('A->B/test/rotation/MSE', test_r_mse_ab, epoch)\n",
    "        boardio.add_scalar('A->B/test/rotation/RMSE', test_r_rmse_ab, epoch)\n",
    "        boardio.add_scalar('A->B/test/rotation/MAE', test_r_mae_ab, epoch)\n",
    "        boardio.add_scalar('A->B/test/translation/MSE', test_t_mse_ab, epoch)\n",
    "        boardio.add_scalar('A->B/test/translation/RMSE', test_t_rmse_ab, epoch)\n",
    "        boardio.add_scalar('A->B/test/translation/MAE', test_t_mae_ab, epoch)\n",
    "\n",
    "        boardio.add_scalar('B->A/test/loss', test_loss, epoch)\n",
    "        boardio.add_scalar('B->A/test/MSE', test_mse_ba, epoch)\n",
    "        boardio.add_scalar('B->A/test/RMSE', test_rmse_ba, epoch)\n",
    "        boardio.add_scalar('B->A/test/MAE', test_mae_ba, epoch)\n",
    "        boardio.add_scalar('B->A/test/rotation/MSE', test_r_mse_ba, epoch)\n",
    "        boardio.add_scalar('B->A/test/rotation/RMSE', test_r_rmse_ba, epoch)\n",
    "        boardio.add_scalar('B->A/test/rotation/MAE', test_r_mae_ba, epoch)\n",
    "        boardio.add_scalar('B->A/test/translation/MSE', test_t_mse_ba, epoch)\n",
    "        boardio.add_scalar('B->A/test/translation/RMSE', test_t_rmse_ba, epoch)\n",
    "        boardio.add_scalar('B->A/test/translation/MAE', test_t_mae_ba, epoch)\n",
    "\n",
    "        ############BEST TEST\n",
    "        boardio.add_scalar('A->B/best_test/loss', best_test_loss, epoch)\n",
    "        boardio.add_scalar('A->B/best_test/MSE', best_test_mse_ab, epoch)\n",
    "        boardio.add_scalar('A->B/best_test/RMSE', best_test_rmse_ab, epoch)\n",
    "        boardio.add_scalar('A->B/best_test/MAE', best_test_mae_ab, epoch)\n",
    "        boardio.add_scalar('A->B/best_test/rotation/MSE', best_test_r_mse_ab, epoch)\n",
    "        boardio.add_scalar('A->B/best_test/rotation/RMSE', best_test_r_rmse_ab, epoch)\n",
    "        boardio.add_scalar('A->B/best_test/rotation/MAE', best_test_r_mae_ab, epoch)\n",
    "        boardio.add_scalar('A->B/best_test/translation/MSE', best_test_t_mse_ab, epoch)\n",
    "        boardio.add_scalar('A->B/best_test/translation/RMSE', best_test_t_rmse_ab, epoch)\n",
    "        boardio.add_scalar('A->B/best_test/translation/MAE', best_test_t_mae_ab, epoch)\n",
    "\n",
    "        boardio.add_scalar('B->A/best_test/loss', best_test_loss, epoch)\n",
    "        boardio.add_scalar('B->A/best_test/MSE', best_test_mse_ba, epoch)\n",
    "        boardio.add_scalar('B->A/best_test/RMSE', best_test_rmse_ba, epoch)\n",
    "        boardio.add_scalar('B->A/best_test/MAE', best_test_mae_ba, epoch)\n",
    "        boardio.add_scalar('B->A/best_test/rotation/MSE', best_test_r_mse_ba, epoch)\n",
    "        boardio.add_scalar('B->A/best_test/rotation/RMSE', best_test_r_rmse_ba, epoch)\n",
    "        boardio.add_scalar('B->A/best_test/rotation/MAE', best_test_r_mae_ba, epoch)\n",
    "        boardio.add_scalar('B->A/best_test/translation/MSE', best_test_t_mse_ba, epoch)\n",
    "        boardio.add_scalar('B->A/best_test/translation/RMSE', best_test_t_rmse_ba, epoch)\n",
    "        boardio.add_scalar('B->A/best_test/translation/MAE', best_test_t_mae_ba, epoch)\n",
    "\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            torch.save(net.module.state_dict(), 'checkpoints/%s/models/model.%d.t7' % (args.exp_name, epoch))\n",
    "        else:\n",
    "            torch.save(net.state_dict(), 'checkpoints/%s/models/model.%d.t7' % (args.exp_name, epoch))\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_one_epoch(args, net, test_loader):\n",
    "    net.eval()\n",
    "    mse_ab = 0\n",
    "    mae_ab = 0\n",
    "    mse_ba = 0\n",
    "    mae_ba = 0\n",
    "\n",
    "    total_loss = 0\n",
    "    total_cycle_loss = 0\n",
    "    num_examples = 0\n",
    "    rotations_ab = []\n",
    "    translations_ab = []\n",
    "    rotations_ab_pred = []\n",
    "    translations_ab_pred = []\n",
    "\n",
    "    rotations_ba = []\n",
    "    translations_ba = []\n",
    "    rotations_ba_pred = []\n",
    "    translations_ba_pred = []\n",
    "\n",
    "    eulers_ab = []\n",
    "    eulers_ba = []\n",
    "\n",
    "    for src, target, rotation_ab, translation_ab, rotation_ba, translation_ba, euler_ab, euler_ba in tqdm(test_loader):\n",
    "        src = src.cuda()\n",
    "        target = target.cuda()\n",
    "        rotation_ab = rotation_ab.cuda()\n",
    "        translation_ab = translation_ab.cuda()\n",
    "        rotation_ba = rotation_ba.cuda()\n",
    "        translation_ba = translation_ba.cuda()\n",
    "\n",
    "        batch_size = src.size(0)\n",
    "        num_examples += batch_size\n",
    "        rotation_ab_pred, translation_ab_pred, rotation_ba_pred, translation_ba_pred = net(src, target)\n",
    "\n",
    "        ## save rotation and translation\n",
    "        rotations_ab.append(rotation_ab.detach().cpu().numpy())\n",
    "        translations_ab.append(translation_ab.detach().cpu().numpy())\n",
    "        rotations_ab_pred.append(rotation_ab_pred.detach().cpu().numpy())\n",
    "        translations_ab_pred.append(translation_ab_pred.detach().cpu().numpy())\n",
    "        eulers_ab.append(euler_ab.numpy())\n",
    "        ##\n",
    "        rotations_ba.append(rotation_ba.detach().cpu().numpy())\n",
    "        translations_ba.append(translation_ba.detach().cpu().numpy())\n",
    "        rotations_ba_pred.append(rotation_ba_pred.detach().cpu().numpy())\n",
    "        translations_ba_pred.append(translation_ba_pred.detach().cpu().numpy())\n",
    "        eulers_ba.append(euler_ba.numpy())\n",
    "\n",
    "        transformed_src = transform_point_cloud(src, rotation_ab_pred, translation_ab_pred)\n",
    "\n",
    "        transformed_target = transform_point_cloud(target, rotation_ba_pred, translation_ba_pred)\n",
    "\n",
    "        ###########################\n",
    "        identity = torch.eye(3).cuda().unsqueeze(0).repeat(batch_size, 1, 1)\n",
    "        loss = F.mse_loss(torch.matmul(rotation_ab_pred.transpose(2, 1), rotation_ab), identity) \\\n",
    "               + F.mse_loss(translation_ab_pred, translation_ab)\n",
    "        if args.cycle:\n",
    "            rotation_loss = F.mse_loss(torch.matmul(rotation_ba_pred, rotation_ab_pred), identity.clone())\n",
    "            translation_loss = torch.mean((torch.matmul(rotation_ba_pred.transpose(2, 1),\n",
    "                                                        translation_ab_pred.view(batch_size, 3, 1)).view(batch_size, 3)\n",
    "                                           + translation_ba_pred) ** 2, dim=[0, 1])\n",
    "            cycle_loss = rotation_loss + translation_loss\n",
    "\n",
    "            loss = loss + cycle_loss * 0.1\n",
    "\n",
    "        total_loss += loss.item() * batch_size\n",
    "\n",
    "        if args.cycle:\n",
    "            total_cycle_loss = total_cycle_loss + cycle_loss.item() * 0.1 * batch_size\n",
    "\n",
    "        mse_ab += torch.mean((transformed_src - target) ** 2, dim=[0, 1, 2]).item() * batch_size\n",
    "        mae_ab += torch.mean(torch.abs(transformed_src - target), dim=[0, 1, 2]).item() * batch_size\n",
    "\n",
    "        mse_ba += torch.mean((transformed_target - src) ** 2, dim=[0, 1, 2]).item() * batch_size\n",
    "        mae_ba += torch.mean(torch.abs(transformed_target - src), dim=[0, 1, 2]).item() * batch_size\n",
    "\n",
    "    rotations_ab = np.concatenate(rotations_ab, axis=0)\n",
    "    translations_ab = np.concatenate(translations_ab, axis=0)\n",
    "    rotations_ab_pred = np.concatenate(rotations_ab_pred, axis=0)\n",
    "    translations_ab_pred = np.concatenate(translations_ab_pred, axis=0)\n",
    "\n",
    "    rotations_ba = np.concatenate(rotations_ba, axis=0)\n",
    "    translations_ba = np.concatenate(translations_ba, axis=0)\n",
    "    rotations_ba_pred = np.concatenate(rotations_ba_pred, axis=0)\n",
    "    translations_ba_pred = np.concatenate(translations_ba_pred, axis=0)\n",
    "\n",
    "    eulers_ab = np.concatenate(eulers_ab, axis=0)\n",
    "    eulers_ba = np.concatenate(eulers_ba, axis=0)\n",
    "\n",
    "    return total_loss * 1.0 / num_examples, total_cycle_loss / num_examples, \\\n",
    "           mse_ab * 1.0 / num_examples, mae_ab * 1.0 / num_examples, \\\n",
    "           mse_ba * 1.0 / num_examples, mae_ba * 1.0 / num_examples, rotations_ab, \\\n",
    "           translations_ab, rotations_ab_pred, translations_ab_pred, rotations_ba, \\\n",
    "           translations_ba, rotations_ba_pred, translations_ba_pred, eulers_ab, eulers_ba\n",
    "\n",
    "\n",
    "def test(args, net, test_loader, boardio, textio):\n",
    "\n",
    "    test_loss, test_cycle_loss, \\\n",
    "    test_mse_ab, test_mae_ab, test_mse_ba, test_mae_ba, test_rotations_ab, test_translations_ab, \\\n",
    "    test_rotations_ab_pred, \\\n",
    "    test_translations_ab_pred, test_rotations_ba, test_translations_ba, test_rotations_ba_pred, \\\n",
    "    test_translations_ba_pred, test_eulers_ab, test_eulers_ba = test_one_epoch(args, net, test_loader)\n",
    "    test_rmse_ab = np.sqrt(test_mse_ab)\n",
    "    test_rmse_ba = np.sqrt(test_mse_ba)\n",
    "\n",
    "    test_rotations_ab_pred_euler = npmat2euler(test_rotations_ab_pred)\n",
    "    test_r_mse_ab = np.mean((test_rotations_ab_pred_euler - np.degrees(test_eulers_ab)) ** 2)\n",
    "    test_r_rmse_ab = np.sqrt(test_r_mse_ab)\n",
    "    test_r_mae_ab = np.mean(np.abs(test_rotations_ab_pred_euler - np.degrees(test_eulers_ab)))\n",
    "    test_t_mse_ab = np.mean((test_translations_ab - test_translations_ab_pred) ** 2)\n",
    "    test_t_rmse_ab = np.sqrt(test_t_mse_ab)\n",
    "    test_t_mae_ab = np.mean(np.abs(test_translations_ab - test_translations_ab_pred))\n",
    "\n",
    "    test_rotations_ba_pred_euler = npmat2euler(test_rotations_ba_pred, 'xyz')\n",
    "    test_r_mse_ba = np.mean((test_rotations_ba_pred_euler - np.degrees(test_eulers_ba)) ** 2)\n",
    "    test_r_rmse_ba = np.sqrt(test_r_mse_ba)\n",
    "    test_r_mae_ba = np.mean(np.abs(test_rotations_ba_pred_euler - np.degrees(test_eulers_ba)))\n",
    "    test_t_mse_ba = np.mean((test_translations_ba - test_translations_ba_pred) ** 2)\n",
    "    test_t_rmse_ba = np.sqrt(test_t_mse_ba)\n",
    "    test_t_mae_ba = np.mean(np.abs(test_translations_ba - test_translations_ba_pred))\n",
    "\n",
    "    textio.cprint('==FINAL TEST==')\n",
    "    textio.cprint('A--------->B')\n",
    "    textio.cprint('EPOCH:: %d, Loss: %f, Cycle Loss: %f, MSE: %f, RMSE: %f, MAE: %f, rot_MSE: %f, rot_RMSE: %f, '\n",
    "                  'rot_MAE: %f, trans_MSE: %f, trans_RMSE: %f, trans_MAE: %f'\n",
    "                  % (-1, test_loss, test_cycle_loss, test_mse_ab, test_rmse_ab, test_mae_ab,\n",
    "                     test_r_mse_ab, test_r_rmse_ab,\n",
    "                     test_r_mae_ab, test_t_mse_ab, test_t_rmse_ab, test_t_mae_ab))\n",
    "    textio.cprint('B--------->A')\n",
    "    textio.cprint('EPOCH:: %d, Loss: %f, MSE: %f, RMSE: %f, MAE: %f, rot_MSE: %f, rot_RMSE: %f, '\n",
    "                  'rot_MAE: %f, trans_MSE: %f, trans_RMSE: %f, trans_MAE: %f'\n",
    "                  % (-1, test_loss, test_mse_ba, test_rmse_ba, test_mae_ba, test_r_mse_ba, test_r_rmse_ba,\n",
    "                     test_r_mae_ba, test_t_mse_ba, test_t_rmse_ba, test_t_mae_ba))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1024)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'num_points'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/hang/Desktop/Master/S2/ML 3D Geometry/project/ml3d/test.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hang/Desktop/Master/S2/ML%203D%20Geometry/project/ml3d/test.ipynb#ch0000007?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(src\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hang/Desktop/Master/S2/ML%203D%20Geometry/project/ml3d/test.ipynb#ch0000007?line=5'>6</a>\u001b[0m args \u001b[39m=\u001b[39m {}\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hang/Desktop/Master/S2/ML%203D%20Geometry/project/ml3d/test.ipynb#ch0000007?line=6'>7</a>\u001b[0m train_loader \u001b[39m=\u001b[39m DataLoader(\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/hang/Desktop/Master/S2/ML%203D%20Geometry/project/ml3d/test.ipynb#ch0000007?line=7'>8</a>\u001b[0m             ModelNet40(num_points\u001b[39m=\u001b[39margs\u001b[39m.\u001b[39;49mnum_points, partition\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m, gaussian_noise\u001b[39m=\u001b[39margs\u001b[39m.\u001b[39mgaussian_noise,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hang/Desktop/Master/S2/ML%203D%20Geometry/project/ml3d/test.ipynb#ch0000007?line=8'>9</a>\u001b[0m                        unseen\u001b[39m=\u001b[39margs\u001b[39m.\u001b[39munseen, factor\u001b[39m=\u001b[39margs\u001b[39m.\u001b[39mfactor),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hang/Desktop/Master/S2/ML%203D%20Geometry/project/ml3d/test.ipynb#ch0000007?line=9'>10</a>\u001b[0m             batch_size\u001b[39m=\u001b[39margs\u001b[39m.\u001b[39mbatch_size, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, drop_last\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hang/Desktop/Master/S2/ML%203D%20Geometry/project/ml3d/test.ipynb#ch0000007?line=11'>12</a>\u001b[0m test_loader \u001b[39m=\u001b[39m DataLoader(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hang/Desktop/Master/S2/ML%203D%20Geometry/project/ml3d/test.ipynb#ch0000007?line=12'>13</a>\u001b[0m             ModelNet40(num_points\u001b[39m=\u001b[39margs\u001b[39m.\u001b[39mnum_points, partition\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m, gaussian_noise\u001b[39m=\u001b[39margs\u001b[39m.\u001b[39mgaussian_noise,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hang/Desktop/Master/S2/ML%203D%20Geometry/project/ml3d/test.ipynb#ch0000007?line=13'>14</a>\u001b[0m                        unseen\u001b[39m=\u001b[39margs\u001b[39m.\u001b[39munseen, factor\u001b[39m=\u001b[39margs\u001b[39m.\u001b[39mfactor),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hang/Desktop/Master/S2/ML%203D%20Geometry/project/ml3d/test.ipynb#ch0000007?line=14'>15</a>\u001b[0m             batch_size\u001b[39m=\u001b[39margs\u001b[39m.\u001b[39mtest_batch_size, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, drop_last\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'num_points'"
     ]
    }
   ],
   "source": [
    "# define the dataloader\n",
    "pc = ModelNet40(num_points=1024, partition='test', gaussian_noise=False, unseen=False, factor=4)\n",
    "src, target, rotation_ab, translation_ab, rotation_ba, translation_ba, euler_ab, euler_ba = pc[6]\n",
    "\n",
    "args = {}\n",
    "train_loader = DataLoader(\n",
    "            ModelNet40(num_points=args.num_points, partition='train', gaussian_noise=args.gaussian_noise,\n",
    "                       unseen=args.unseen, factor=args.factor),\n",
    "            batch_size=args.batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "            ModelNet40(num_points=args.num_points, partition='test', gaussian_noise=args.gaussian_noise,\n",
    "                       unseen=args.unseen, factor=args.factor),\n",
    "            batch_size=args.test_batch_size, shuffle=False, drop_last=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('3d_geometry')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "404d86034d14cc62a99913f0f514620ac3e2e8472611b3eef45ce38c30d51311"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
