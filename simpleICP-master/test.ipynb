{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpleicp import PointCloud, SimpleICP\n",
    "import numpy as np\n",
    "import torch as torch\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "sys.path.append(\"../dcp-master\")\n",
    "from data import ModelNet40\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import k3d\n",
    "import trimesh\n",
    "from pathlib import Path\n",
    "from util import npmat2euler\n",
    "from tqdm import tqdm\n",
    "\n",
    "def visualize_pointcloud(point_cloud1, point_cloud2, point_size, flip_axes=False, name='point_cloud', R=None, t=None):\n",
    "    plot = k3d.plot(name=name, grid_visible=False, grid=(-0.55, -0.55, -0.55, 0.55, 0.55, 0.55))\n",
    "    # if flip_axes:\n",
    "    #     point_cloud[:, 2] = point_cloud[:, 2] * -1\n",
    "    #     point_cloud[:, [0, 1, 2]] = point_cloud[:, [0, 2, 1]]\n",
    "    # t_broadcast = np.broadcast_to(t[:, np.newaxis], (3, point_cloud1.X.shape[0]))\n",
    "    # point_cloud1 = (R @ point_cloud1.X.T + t_broadcast).T\n",
    "    plt_points1 = k3d.points(positions=point_cloud1.X.astype(np.float32), point_size=point_size, color=0xd0d0d0)\n",
    "    plt_points2 = k3d.points(positions=point_cloud2.astype(np.float32), point_size=point_size, color=0x0dd00d)\n",
    "    plot += plt_points1\n",
    "    plot += plt_points2\n",
    "    plt_points1.shader = '3d'\n",
    "    plt_points2.shader = '3d'\n",
    "    plot.display()\n",
    "\n",
    "def transform(point_cloud, R=None, t=None):\n",
    "    t_broadcast = np.broadcast_to(t[:, np.newaxis], (3, point_cloud.shape[0]))\n",
    "    return (R @ point_cloud.T + t_broadcast).T\n",
    "\n",
    "def test_one_epoch(pc):\n",
    "    mse_ab = 0\n",
    "    mae_ab = 0\n",
    "    mse_ba = 0\n",
    "    mae_ba = 0\n",
    "\n",
    "    total_loss = 0\n",
    "    total_cycle_loss = 0\n",
    "    num_examples = 0\n",
    "    rotations_ab = []\n",
    "    translations_ab = []\n",
    "    rotations_ab_pred = []\n",
    "    translations_ab_pred = []\n",
    "\n",
    "    rotations_ba = []\n",
    "    translations_ba = []\n",
    "    rotations_ba_pred = []\n",
    "    translations_ba_pred = []\n",
    "\n",
    "    eulers_ab = []\n",
    "    eulers_ba = []\n",
    "    for i in tqdm(range(len(pc))):\n",
    "        \n",
    "        num_examples += 1\n",
    "        src, target, rotation_ab, translation_ab, rotation_ba, translation_ba, euler_ab, euler_ba, _ = pc[i]\n",
    "        rotation_ab = torch.tensor(rotation_ab).double()\n",
    "        translation_ab = torch.tensor(translation_ab).double()\n",
    "        rotation_ba = torch.tensor(rotation_ba).double()\n",
    "        translation_ba = torch.tensor(translation_ba).double()\n",
    "        euler_ab = torch.tensor(euler_ab).double()\n",
    "        euler_ba = torch.tensor(euler_ba).double()\n",
    "\n",
    "\n",
    "        src = PointCloud(src.T, columns=[\"x\", \"y\", \"z\"])\n",
    "        target = PointCloud(target.T, columns=[\"x\", \"y\", \"z\"])\n",
    "        # Create simpleICP object, add point clouds, and run algorithm!\n",
    "        icp = SimpleICP()\n",
    "        icp.add_point_clouds(target, src)\n",
    "        H, X_mov_transformed, rigid_body_transformation_params = icp.run(max_overlap_distance=1)\n",
    "        X_mov_transformed = torch.tensor(X_mov_transformed)\n",
    "\n",
    "        # get the predicted rotations and translations\n",
    "        rotation_ab_pred = H[:3, :3]\n",
    "        translation_ab_pred = H[:3, 3]\n",
    "        rotation_ab_pred = torch.tensor(rotation_ab_pred).double()\n",
    "        translation_ab_pred = torch.tensor(translation_ab_pred).double()\n",
    "        rotation_ba_pred = rotation_ab_pred.transpose(1, 0).contiguous()\n",
    "        translation_ba_pred = -torch.matmul(rotation_ba_pred, translation_ab_pred.unsqueeze(1)).squeeze(1)\n",
    "\n",
    "        ## save rotation and translation\n",
    "        rotations_ab.append(rotation_ab.unsqueeze(0).detach().cpu().numpy())\n",
    "        translations_ab.append(translation_ab.unsqueeze(0).detach().cpu().numpy())\n",
    "        rotations_ab_pred.append(rotation_ab_pred.unsqueeze(0).detach().cpu().numpy())\n",
    "        translations_ab_pred.append(translation_ab_pred.unsqueeze(0).detach().cpu().numpy())\n",
    "        eulers_ab.append(euler_ab.unsqueeze(0).numpy())\n",
    "        ##\n",
    "        rotations_ba.append(rotation_ba.unsqueeze(0).detach().cpu().numpy())\n",
    "        translations_ba.append(translation_ba.unsqueeze(0).detach().cpu().numpy())\n",
    "        rotations_ba_pred.append(rotation_ba_pred.unsqueeze(0).detach().cpu().numpy())\n",
    "        translations_ba_pred.append(translation_ba_pred.unsqueeze(0).detach().cpu().numpy())\n",
    "        eulers_ba.append(euler_ba.unsqueeze(0).numpy())\n",
    "        ##############################################\n",
    "        identity = torch.eye(3).repeat(1, 1)\n",
    "        loss = F.mse_loss(torch.matmul(rotation_ab_pred.transpose(1, 0), rotation_ab), identity) \\\n",
    "                + F.mse_loss(translation_ab_pred, translation_ab)\n",
    "        total_loss += loss.item()\n",
    "        mse_ab += torch.mean((X_mov_transformed - torch.tensor(target.X)) ** 2, dim=[0, 1]).item()\n",
    "        mae_ab += torch.mean(torch.abs(X_mov_transformed - torch.tensor(target.X)), dim=[0, 1]).item()\n",
    "\n",
    "        transformed_target = transform(target.X, R=rotation_ba_pred, t=translation_ba_pred)\n",
    "        mse_ba += torch.mean((transformed_target - torch.tensor(src.X)) ** 2, dim=[0, 1]).item()\n",
    "        mae_ba += torch.mean(torch.abs(transformed_target - torch.tensor(src.X)), dim=[0, 1]).item()\n",
    "\n",
    "    rotations_ab = np.concatenate(rotations_ab, axis=0)\n",
    "    translations_ab = np.concatenate(translations_ab, axis=0)\n",
    "    rotations_ab_pred = np.concatenate(rotations_ab_pred, axis=0)\n",
    "    translations_ab_pred = np.concatenate(translations_ab_pred, axis=0)\n",
    "\n",
    "    rotations_ba = np.concatenate(rotations_ba, axis=0)\n",
    "    translations_ba = np.concatenate(translations_ba, axis=0)\n",
    "    rotations_ba_pred = np.concatenate(rotations_ba_pred, axis=0)\n",
    "    translations_ba_pred = np.concatenate(translations_ba_pred, axis=0)\n",
    "\n",
    "    eulers_ab = np.concatenate(eulers_ab, axis=0)\n",
    "    eulers_ba = np.concatenate(eulers_ba, axis=0)\n",
    "\n",
    "    return total_loss * 1.0 / num_examples, total_cycle_loss / num_examples, \\\n",
    "           mse_ab * 1.0 / num_examples, mae_ab * 1.0 / num_examples, \\\n",
    "           mse_ba * 1.0 / num_examples, mae_ba * 1.0 / num_examples, rotations_ab, \\\n",
    "           translations_ab, rotations_ab_pred, translations_ab_pred, rotations_ba, \\\n",
    "           translations_ba, rotations_ba_pred, translations_ba_pred, eulers_ab, eulers_ba\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "class TUM(Dataset):\n",
    "        def __init__(self, size):\n",
    "                self.pcd1 = o3d.io.read_point_cloud(\"../4625_after_.pcd\")\n",
    "                self.index = np.random.randint(len(self.pcd1.points),size=size)\n",
    "                # print(self.index)\n",
    "                self.points1 = np.array(self.pcd1.points)[self.index] #转为矩阵\n",
    "\n",
    "                self.pcd2 = o3d.io.read_point_cloud(\"../4650_after_.pcd\")\n",
    "                self.points2 = np.array(self.pcd2.points)[self.index]\n",
    "\n",
    "                self.points1 = self.points1[np.newaxis,:]\n",
    "    \n",
    "        def __getitem__(self, index):\n",
    "                points1 = self.points1[index]\n",
    "                anglex = np.random.uniform() * np.pi / 20\n",
    "                angley = np.random.uniform() * np.pi / 20\n",
    "                anglez = np.random.uniform() * np.pi / 20\n",
    "\n",
    "                cosx = np.cos(anglex)\n",
    "                cosy = np.cos(angley)\n",
    "                cosz = np.cos(anglez)\n",
    "                sinx = np.sin(anglex)\n",
    "                siny = np.sin(angley)\n",
    "                sinz = np.sin(anglez)\n",
    "                Rx = np.array([[1, 0, 0],\n",
    "                                [0, cosx, -sinx],\n",
    "                                [0, sinx, cosx]])\n",
    "                Ry = np.array([[cosy, 0, siny],\n",
    "                                [0, 1, 0],\n",
    "                                [-siny, 0, cosy]])\n",
    "                Rz = np.array([[cosz, -sinz, 0],\n",
    "                                [sinz, cosz, 0],\n",
    "                                [0, 0, 1]])\n",
    "                R_ab = Rx.dot(Ry).dot(Rz)\n",
    "                R_ba = R_ab.T\n",
    "                translation_ab = np.array([np.random.uniform(-0.5, 0.5), np.random.uniform(-0.5, 0.5),\n",
    "                                                np.random.uniform(-0.5, 0.5)])\n",
    "                translation_ba = -R_ba.dot(translation_ab)\n",
    "\n",
    "\n",
    "                euler_ab = np.asarray([anglez, angley, anglex])\n",
    "                euler_ba = -euler_ab[::-1]\n",
    "                \n",
    "                return points1.T.astype('float32'), self.points2.T.astype('float32'), R_ab.astype('float32'), \\\n",
    "        translation_ab.astype('float32'), R_ba.astype('float32'), translation_ba.astype('float32'), \\\n",
    "        euler_ab.astype('float32'), euler_ba.astype('float32'), self.index\n",
    "\n",
    "        def __len__(self):\n",
    "                return len(self.points1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==FINAL TEST==\n",
      "A--------->B\n",
      "EPOCH:: -1, Loss: 0.047889, Cycle Loss: 0.000000, MSE: 0.116747, RMSE: 0.341683, MAE: 0.209915, rot_MSE: 6.312494, rot_RMSE: 2.512468, rot_MAE: 2.207949, trans_MSE: 0.046549, trans_RMSE: 0.215753, trans_MAE: 0.196382\n",
      "B--------->A\n",
      "EPOCH:: -1, Loss: 0.047889, MSE: 0.116747, RMSE: 0.341683, MAE: 0.210131, rot_MSE: 6.312494, rot_RMSE: 2.512468, rot_MAE: 2.207949, trans_MSE: 0.048677, trans_RMSE: 0.220628, trans_MAE: 0.191498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pc = TUM(5000)\n",
    "\n",
    "test_loss, test_cycle_loss, \\\n",
    "test_mse_ab, test_mae_ab, test_mse_ba, test_mae_ba, test_rotations_ab, test_translations_ab, \\\n",
    "test_rotations_ab_pred, \\\n",
    "test_translations_ab_pred, test_rotations_ba, test_translations_ba, test_rotations_ba_pred, \\\n",
    "test_translations_ba_pred, test_eulers_ab, test_eulers_ba = test_one_epoch(pc)\n",
    "test_rmse_ab = np.sqrt(test_mse_ab)\n",
    "test_rmse_ba = np.sqrt(test_mse_ba)\n",
    "\n",
    "test_rotations_ab_pred_euler = npmat2euler(test_rotations_ab_pred)\n",
    "test_r_mse_ab = np.mean((test_rotations_ab_pred_euler - np.degrees(test_eulers_ab)) ** 2)\n",
    "test_r_rmse_ab = np.sqrt(test_r_mse_ab)\n",
    "test_r_mae_ab = np.mean(np.abs(test_rotations_ab_pred_euler - np.degrees(test_eulers_ab)))\n",
    "test_t_mse_ab = np.mean((test_translations_ab - test_translations_ab_pred) ** 2)\n",
    "test_t_rmse_ab = np.sqrt(test_t_mse_ab)\n",
    "test_t_mae_ab = np.mean(np.abs(test_translations_ab - test_translations_ab_pred))\n",
    "\n",
    "test_rotations_ba_pred_euler = npmat2euler(test_rotations_ba_pred, 'xyz')\n",
    "test_r_mse_ba = np.mean((test_rotations_ba_pred_euler - np.degrees(test_eulers_ba)) ** 2)\n",
    "test_r_rmse_ba = np.sqrt(test_r_mse_ba)\n",
    "test_r_mae_ba = np.mean(np.abs(test_rotations_ba_pred_euler - np.degrees(test_eulers_ba)))\n",
    "test_t_mse_ba = np.mean((test_translations_ba - test_translations_ba_pred) ** 2)\n",
    "test_t_rmse_ba = np.sqrt(test_t_mse_ba)\n",
    "test_t_mae_ba = np.mean(np.abs(test_translations_ba - test_translations_ba_pred))\n",
    "\n",
    "# filename = 'icp_matrix.txt'\n",
    "# with open(filename,'w') as f:\n",
    "#     f.write('==FINAL TEST==\\n')\n",
    "#     f.write('A--------->B\\n')\n",
    "#     f.write('EPOCH:: %d, Loss: %f, Cycle Loss: %f, MSE: %f, RMSE: %f, MAE: %f, rot_MSE: %f, rot_RMSE: %f, '\n",
    "#                     'rot_MAE: %f, trans_MSE: %f, trans_RMSE: %f, trans_MAE: %f\\n'\n",
    "#                     % (0, test_loss, test_cycle_loss, test_mse_ab, test_rmse_ab, test_mae_ab,\n",
    "#                         test_r_mse_ab, test_r_rmse_ab,\n",
    "#                         test_r_mae_ab, test_t_mse_ab, test_t_rmse_ab, test_t_mae_ab))\n",
    "#     f.write('B--------->A\\n')\n",
    "#     f.write('EPOCH:: %d, Loss: %f, MSE: %f, RMSE: %f, MAE: %f, rot_MSE: %f, rot_RMSE: %f, '\n",
    "#                     'rot_MAE: %f, trans_MSE: %f, trans_RMSE: %f, trans_MAE: %f\\n'\n",
    "#                     % (0, test_loss, test_mse_ba, test_rmse_ba, test_mae_ba, test_r_mse_ba, test_r_rmse_ba,\n",
    "#                         test_r_mae_ba, test_t_mse_ba, test_t_rmse_ba, test_t_mae_ba))\n",
    "print('==FINAL TEST==')\n",
    "print('A--------->B')\n",
    "print('EPOCH:: %d, Loss: %f, Cycle Loss: %f, MSE: %f, RMSE: %f, MAE: %f, rot_MSE: %f, rot_RMSE: %f, '\n",
    "                  'rot_MAE: %f, trans_MSE: %f, trans_RMSE: %f, trans_MAE: %f'\n",
    "                  % (-1, test_loss, test_cycle_loss, test_mse_ab, test_rmse_ab, test_mae_ab,\n",
    "                     test_r_mse_ab, test_r_rmse_ab,\n",
    "                     test_r_mae_ab, test_t_mse_ab, test_t_rmse_ab, test_t_mae_ab))\n",
    "print('B--------->A')\n",
    "print('EPOCH:: %d, Loss: %f, MSE: %f, RMSE: %f, MAE: %f, rot_MSE: %f, rot_RMSE: %f, '\n",
    "                  'rot_MAE: %f, trans_MSE: %f, trans_RMSE: %f, trans_MAE: %f'\n",
    "                  % (-1, test_loss, test_mse_ba, test_rmse_ba, test_mae_ba, test_r_mse_ba, test_r_rmse_ba,\n",
    "                     test_r_mae_ba, test_t_mse_ba, test_t_rmse_ba, test_t_mae_ba))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f5dfeb23bcc4d3bb60ed74414e28f1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "src, target, rotation_ab, translation_ab, rotation_ba, translation_ba, euler_ab, euler_ba, _ = pc[0]\n",
    "src = PointCloud(src.T, columns=[\"x\", \"y\", \"z\"])\n",
    "target = PointCloud(target.T, columns=[\"x\", \"y\", \"z\"])\n",
    "# Create simpleICP object, add point clouds, and run algorithm!\n",
    "icp = SimpleICP()\n",
    "icp.add_point_clouds(target, src)\n",
    "H, X_mov_transformed, rigid_body_transformation_params = icp.run(max_overlap_distance=1)\n",
    "visualize_pointcloud(target, X_mov_transformed, .05, R=H[:3,:3], t=H[:3, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RigidBodyParameters(alpha1=Parameter(initial_value=0.10750457315556647, observed_value=0.0, observation_weight=0.0, estimated_value=0.10750457315556647, estimated_uncertainty=1.4988235443417607e-05, scale_for_logging=57.29577951308232), alpha2=Parameter(initial_value=-0.16308165329963306, observed_value=0.0, observation_weight=0.0, estimated_value=-0.16308165329963306, estimated_uncertainty=1.5435543974382083e-05, scale_for_logging=57.29577951308232), alpha3=Parameter(initial_value=0.011883495138386518, observed_value=0.0, observation_weight=0.0, estimated_value=0.011883495138386518, estimated_uncertainty=2.3124539773152144e-05, scale_for_logging=57.29577951308232), tx=Parameter(initial_value=1.0953829982311267, observed_value=0.0, observation_weight=0.0, estimated_value=1.0953829982311267, estimated_uncertainty=4.9242055285358574e-05, scale_for_logging=1), ty=Parameter(initial_value=0.4325993321892744, observed_value=0.0, observation_weight=0.0, estimated_value=0.4325993321892744, estimated_uncertainty=4.7021331722496086e-05, scale_for_logging=1), tz=Parameter(initial_value=0.4725850417356405, observed_value=0.0, observation_weight=0.0, estimated_value=0.4725850417356405, estimated_uncertainty=3.296648002048798e-05, scale_for_logging=1))\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Export to disk\"\"\"\n",
    "\n",
    "\n",
    "def export_mesh_to_obj(path, vertices, faces, vertices2):\n",
    "    \"\"\"\n",
    "    exports mesh as OBJ\n",
    "    :param path: output path for the OBJ file\n",
    "    :param vertices: Nx3 vertices\n",
    "    :param faces: Mx3 faces\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    # write vertices starting with \"v \"\n",
    "    # write faces starting with \"f \"\n",
    "\n",
    "    # ###############\n",
    "    # DONE: Implement\n",
    "    v = \"\"\n",
    "    f = \"\"\n",
    "    v2 = \"\"\n",
    "    file = open(path, 'w+')\n",
    "\n",
    "    if vertices is not None:\n",
    "        for vertice in vertices:\n",
    "            v = v + \"v \"\n",
    "            for i in vertice:\n",
    "                v = v + str(i) + \" \"\n",
    "            v = v + \"104 240 234\\n\"\n",
    "            # v = v + \"\\n\"\n",
    "        \n",
    "    count = 1\n",
    "    if faces is not None:\n",
    "        for face in faces:\n",
    "            f = f + \"f \"\n",
    "            for i in face:\n",
    "                f = f + str(i+1) + \" \"\n",
    "            f = f + \"\\n\"\n",
    "\n",
    "    if vertices2 is not None:\n",
    "        for vertice2 in vertices2:\n",
    "            v2 = v2 + \"v \"\n",
    "            for i in vertice2:\n",
    "                v2 = v2 + str(i) + \" \"\n",
    "            v2 = v2 + \"252 133 81\\n\"  \n",
    "            # v2 = v2 + \"\\n\"    \n",
    "    file.write(v)\n",
    "    file.write(v2)\n",
    "    file.write(f)\n",
    "    file.close()\n",
    "        \n",
    "    # ###############\n",
    "\n",
    "\n",
    "def export_pointcloud_to_obj(path, pointcloud, pointcloud2=None):\n",
    "    \"\"\"\n",
    "    export pointcloud as OBJ\n",
    "    :param path: output path for the OBJ file\n",
    "    :param pointcloud: Nx3 points\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    # ###############\n",
    "    # DONE: Implement\n",
    "    export_mesh_to_obj(path, pointcloud, None, pointcloud2)\n",
    "    # ###############\n",
    "\n",
    "print(rigid_body_transformation_params)\n",
    "export_pointcloud_to_obj('../icp_test.obj', target.X, X_mov_transformed)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('python39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "beda123ca6d46414026d3c59f732de1f5fb19d6ba2f32753cc4223591eed0a9d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
