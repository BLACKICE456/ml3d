{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use DCP as initializer\n",
    "---\n",
    "## Define dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "299\n",
      "299\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from dcp import train, test\n",
    "from data import SceneNet\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "sys.path.append(\"dcp-master\")\n",
    "from model import DCP\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "trainDataset = SceneNet(1024, \"train\")\n",
    "valDataset = SceneNet(1024, \"val\")\n",
    "train_loader = DataLoader(trainDataset, batch_size=32, shuffle=False, drop_last=False)\n",
    "test_loader = DataLoader(valDataset, batch_size=1, shuffle=False, drop_last=False)\n",
    "print(len(trainDataset))\n",
    "print(len(valDataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "        \"model_path\": 'checkpoints/dcp_v1/models/model.best.t7',\n",
    "        # \"model_path\": 'dcp-master/pretrained/dcp_v2.t7',\n",
    "        \"exp_name\":\"dcp_v1\",\n",
    "         \"model\":\"dcp\", \n",
    "         \"emb_nn\":\"dgcnn\", \n",
    "         \"pointer\":\"identity\", \n",
    "         \"head\":\"svd\", \n",
    "         \"eval\": True,\n",
    "         'emb_dims': 512,\n",
    "         'cycle': False,\n",
    "         'use_sgd': False,\n",
    "         'lr': 0.001,\n",
    "         'epochs': 250,\n",
    "         'n_blocks': 1,\n",
    "         'dropout': 0.0,\n",
    "         'ff_dims': 1024,\n",
    "         'n_heads': 4,\n",
    "         'use_sgd': False,\n",
    "         'momentum': 0.9,\n",
    "        }\n",
    "net = DCP(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCP Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:02<00:00, 144.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: -train- Loss: 140.252760,  -val- Loss: 20.018235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:01<00:00, 160.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: -train- Loss: 82.563642,  -val- Loss: 39.954441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:02<00:00, 147.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: -train- Loss: 99.874546,  -val- Loss: 57.535624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:02<00:00, 144.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: -train- Loss: 85.799290,  -val- Loss: 55.117462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:01<00:00, 156.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: -train- Loss: 84.325084,  -val- Loss: 43.142603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:01<00:00, 153.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: -train- Loss: 76.980802,  -val- Loss: 38.269503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:02<00:00, 144.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: -train- Loss: 95.143735,  -val- Loss: 34.055507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:02<00:00, 148.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: -train- Loss: 107.245315,  -val- Loss: 32.774786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:02<00:00, 147.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: -train- Loss: 71.150799,  -val- Loss: 30.768770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:02<00:00, 144.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: -train- Loss: 63.216900,  -val- Loss: 26.385417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:02<00:00, 144.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: -train- Loss: 59.681221,  -val- Loss: 37.592841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:02<00:00, 142.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: -train- Loss: 57.215170,  -val- Loss: 27.649919\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/root/autodl-tmp/ml3d/project/dcp_icp.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bregion-4.autodl.com/root/autodl-tmp/ml3d/project/dcp_icp.ipynb#ch0000005vscode-remote?line=0'>1</a>\u001b[0m net \u001b[39m=\u001b[39m DCP(args)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bregion-4.autodl.com/root/autodl-tmp/ml3d/project/dcp_icp.ipynb#ch0000005vscode-remote?line=1'>2</a>\u001b[0m train(args, net, train_loader, test_loader)\n",
      "File \u001b[0;32m~/autodl-tmp/ml3d/project/dcp.py:186\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(args, net, train_loader, test_loader)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(args[\u001b[39m'\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[1;32m    181\u001b[0m     scheduler\u001b[39m.\u001b[39mstep()\n\u001b[1;32m    182\u001b[0m     train_loss, train_cycle_loss, \\\n\u001b[1;32m    183\u001b[0m     train_mse_ab, train_mae_ab, train_mse_ba, train_mae_ba, train_rotations_ab, train_translations_ab, \\\n\u001b[1;32m    184\u001b[0m     train_rotations_ab_pred, \\\n\u001b[1;32m    185\u001b[0m     train_translations_ab_pred, train_rotations_ba, train_translations_ba, train_rotations_ba_pred, \\\n\u001b[0;32m--> 186\u001b[0m     train_translations_ba_pred, train_eulers_ab, train_eulers_ba \u001b[39m=\u001b[39m train_one_epoch(args, net, train_loader, opt)\n\u001b[1;32m    187\u001b[0m     test_loss, test_cycle_loss, \\\n\u001b[1;32m    188\u001b[0m     test_mse_ab, test_mae_ab, test_mse_ba, test_mae_ba, test_rotations_ab, test_translations_ab, \\\n\u001b[1;32m    189\u001b[0m     test_rotations_ab_pred, \\\n\u001b[1;32m    190\u001b[0m     test_translations_ab_pred, test_rotations_ba, test_translations_ba, test_rotations_ba_pred, \\\n\u001b[1;32m    191\u001b[0m     test_translations_ba_pred, test_eulers_ab, test_eulers_ba \u001b[39m=\u001b[39m test_one_epoch(args, net, test_loader)\n\u001b[1;32m    192\u001b[0m     train_rmse_ab \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqrt(train_mse_ab)\n",
      "File \u001b[0;32m~/autodl-tmp/ml3d/project/dcp.py:69\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(args, net, train_loader, opt)\u001b[0m\n\u001b[1;32m     65\u001b[0m eulers_ba \u001b[39m=\u001b[39m []\n\u001b[1;32m     67\u001b[0m net \u001b[39m=\u001b[39m net\u001b[39m.\u001b[39mcuda()\n\u001b[0;32m---> 69\u001b[0m \u001b[39mfor\u001b[39;00m src, target, rotation_ab, translation_ab, rotation_ba, translation_ba, euler_ab, euler_ba \u001b[39min\u001b[39;00m train_loader:\n\u001b[1;32m     70\u001b[0m     \u001b[39m# src = torch.tensor(src)\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     \u001b[39m# target = torch.tensor(target)\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     src \u001b[39m=\u001b[39m src\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m     73\u001b[0m     target \u001b[39m=\u001b[39m target\u001b[39m.\u001b[39mcuda()\n",
      "File \u001b[0;32m~/miniconda3/envs/ml3d/lib/python3.9/site-packages/torch/utils/data/dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 652\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    653\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    654\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    655\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    656\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/ml3d/lib/python3.9/site-packages/torch/utils/data/dataloader.py:692\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    691\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 692\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    693\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    694\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml3d/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/ml3d/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/autodl-tmp/ml3d/project/data.py:88\u001b[0m, in \u001b[0;36mSceneNet.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     86\u001b[0m     points1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m][index][\u001b[39m0\u001b[39m]\n\u001b[1;32m     87\u001b[0m     points2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m][index][\u001b[39m1\u001b[39m]\n\u001b[0;32m---> 88\u001b[0m T \u001b[39m=\u001b[39m transformation(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata[\u001b[39m'\u001b[39;49m\u001b[39mscenes\u001b[39;49m\u001b[39m'\u001b[39;49m][index], (index\u001b[39m%\u001b[39;49m\u001b[39m299\u001b[39;49m)\u001b[39m*\u001b[39;49m\u001b[39m25\u001b[39;49m, (index\u001b[39m%\u001b[39;49m\u001b[39m299\u001b[39;49m)\u001b[39m*\u001b[39;49m\u001b[39m25\u001b[39;49m\u001b[39m+\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minterval\u001b[39m*\u001b[39;49m\u001b[39m25\u001b[39;49m)\n\u001b[1;32m     89\u001b[0m R_ab \u001b[39m=\u001b[39m T[:\u001b[39m3\u001b[39m,:\u001b[39m3\u001b[39m]\n\u001b[1;32m     90\u001b[0m R_ba \u001b[39m=\u001b[39m R_ab\u001b[39m.\u001b[39mT\n",
      "File \u001b[0;32m~/autodl-tmp/ml3d/project/transformation.py:62\u001b[0m, in \u001b[0;36mtransformation\u001b[0;34m(traj_index, first_frame, second_frame)\u001b[0m\n\u001b[1;32m     56\u001b[0m second_pose \u001b[39m=\u001b[39m {\n\u001b[1;32m     57\u001b[0m      \u001b[39m'\u001b[39m\u001b[39mlookat\u001b[39m\u001b[39m'\u001b[39m:np\u001b[39m.\u001b[39marray([second_lookat_x,second_lookat_y,second_lookat_z]),\n\u001b[1;32m     58\u001b[0m      \u001b[39m'\u001b[39m\u001b[39mcamera\u001b[39m\u001b[39m'\u001b[39m:np\u001b[39m.\u001b[39marray([second_camera_x,second_camera_y,second_camera_z])\n\u001b[1;32m     59\u001b[0m }\n\u001b[1;32m     61\u001b[0m r1 \u001b[39m=\u001b[39m world_to_camera_with_pose(first_pose)\n\u001b[0;32m---> 62\u001b[0m r2 \u001b[39m=\u001b[39m world_to_camera_with_pose(second_pose)\n\u001b[1;32m     63\u001b[0m transformation \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(r2, np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39minv(r1))\n\u001b[1;32m     65\u001b[0m file\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/autodl-tmp/ml3d/project/transformation.py:15\u001b[0m, in \u001b[0;36mworld_to_camera_with_pose\u001b[0;34m(view_pose)\u001b[0m\n\u001b[1;32m     13\u001b[0m R \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdiag(np\u001b[39m.\u001b[39mones(\u001b[39m4\u001b[39m))\n\u001b[1;32m     14\u001b[0m R[\u001b[39m2\u001b[39m,:\u001b[39m3\u001b[39m] \u001b[39m=\u001b[39m normalize(lookat_pose \u001b[39m-\u001b[39m camera_pose)\n\u001b[0;32m---> 15\u001b[0m R[\u001b[39m0\u001b[39m,:\u001b[39m3\u001b[39m] \u001b[39m=\u001b[39m normalize(np\u001b[39m.\u001b[39;49mcross(R[\u001b[39m2\u001b[39;49m,:\u001b[39m3\u001b[39;49m],up))\n\u001b[1;32m     16\u001b[0m R[\u001b[39m1\u001b[39m,:\u001b[39m3\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mnormalize(np\u001b[39m.\u001b[39mcross(R[\u001b[39m0\u001b[39m,:\u001b[39m3\u001b[39m],R[\u001b[39m2\u001b[39m,:\u001b[39m3\u001b[39m]))\n\u001b[1;32m     17\u001b[0m T \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdiag(np\u001b[39m.\u001b[39mones(\u001b[39m4\u001b[39m))\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mcross\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml3d/lib/python3.9/site-packages/numpy/core/numeric.py:1661\u001b[0m, in \u001b[0;36mcross\u001b[0;34m(a, b, axisa, axisb, axisc, axis)\u001b[0m\n\u001b[1;32m   1656\u001b[0m \u001b[39mif\u001b[39;00m b\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[1;32m   1657\u001b[0m     \u001b[39m# cp0 = a1 * b2 - a2 * b1\u001b[39;00m\n\u001b[1;32m   1658\u001b[0m     \u001b[39m# cp1 = a2 * b0 - a0 * b2\u001b[39;00m\n\u001b[1;32m   1659\u001b[0m     \u001b[39m# cp2 = a0 * b1 - a1 * b0\u001b[39;00m\n\u001b[1;32m   1660\u001b[0m     multiply(a1, b2, out\u001b[39m=\u001b[39mcp0)\n\u001b[0;32m-> 1661\u001b[0m     tmp \u001b[39m=\u001b[39m array(a2 \u001b[39m*\u001b[39;49m b1)\n\u001b[1;32m   1662\u001b[0m     cp0 \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m tmp\n\u001b[1;32m   1663\u001b[0m     multiply(a2, b0, out\u001b[39m=\u001b[39mcp1)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "train(args, net, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCP Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:06<00:00, 44.01it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==FINAL TEST==\n",
      "A--------->B\n",
      "EPOCH:: 1, Loss: 18.654200, Cycle Loss: 0.000000, MSE: 2.038408, RMSE: 1.427728, MAE: 1.028823, rot_MSE: 24.127089, rot_RMSE: 4.911933, rot_MAE: 3.244349, trans_MSE: 0.040257, trans_RMSE: 0.200640, trans_MAE: 0.131760\n",
      "B--------->A\n",
      "EPOCH:: 1, Loss: 18.654200, MSE: 2.038408, RMSE: 1.427728, MAE: 1.028205, rot_MSE: 24.172363, rot_RMSE: 4.916540, rot_MAE: 3.263173, trans_MSE: 0.039524, trans_RMSE: 0.198806, trans_MAE: 0.130251\n",
      "[[ 0.99502903  0.08289655  0.05518261]\n",
      " [-0.08219942  0.99650586 -0.01479   ]\n",
      " [-0.05621544  0.01018047  0.9983666 ]]\n",
      "[-0.40880036 -0.01387513  0.21633339]\n"
     ]
    }
   ],
   "source": [
    "net.load_state_dict(torch.load(args['model_path']), strict=False)\n",
    "\n",
    "r, t = test(args, net, test_loader)\n",
    "print(r[0])\n",
    "print(t[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.99980277 -0.00443393  0.0193574 ]\n",
      " [ 0.00360092  0.9990747   0.04285804]\n",
      " [-0.01952951 -0.04277989  0.9988936 ]]\n",
      "[-0.0209675   0.00747702  0.02584793]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "761d942498f842a79df2fb545f19dd78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ac3caf9ca9f45e795a9e2702ac8684c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0709ab995ff043339e9192c9331c685a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import k3d\n",
    "from util import transform_point_cloud\n",
    "\n",
    "def visualize_pointcloud(point_cloud1, point_size, point_cloud2=None, flip_axes=False, name='point_cloud', R=None, t=None):\n",
    "    plot = k3d.plot(name=name, grid_visible=False, grid=(-0.55, -0.55, -0.55, 0.55, 0.55, 0.55))\n",
    "    plt_points1 = k3d.points(positions=point_cloud1, point_size=point_size, color=0xd0d0d0)\n",
    "    plot += plt_points1\n",
    "    plt_points1.shader = '3d'\n",
    "    if point_cloud2 is not None:\n",
    "        plt_points2 = k3d.points(positions=point_cloud2, point_size=point_size, color=0x0dd00d)\n",
    "        plot += plt_points2\n",
    "        plt_points2.shader = '3d'\n",
    "    plot.display()\n",
    "\n",
    "def transform(point_cloud, R=None, t=None):\n",
    "    t_broadcast = np.broadcast_to(t[:, np.newaxis], (3, point_cloud.shape[0]))\n",
    "    return (R @ point_cloud.T + t_broadcast).T\n",
    "\n",
    "\n",
    "src, target, rotation_ab, translation_ab, rotation_ba, translation_ba, euler_ab, euler_ba = valDataset[20]\n",
    "print(rotation_ab)\n",
    "print(translation_ab)\n",
    "# print(points1.shape)\n",
    "transformed_src = transform_point_cloud(torch.tensor(src), torch.tensor(r[20]).unsqueeze(0), torch.tensor(t[20]).unsqueeze(0)).T\n",
    "transformed_src2 = transform_point_cloud(torch.tensor(src), torch.tensor(rotation_ab).unsqueeze(0), torch.tensor(translation_ab).unsqueeze(0)).T\n",
    "# transformed_src1 = transform_point_cloud(torch.tensor(src), r1, t1).T\n",
    "# visualize_pointcloud(target.T, .03, transformed_src1)\n",
    "visualize_pointcloud(target.T, .03, transformed_src)\n",
    "visualize_pointcloud(target.T, .03, transformed_src2)\n",
    "visualize_pointcloud(src.T, .03, target.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICP Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [18:26<00:00,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==FINAL TEST==\n",
      "A--------->B\n",
      "EPOCH:: -1, Loss: 0.064569, Cycle Loss: 0.000000, MSE: 0.012127, RMSE: 0.110121, MAE: 0.022179, rot_MSE: 26.837176, rot_RMSE: 5.180461, rot_MAE: 3.329714, trans_MSE: 0.060489, trans_RMSE: 0.245946, trans_MAE: 0.141536\n",
      "B--------->A\n",
      "EPOCH:: -1, Loss: 0.064569, MSE: 0.012127, RMSE: 0.110121, MAE: 0.021606, rot_MSE: 26.886614, rot_RMSE: 5.185230, rot_MAE: 3.342849, trans_MSE: 0.059994, trans_RMSE: 0.244936, trans_MAE: 0.140190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from icp import test\n",
    "\n",
    "valDataset = SceneNet(1024, \"val\", icp=True, r=r, t=t)\n",
    "print(len(valDataset))\n",
    "r_icp, t_icp = test(valDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.99980277 -0.00443393  0.0193574 ]\n",
      " [ 0.00360092  0.9990747   0.04285804]\n",
      " [-0.01952951 -0.04277989  0.9988936 ]]\n",
      "[-0.0209675   0.00747702  0.02584793]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9a2b292a580442cbdebc527fd623799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b5193c73d4c4cf5863bab742e38627f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb1c7c5778af49a78aef541dd44b4307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "src, target, rotation_ab, translation_ab, rotation_ba, translation_ba, euler_ab, euler_ba = valDataset[20]\n",
    "print(rotation_ab)\n",
    "print(translation_ab)\n",
    "# print(points1.shape)\n",
    "transformed_src = transform_point_cloud(torch.tensor(src).double(), torch.tensor(r_icp[20]).unsqueeze(0).double(), torch.tensor(t_icp[20]).unsqueeze(0).double()).T\n",
    "transformed_src2 = transform_point_cloud(torch.tensor(src), torch.tensor(rotation_ab).unsqueeze(0), torch.tensor(translation_ab).unsqueeze(0)).T\n",
    "# transformed_src1 = transform_point_cloud(torch.tensor(src), r1, t1).T\n",
    "# visualize_pointcloud(target.T, .03, transformed_src1)\n",
    "visualize_pointcloud(target.T, .03, transformed_src)\n",
    "visualize_pointcloud(target.T, .03, transformed_src2)\n",
    "visualize_pointcloud(src.T, .03, target.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Export to disk\"\"\"\n",
    "\n",
    "\n",
    "def export_mesh_to_obj(path, vertices, faces, vertices2):\n",
    "    \"\"\"\n",
    "    exports mesh as OBJ\n",
    "    :param path: output path for the OBJ file\n",
    "    :param vertices: Nx3 vertices\n",
    "    :param faces: Mx3 faces\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    # write vertices starting with \"v \"\n",
    "    # write faces starting with \"f \"\n",
    "\n",
    "    # ###############\n",
    "    # DONE: Implement\n",
    "    v = \"\"\n",
    "    f = \"\"\n",
    "    v2 = \"\"\n",
    "    file = open(path, 'w+')\n",
    "\n",
    "    if vertices is not None:\n",
    "        for vertice in vertices:\n",
    "            v = v + \"v \"\n",
    "            for i in vertice:\n",
    "                v = v + str(i) + \" \"\n",
    "            v = v + \"0.407843 0.941176 0.917647\\n\"\n",
    "            # v = v + \"\\n\"\n",
    "        \n",
    "    count = 1\n",
    "    if faces is not None:\n",
    "        for face in faces:\n",
    "            f = f + \"f \"\n",
    "            for i in face:\n",
    "                f = f + str(i+1) + \" \"\n",
    "            f = f + \"\\n\"\n",
    "\n",
    "    if vertices2 is not None:\n",
    "        for vertice2 in vertices2:\n",
    "            v2 = v2 + \"v \"\n",
    "            for i in vertice2:\n",
    "                v2 = v2 + str(i[0]) + \" \"\n",
    "            v2 = v2 + \"0.98823529 0.5215686 0.317647\\n\"  \n",
    "            # v2 = v2 + \"\\n\"    \n",
    "    file.write(v)\n",
    "    file.write(v2)\n",
    "    file.write(f)\n",
    "    file.close()\n",
    "        \n",
    "    # ###############\n",
    "\n",
    "\n",
    "def export_pointcloud_to_obj(path, pointcloud, pointcloud2=None):\n",
    "    \"\"\"\n",
    "    export pointcloud as OBJ\n",
    "    :param path: output path for the OBJ file\n",
    "    :param pointcloud: Nx3 points\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    # ###############\n",
    "    # DONE: Implement\n",
    "    export_mesh_to_obj(path, pointcloud, None, pointcloud2)\n",
    "    # ###############\n",
    "\n",
    "# print(rigid_body_transformation_params)\n",
    "valDataset = SceneNet(10000, \"val\", icp=True, r=r, t=t)\n",
    "for i in range(len(valDataset)):\n",
    "    src, target, rotation_ab, translation_ab, rotation_ba, translation_ba, euler_ab, euler_ba = valDataset[i]\n",
    "    transformed_src = transform_point_cloud(torch.tensor(src).double(), torch.tensor(r_icp[i]).unsqueeze(0).double(), torch.tensor(t_icp[i]).unsqueeze(0).double()).T\n",
    "    export_pointcloud_to_obj('56_'+str(i)+'.obj', target.T, np.array(transformed_src))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('python39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "beda123ca6d46414026d3c59f732de1f5fb19d6ba2f32753cc4223591eed0a9d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
