{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use DCP as initializer\n",
    "---\n",
    "## Define dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dcp import train, test\n",
    "from data import SceneNet\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "sys.path.append(\"dcp-master\")\n",
    "from model import DCP\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import k3d\n",
    "from util import transform_point_cloud\n",
    "\n",
    "def visualize_pointcloud(point_cloud1, point_size, point_cloud2=None, flip_axes=False, name='point_cloud', R=None, t=None):\n",
    "    plot = k3d.plot(name=name, grid_visible=False, grid=(-0.55, -0.55, -0.55, 0.55, 0.55, 0.55))\n",
    "    plt_points1 = k3d.points(positions=point_cloud1, point_size=point_size, color=0xd0d0d0)\n",
    "    plot += plt_points1\n",
    "    plt_points1.shader = '3d'\n",
    "    if point_cloud2 is not None:\n",
    "        plt_points2 = k3d.points(positions=point_cloud2, point_size=point_size, color=0x0dd00d)\n",
    "        plot += plt_points2\n",
    "        plt_points2.shader = '3d'\n",
    "    plot.display()\n",
    "\n",
    "def transform(point_cloud, R=None, t=None):\n",
    "    t_broadcast = np.broadcast_to(t[:, np.newaxis], (3, point_cloud.shape[0]))\n",
    "    return (R @ point_cloud.T + t_broadcast).T\n",
    "\n",
    "trainDataset = SceneNet(1024, \"train\", filter=False)\n",
    "valDataset = SceneNet(1024, \"val\", filter=False)\n",
    "train_loader = DataLoader(trainDataset, batch_size=32, shuffle=False, drop_last=False)\n",
    "test_loader = DataLoader(valDataset, batch_size=1, shuffle=False, drop_last=False)\n",
    "print(len(trainDataset))\n",
    "print(len(valDataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "        \"model_path\": 'checkpoints/dcp_v1/models/model.best.t7',\n",
    "        # \"model_path\": 'dcp-master/pretrained/dcp_v2.t7',\n",
    "        \"exp_name\":\"dcp_v1\",\n",
    "         \"model\":\"dcp\", \n",
    "         \"emb_nn\":\"dgcnn\", \n",
    "         \"pointer\":\"identity\", \n",
    "         \"head\":\"svd\", \n",
    "         \"eval\": True,\n",
    "         'emb_dims': 512,\n",
    "         'cycle': False,\n",
    "         'use_sgd': False,\n",
    "         'lr': 0.001,\n",
    "         'epochs': 350,\n",
    "         'n_blocks': 1,\n",
    "         'dropout': 0.0,\n",
    "         'ff_dims': 1024,\n",
    "         'n_heads': 4,\n",
    "         'use_sgd': False,\n",
    "         'momentum': 0.9,\n",
    "        }\n",
    "net = DCP(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCP Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train(args, net, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCP Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load(args['model_path']), strict=False)\n",
    "\n",
    "r, t = test(args, net, test_loader)\n",
    "# print(r[0])\n",
    "# print(t[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "valDataset = SceneNet(20000, \"val\", filter=True)\n",
    "src, target, rotation_ab, translation_ab, rotation_ba, translation_ba, euler_ab, euler_ba = valDataset[42]\n",
    "# print(rotation_ab)\n",
    "# print(translation_ab)\n",
    "# print(points1.shape)\n",
    "transformed_src = transform_point_cloud(torch.tensor(src), torch.tensor(r[42]).unsqueeze(0), torch.tensor(t[42]).unsqueeze(0)).T\n",
    "transformed_src2 = transform_point_cloud(torch.tensor(src), torch.tensor(rotation_ab).unsqueeze(0), torch.tensor(translation_ab).unsqueeze(0)).T\n",
    "# transformed_src1 = transform_point_cloud(torch.tensor(src), r1, t1).T\n",
    "# visualize_pointcloud(target.T, .03, transformed_src1)\n",
    "visualize_pointcloud(target.T, .03, transformed_src)\n",
    "visualize_pointcloud(target.T, .03, transformed_src2)\n",
    "visualize_pointcloud(target.T, .03, src.T)\n",
    "# export_pointcloud_to_obj('71_origin_filter.obj', target.T, np.array(src.T))\n",
    "# export_pointcloud_to_obj('71_dcp_filter.obj', target.T, np.array(transformed_src))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICP Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icp import test\n",
    "\n",
    "valDataset = SceneNet(1024, \"val\", icp=True, r=r, t=t, filter=True)\n",
    "print(len(valDataset))\n",
    "r_icp, t_icp = test(valDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valDataset = SceneNet(20000, \"val\", icp=True, r=r, t=t, filter=True)\n",
    "src, target, rotation_ab, translation_ab, rotation_ba, translation_ba, euler_ab, euler_ba = valDataset[42]\n",
    "# print(rotation_ab)\n",
    "# print(translation_ab)\n",
    "# print(points1.shape)\n",
    "transformed_src = transform_point_cloud(torch.tensor(src).double(), torch.tensor(r_icp[0]).unsqueeze(0).double(), torch.tensor(t_icp[0]).unsqueeze(0).double()).T\n",
    "transformed_src2 = transform_point_cloud(torch.tensor(src), torch.tensor(rotation_ab).unsqueeze(0), torch.tensor(translation_ab).unsqueeze(0)).T\n",
    "# transformed_src1 = transform_point_cloud(torch.tensor(src), r1, t1).T\n",
    "# visualize_pointcloud(target.T, .03, transformed_src1)\n",
    "visualize_pointcloud(target.T, .03, transformed_src)\n",
    "visualize_pointcloud(target.T, .03, transformed_src2)\n",
    "visualize_pointcloud(target.T, .03, src.T)\n",
    "\n",
    "# export_pointcloud_to_obj('71_icp_filter.obj', target.T, np.array(transformed_src))\n",
    "# export_pointcloud_to_obj('24_icp.obj', target.T, np.array(transformed_src))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Export to disk\"\"\"\n",
    "\n",
    "\n",
    "def export_mesh_to_obj(path, vertices, faces, vertices2):\n",
    "    \"\"\"\n",
    "    exports mesh as OBJ\n",
    "    :param path: output path for the OBJ file\n",
    "    :param vertices: Nx3 vertices\n",
    "    :param faces: Mx3 faces\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    # write vertices starting with \"v \"\n",
    "    # write faces starting with \"f \"\n",
    "\n",
    "    # ###############\n",
    "    # DONE: Implement\n",
    "    v = \"\"\n",
    "    f = \"\"\n",
    "    v2 = \"\"\n",
    "    file = open(path, 'w+')\n",
    "\n",
    "    if vertices is not None:\n",
    "        for vertice in vertices:\n",
    "            v = v + \"v \"\n",
    "            for i in vertice:\n",
    "                v = v + str(i) + \" \"\n",
    "            v = v + \"0.098039 0.8117647 0.\\n\"\n",
    "            # v = v + \"\\n\"\n",
    "        \n",
    "    count = 1\n",
    "    if faces is not None:\n",
    "        for face in faces:\n",
    "            f = f + \"f \"\n",
    "            for i in face:\n",
    "                f = f + str(i+1) + \" \"\n",
    "            f = f + \"\\n\"\n",
    "\n",
    "    if vertices2 is not None:\n",
    "        for vertice2 in vertices2:\n",
    "            v2 = v2 + \"v \"\n",
    "            for i in vertice2:\n",
    "                v2 = v2 + str(i) + \" \"\n",
    "            v2 = v2 + \"0.717647 0.717647 0.717647\\n\"  \n",
    "            # v2 = v2 + \"\\n\"    \n",
    "    file.write(v)\n",
    "    file.write(v2)\n",
    "    file.write(f)\n",
    "    file.close()\n",
    "        \n",
    "    # ###############\n",
    "\n",
    "\n",
    "def export_pointcloud_to_obj(path, pointcloud, pointcloud2=None):\n",
    "    \"\"\"\n",
    "    export pointcloud as OBJ\n",
    "    :param path: output path for the OBJ file\n",
    "    :param pointcloud: Nx3 points\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    # ###############\n",
    "    # DONE: Implement\n",
    "    export_mesh_to_obj(path, pointcloud, None, pointcloud2)\n",
    "    # ###############\n",
    "\n",
    "# print(rigid_body_transformation_params)\n",
    "# valDataset = SceneNet(10000, \"val\", icp=True, r=r, t=t)\n",
    "# for i in range(len(valDataset)):\n",
    "#     src, target, rotation_ab, translation_ab, rotation_ba, translation_ba, euler_ab, euler_ba = valDataset[i]\n",
    "#     transformed_src = transform_point_cloud(torch.tensor(src).double(), torch.tensor(r_icp[i]).unsqueeze(0).double(), torch.tensor(t_icp[i]).unsqueeze(0).double()).T\n",
    "#     export_pointcloud_to_obj('56_'+str(i)+'.obj', target.T, np.array(transformed_src))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('python39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "beda123ca6d46414026d3c59f732de1f5fb19d6ba2f32753cc4223591eed0a9d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
