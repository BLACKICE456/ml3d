{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use DCP as initializer\n",
    "---\n",
    "## Define dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299\n",
      "299\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from dcp import train, test\n",
    "from data import SceneNet\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "sys.path.append(\"dcp-master\")\n",
    "from model import DCP\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import k3d\n",
    "from util import transform_point_cloud\n",
    "\n",
    "def visualize_pointcloud(point_cloud1, point_size, point_cloud2=None, flip_axes=False, name='point_cloud', R=None, t=None):\n",
    "    plot = k3d.plot(name=name, grid_visible=False, grid=(-0.55, -0.55, -0.55, 0.55, 0.55, 0.55))\n",
    "    plt_points1 = k3d.points(positions=point_cloud1, point_size=point_size, color=0xd0d0d0)\n",
    "    plot += plt_points1\n",
    "    plt_points1.shader = '3d'\n",
    "    if point_cloud2 is not None:\n",
    "        plt_points2 = k3d.points(positions=point_cloud2, point_size=point_size, color=0x0dd00d)\n",
    "        plot += plt_points2\n",
    "        plt_points2.shader = '3d'\n",
    "    plot.display()\n",
    "\n",
    "def transform(point_cloud, R=None, t=None):\n",
    "    t_broadcast = np.broadcast_to(t[:, np.newaxis], (3, point_cloud.shape[0]))\n",
    "    return (R @ point_cloud.T + t_broadcast).T\n",
    "\n",
    "trainDataset = SceneNet(1024, \"train\", filter=False)\n",
    "valDataset = SceneNet(1024, \"val\", filter=False)\n",
    "train_loader = DataLoader(trainDataset, batch_size=32, shuffle=False, drop_last=False)\n",
    "test_loader = DataLoader(valDataset, batch_size=1, shuffle=False, drop_last=False)\n",
    "print(len(trainDataset))\n",
    "print(len(valDataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "        \"model_path\": 'checkpoints/dcp_v1/models/model.best.t7',\n",
    "        # \"model_path\": 'dcp-master/pretrained/dcp_v2.t7',\n",
    "        \"exp_name\":\"dcp_v1\",\n",
    "         \"model\":\"dcp\", \n",
    "         \"emb_nn\":\"dgcnn\", \n",
    "         \"pointer\":\"identity\", \n",
    "         \"head\":\"svd\", \n",
    "         \"eval\": True,\n",
    "         'emb_dims': 512,\n",
    "         'cycle': False,\n",
    "         'use_sgd': False,\n",
    "         'lr': 0.001,\n",
    "         'epochs': 350,\n",
    "         'n_blocks': 1,\n",
    "         'dropout': 0.0,\n",
    "         'ff_dims': 1024,\n",
    "         'n_heads': 4,\n",
    "         'use_sgd': False,\n",
    "         'momentum': 0.9,\n",
    "        }\n",
    "net = DCP(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCP Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Adam\n",
      "Epoch 0: -train- Loss: 2.449583\n",
      "Epoch 1: -train- Loss: 1.590965\n",
      "Epoch 2: -train- Loss: 1.429964\n",
      "Epoch 3: -train- Loss: 1.294368\n",
      "Epoch 4: -train- Loss: 1.193472\n",
      "Epoch 5: -train- Loss: 1.087186\n",
      "Epoch 6: -train- Loss: 0.998024\n",
      "Epoch 7: -train- Loss: 0.930252\n",
      "Epoch 8: -train- Loss: 0.869094\n",
      "Epoch 9: -train- Loss: 0.816797\n",
      "Epoch 10: -train- Loss: 0.757757\n",
      "Epoch 11: -train- Loss: 0.750793\n",
      "Epoch 12: -train- Loss: 0.704089\n",
      "Epoch 13: -train- Loss: 0.754186\n",
      "Epoch 14: -train- Loss: 0.695255\n",
      "Epoch 15: -train- Loss: 0.687837\n",
      "Epoch 16: -train- Loss: 0.674733\n",
      "Epoch 17: -train- Loss: 0.569572\n",
      "Epoch 18: -train- Loss: 0.540720\n",
      "Epoch 19: -train- Loss: 0.495528\n",
      "Epoch 20: -train- Loss: 0.481770\n",
      "Epoch 21: -train- Loss: 0.496051\n",
      "Epoch 22: -train- Loss: 0.454704\n",
      "Epoch 23: -train- Loss: 0.471385\n",
      "Epoch 24: -train- Loss: 0.543799\n",
      "Epoch 25: -train- Loss: 0.590928\n",
      "Epoch 26: -train- Loss: 0.584126\n",
      "Epoch 27: -train- Loss: 0.735792\n",
      "Epoch 28: -train- Loss: 0.686409\n",
      "Epoch 29: -train- Loss: 0.635356\n",
      "Epoch 30: -train- Loss: 0.515939\n",
      "Epoch 31: -train- Loss: 0.475296\n",
      "Epoch 32: -train- Loss: 0.570931\n",
      "Epoch 33: -train- Loss: 0.545567\n",
      "Epoch 34: -train- Loss: 0.523017\n",
      "Epoch 35: -train- Loss: 0.483056\n",
      "Epoch 36: -train- Loss: 0.422877\n",
      "Epoch 37: -train- Loss: 0.402909\n",
      "Epoch 38: -train- Loss: 0.390445\n",
      "Epoch 39: -train- Loss: 0.367367\n",
      "Epoch 40: -train- Loss: 0.357063\n",
      "Epoch 41: -train- Loss: 0.342575\n",
      "Epoch 42: -train- Loss: 0.347845\n",
      "Epoch 43: -train- Loss: 0.339866\n",
      "Epoch 44: -train- Loss: 0.330039\n",
      "Epoch 45: -train- Loss: 0.325631\n",
      "Epoch 46: -train- Loss: 0.299818\n",
      "Epoch 47: -train- Loss: 0.288549\n",
      "Epoch 48: -train- Loss: 0.280661\n",
      "Epoch 49: -train- Loss: 0.272991\n",
      "Epoch 50: -train- Loss: 0.265486\n",
      "Epoch 51: -train- Loss: 0.260615\n",
      "Epoch 52: -train- Loss: 0.257223\n",
      "Epoch 53: -train- Loss: 0.254055\n",
      "Epoch 54: -train- Loss: 0.251750\n",
      "Epoch 55: -train- Loss: 0.273092\n",
      "Epoch 56: -train- Loss: 0.315292\n",
      "Epoch 57: -train- Loss: 0.298610\n",
      "Epoch 58: -train- Loss: 0.274265\n",
      "Epoch 59: -train- Loss: 0.277374\n",
      "Epoch 60: -train- Loss: 0.272128\n",
      "Epoch 61: -train- Loss: 0.260964\n",
      "Epoch 62: -train- Loss: 0.253254\n",
      "Epoch 63: -train- Loss: 0.248031\n",
      "Epoch 64: -train- Loss: 0.243769\n",
      "Epoch 65: -train- Loss: 0.241087\n",
      "Epoch 66: -train- Loss: 0.240402\n",
      "Epoch 67: -train- Loss: 0.240536\n",
      "Epoch 68: -train- Loss: 0.238709\n",
      "Epoch 69: -train- Loss: 0.237333\n",
      "Epoch 70: -train- Loss: 0.235631\n",
      "Epoch 71: -train- Loss: 0.233852\n",
      "Epoch 72: -train- Loss: 0.234967\n",
      "Epoch 73: -train- Loss: 0.232179\n",
      "Epoch 74: -train- Loss: 0.235600\n",
      "Epoch 75: -train- Loss: 0.234519\n",
      "Epoch 76: -train- Loss: 0.235717\n",
      "Epoch 77: -train- Loss: 0.229870\n",
      "Epoch 78: -train- Loss: 0.231639\n",
      "Epoch 79: -train- Loss: 0.224549\n",
      "Epoch 80: -train- Loss: 0.224150\n",
      "Epoch 81: -train- Loss: 0.219949\n",
      "Epoch 82: -train- Loss: 0.220630\n",
      "Epoch 83: -train- Loss: 0.221709\n",
      "Epoch 84: -train- Loss: 0.218741\n",
      "Epoch 85: -train- Loss: 0.220063\n",
      "Epoch 86: -train- Loss: 0.219906\n",
      "Epoch 87: -train- Loss: 0.213762\n",
      "Epoch 88: -train- Loss: 0.211436\n",
      "Epoch 89: -train- Loss: 0.211660\n",
      "Epoch 90: -train- Loss: 0.213439\n",
      "Epoch 91: -train- Loss: 0.210592\n",
      "Epoch 92: -train- Loss: 0.213090\n",
      "Epoch 93: -train- Loss: 0.211190\n",
      "Epoch 94: -train- Loss: 0.212478\n",
      "Epoch 95: -train- Loss: 0.213784\n",
      "Epoch 96: -train- Loss: 0.209386\n",
      "Epoch 97: -train- Loss: 0.206982\n",
      "Epoch 98: -train- Loss: 0.207628\n",
      "Epoch 99: -train- Loss: 0.206841\n",
      "Epoch 100: -train- Loss: 0.199479\n",
      "Epoch 101: -train- Loss: 0.196818\n",
      "Epoch 102: -train- Loss: 0.194947\n",
      "Epoch 103: -train- Loss: 0.193915\n",
      "Epoch 104: -train- Loss: 0.194886\n",
      "Epoch 105: -train- Loss: 0.193419\n",
      "Epoch 106: -train- Loss: 0.193547\n",
      "Epoch 107: -train- Loss: 0.206346\n",
      "Epoch 108: -train- Loss: 0.203065\n",
      "Epoch 109: -train- Loss: 0.250294\n",
      "Epoch 110: -train- Loss: 0.227611\n",
      "Epoch 111: -train- Loss: 0.216471\n",
      "Epoch 112: -train- Loss: 0.205825\n",
      "Epoch 113: -train- Loss: 0.201197\n",
      "Epoch 114: -train- Loss: 0.197621\n",
      "Epoch 115: -train- Loss: 0.195889\n",
      "Epoch 116: -train- Loss: 0.193492\n",
      "Epoch 117: -train- Loss: 0.191885\n",
      "Epoch 118: -train- Loss: 0.191048\n",
      "Epoch 119: -train- Loss: 0.189529\n",
      "Epoch 120: -train- Loss: 0.188744\n",
      "Epoch 121: -train- Loss: 0.188157\n",
      "Epoch 122: -train- Loss: 0.187606\n",
      "Epoch 123: -train- Loss: 0.187083\n",
      "Epoch 124: -train- Loss: 0.186827\n",
      "Epoch 125: -train- Loss: 0.186025\n",
      "Epoch 126: -train- Loss: 0.185548\n",
      "Epoch 127: -train- Loss: 0.185278\n",
      "Epoch 128: -train- Loss: 0.184150\n",
      "Epoch 129: -train- Loss: 0.183746\n",
      "Epoch 130: -train- Loss: 0.185477\n",
      "Epoch 131: -train- Loss: 0.184260\n",
      "Epoch 132: -train- Loss: 0.183106\n",
      "Epoch 133: -train- Loss: 0.182199\n",
      "Epoch 134: -train- Loss: 0.181518\n",
      "Epoch 135: -train- Loss: 0.182087\n",
      "Epoch 136: -train- Loss: 0.181122\n",
      "Epoch 137: -train- Loss: 0.180115\n",
      "Epoch 138: -train- Loss: 0.181465\n",
      "Epoch 139: -train- Loss: 0.180095\n",
      "Epoch 140: -train- Loss: 0.179065\n",
      "Epoch 141: -train- Loss: 0.178342\n",
      "Epoch 142: -train- Loss: 0.177830\n",
      "Epoch 143: -train- Loss: 0.177517\n",
      "Epoch 144: -train- Loss: 0.177243\n",
      "Epoch 145: -train- Loss: 0.176945\n",
      "Epoch 146: -train- Loss: 0.176703\n",
      "Epoch 147: -train- Loss: 0.176477\n",
      "Epoch 148: -train- Loss: 0.176244\n",
      "Epoch 149: -train- Loss: 0.176013\n",
      "Epoch 150: -train- Loss: 0.175793\n",
      "Epoch 151: -train- Loss: 0.175608\n",
      "Epoch 152: -train- Loss: 0.175894\n",
      "Epoch 153: -train- Loss: 0.176158\n",
      "Epoch 154: -train- Loss: 0.175902\n",
      "Epoch 155: -train- Loss: 0.175638\n",
      "Epoch 156: -train- Loss: 0.174947\n",
      "Epoch 157: -train- Loss: 0.174603\n",
      "Epoch 158: -train- Loss: 0.174380\n",
      "Epoch 159: -train- Loss: 0.174133\n",
      "Epoch 160: -train- Loss: 0.173966\n",
      "Epoch 161: -train- Loss: 0.173841\n",
      "Epoch 162: -train- Loss: 0.173721\n",
      "Epoch 163: -train- Loss: 0.173601\n",
      "Epoch 164: -train- Loss: 0.173485\n",
      "Epoch 165: -train- Loss: 0.173374\n",
      "Epoch 166: -train- Loss: 0.173270\n",
      "Epoch 167: -train- Loss: 0.173334\n",
      "Epoch 168: -train- Loss: 0.173734\n",
      "Epoch 169: -train- Loss: 0.173096\n",
      "Epoch 170: -train- Loss: 0.173033\n",
      "Epoch 171: -train- Loss: 0.172866\n",
      "Epoch 172: -train- Loss: 0.172733\n",
      "Epoch 173: -train- Loss: 0.172614\n",
      "Epoch 174: -train- Loss: 0.172497\n",
      "Epoch 175: -train- Loss: 0.172402\n",
      "Epoch 176: -train- Loss: 0.172468\n",
      "Epoch 177: -train- Loss: 0.172716\n",
      "Epoch 178: -train- Loss: 0.172239\n",
      "Epoch 179: -train- Loss: 0.172169\n",
      "Epoch 180: -train- Loss: 0.171964\n",
      "Epoch 181: -train- Loss: 0.171841\n",
      "Epoch 182: -train- Loss: 0.171718\n",
      "Epoch 183: -train- Loss: 0.171623\n",
      "Epoch 184: -train- Loss: 0.171673\n",
      "Epoch 185: -train- Loss: 0.171880\n",
      "Epoch 186: -train- Loss: 0.171401\n",
      "Epoch 187: -train- Loss: 0.171348\n",
      "Epoch 188: -train- Loss: 0.171159\n",
      "Epoch 189: -train- Loss: 0.171021\n",
      "Epoch 190: -train- Loss: 0.170897\n",
      "Epoch 191: -train- Loss: 0.170786\n",
      "Epoch 192: -train- Loss: 0.170885\n",
      "Epoch 193: -train- Loss: 0.171314\n",
      "Epoch 194: -train- Loss: 0.170751\n",
      "Epoch 195: -train- Loss: 0.170581\n",
      "Epoch 196: -train- Loss: 0.170378\n",
      "Epoch 197: -train- Loss: 0.170225\n",
      "Epoch 198: -train- Loss: 0.170076\n",
      "Epoch 199: -train- Loss: 0.169953\n",
      "Epoch 200: -train- Loss: 0.169884\n",
      "Epoch 201: -train- Loss: 0.169817\n",
      "Epoch 202: -train- Loss: 0.169751\n",
      "Epoch 203: -train- Loss: 0.169683\n",
      "Epoch 204: -train- Loss: 0.169619\n",
      "Epoch 205: -train- Loss: 0.169557\n",
      "Epoch 206: -train- Loss: 0.169630\n",
      "Epoch 207: -train- Loss: 0.170303\n",
      "Epoch 208: -train- Loss: 0.169614\n",
      "Epoch 209: -train- Loss: 0.169531\n",
      "Epoch 210: -train- Loss: 0.169452\n",
      "Epoch 211: -train- Loss: 0.169334\n",
      "Epoch 212: -train- Loss: 0.169243\n",
      "Epoch 213: -train- Loss: 0.169156\n",
      "Epoch 214: -train- Loss: 0.169074\n",
      "Epoch 215: -train- Loss: 0.168994\n",
      "Epoch 216: -train- Loss: 0.168920\n",
      "Epoch 217: -train- Loss: 0.168845\n",
      "Epoch 218: -train- Loss: 0.168772\n",
      "Epoch 219: -train- Loss: 0.168735\n",
      "Epoch 220: -train- Loss: 0.169169\n",
      "Epoch 221: -train- Loss: 0.168934\n",
      "Epoch 222: -train- Loss: 0.168837\n",
      "Epoch 223: -train- Loss: 0.168674\n",
      "Epoch 224: -train- Loss: 0.168550\n",
      "Epoch 225: -train- Loss: 0.168439\n",
      "Epoch 226: -train- Loss: 0.168340\n",
      "Epoch 227: -train- Loss: 0.168246\n",
      "Epoch 228: -train- Loss: 0.168158\n",
      "Epoch 229: -train- Loss: 0.168073\n",
      "Epoch 230: -train- Loss: 0.167992\n",
      "Epoch 231: -train- Loss: 0.167908\n",
      "Epoch 232: -train- Loss: 0.167829\n",
      "Epoch 233: -train- Loss: 0.167782\n",
      "Epoch 234: -train- Loss: 0.168125\n",
      "Epoch 235: -train- Loss: 0.167919\n",
      "Epoch 236: -train- Loss: 0.167724\n",
      "Epoch 237: -train- Loss: 0.167602\n",
      "Epoch 238: -train- Loss: 0.167498\n",
      "Epoch 239: -train- Loss: 0.167389\n",
      "Epoch 240: -train- Loss: 0.167291\n",
      "Epoch 241: -train- Loss: 0.167201\n",
      "Epoch 242: -train- Loss: 0.167115\n",
      "Epoch 243: -train- Loss: 0.167035\n",
      "Epoch 244: -train- Loss: 0.167012\n",
      "Epoch 245: -train- Loss: 0.167484\n",
      "Epoch 246: -train- Loss: 0.166922\n",
      "Epoch 247: -train- Loss: 0.166879\n",
      "Epoch 248: -train- Loss: 0.166749\n",
      "Epoch 249: -train- Loss: 0.166640\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train(args, net, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCP Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [00:02<00:00, 138.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==FINAL TEST==\n",
      "A--------->B\n",
      "EPOCH:: 1, Loss: 0.221726, Cycle Loss: 0.000000, MSE: 2.440407, RMSE: 1.562180, MAE: 1.020274, rot_MSE: 133.800919, rot_RMSE: 11.567235, rot_MAE: 4.192022, trans_MSE: 0.207820, trans_RMSE: 0.455872, trans_MAE: 0.182717\n",
      "B--------->A\n",
      "EPOCH:: 1, Loss: 0.221726, MSE: 2.440407, RMSE: 1.562180, MAE: 1.019776, rot_MSE: 133.268372, rot_RMSE: 11.544192, rot_MAE: 4.197148, trans_MSE: 0.202790, trans_RMSE: 0.450323, trans_MAE: 0.183058\n",
      "[[-0.0740141  -0.8204512   0.5669067 ]\n",
      " [-0.96988523  0.19149436  0.15051201]\n",
      " [-0.2320468  -0.53869325 -0.80991614]]\n",
      "[-0.9064398  1.7053207  6.9145575]\n"
     ]
    }
   ],
   "source": [
    "net.load_state_dict(torch.load(args['model_path']), strict=False)\n",
    "\n",
    "r, t = test(args, net, test_loader)\n",
    "print(r[0])\n",
    "print(t[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.999362   -0.01426313 -0.03274392]\n",
      " [ 0.01678179  0.9968136   0.07798077]\n",
      " [ 0.03152734 -0.07848052  0.996417  ]]\n",
      "[ 0.2539836  -0.06697565  0.05225628]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78de634c47ee49a0aefca9a3733dbcac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f477d8cafda14b53a1f6cc4d01152632",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ed0e65473cf4a968be60dea0bbbfc21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "valDataset = SceneNet(20000, \"val\", filter=True)\n",
    "src, target, rotation_ab, translation_ab, rotation_ba, translation_ba, euler_ab, euler_ba = valDataset[42]\n",
    "print(rotation_ab)\n",
    "print(translation_ab)\n",
    "# print(points1.shape)\n",
    "transformed_src = transform_point_cloud(torch.tensor(src), torch.tensor(r[42]).unsqueeze(0), torch.tensor(t[42]).unsqueeze(0)).T\n",
    "transformed_src2 = transform_point_cloud(torch.tensor(src), torch.tensor(rotation_ab).unsqueeze(0), torch.tensor(translation_ab).unsqueeze(0)).T\n",
    "# transformed_src1 = transform_point_cloud(torch.tensor(src), r1, t1).T\n",
    "# visualize_pointcloud(target.T, .03, transformed_src1)\n",
    "visualize_pointcloud(target.T, .03, transformed_src)\n",
    "visualize_pointcloud(target.T, .03, transformed_src2)\n",
    "visualize_pointcloud(target.T, .03, src.T)\n",
    "export_pointcloud_to_obj('71_origin_filter.obj', target.T, np.array(src.T))\n",
    "# export_pointcloud_to_obj('71_dcp_filter.obj', target.T, np.array(transformed_src))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICP Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/299 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "SimpleICPException",
     "evalue": "Too few correspondences! At least 6 correspondences are needed to estimate the 6 rigid body transformation parameters. The current number of correspondences is 0.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSimpleICPException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m/root/autodl-tmp/ml3d/project/dcp_icp.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bregion-4.autodl.com/root/autodl-tmp/ml3d/project/dcp_icp.ipynb#ch0000011vscode-remote?line=2'>3</a>\u001b[0m valDataset \u001b[39m=\u001b[39m SceneNet(\u001b[39m5000\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mval\u001b[39m\u001b[39m\"\u001b[39m, icp\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, r\u001b[39m=\u001b[39mr, t\u001b[39m=\u001b[39mt, \u001b[39mfilter\u001b[39m\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bregion-4.autodl.com/root/autodl-tmp/ml3d/project/dcp_icp.ipynb#ch0000011vscode-remote?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(valDataset))\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bregion-4.autodl.com/root/autodl-tmp/ml3d/project/dcp_icp.ipynb#ch0000011vscode-remote?line=4'>5</a>\u001b[0m r_icp, t_icp \u001b[39m=\u001b[39m test(valDataset)\n",
      "File \u001b[0;32m~/autodl-tmp/ml3d/project/icp.py:109\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtest\u001b[39m(dataset):\n\u001b[1;32m    105\u001b[0m     test_loss, test_cycle_loss, \\\n\u001b[1;32m    106\u001b[0m     test_mse_ab, test_mae_ab, test_mse_ba, test_mae_ba, test_rotations_ab, test_translations_ab, \\\n\u001b[1;32m    107\u001b[0m     test_rotations_ab_pred, \\\n\u001b[1;32m    108\u001b[0m     test_translations_ab_pred, test_rotations_ba, test_translations_ba, test_rotations_ba_pred, \\\n\u001b[0;32m--> 109\u001b[0m     test_translations_ba_pred, test_eulers_ab, test_eulers_ba \u001b[39m=\u001b[39m test_one_epoch(dataset)\n\u001b[1;32m    110\u001b[0m     test_rmse_ab \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqrt(test_mse_ab)\n\u001b[1;32m    111\u001b[0m     test_rmse_ba \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqrt(test_mse_ba)\n",
      "File \u001b[0;32m~/autodl-tmp/ml3d/project/icp.py:50\u001b[0m, in \u001b[0;36mtest_one_epoch\u001b[0;34m(pc)\u001b[0m\n\u001b[1;32m     48\u001b[0m icp \u001b[39m=\u001b[39m SimpleICP()\n\u001b[1;32m     49\u001b[0m icp\u001b[39m.\u001b[39madd_point_clouds(target, src)\n\u001b[0;32m---> 50\u001b[0m H, X_mov_transformed, rigid_body_transformation_params \u001b[39m=\u001b[39m icp\u001b[39m.\u001b[39;49mrun(max_overlap_distance\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     51\u001b[0m X_mov_transformed \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(X_mov_transformed)\n\u001b[1;32m     53\u001b[0m \u001b[39m# get the predicted rotations and translations\u001b[39;00m\n",
      "File \u001b[0;32m~/autodl-tmp/ml3d/project/simpleICP-master/simpleicp/simpleicp.py:183\u001b[0m, in \u001b[0;36mSimpleICP.run\u001b[0;34m(self, correspondences, neighbors, min_planarity, max_overlap_distance, min_change, max_iterations, distance_weights, rbp_observed_values, rbp_observation_weights, debug_dirpath)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[39m# cp.reject_wrt_to_angle_between_normals()  # not implemented yet\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[39mif\u001b[39;00m cp\u001b[39m.\u001b[39mnum_corr_pts \u001b[39m<\u001b[39m \u001b[39m6\u001b[39m:\n\u001b[0;32m--> 183\u001b[0m     \u001b[39mraise\u001b[39;00m SimpleICPException(\n\u001b[1;32m    184\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mToo few correspondences! At least 6 correspondences are needed to estimate \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    185\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mthe 6 rigid body transformation parameters. The current number of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    186\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcorrespondences is \u001b[39m\u001b[39m{\u001b[39;00mcp\u001b[39m.\u001b[39mnum_corr_pts\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    187\u001b[0m     )\n\u001b[1;32m    189\u001b[0m \u001b[39mif\u001b[39;00m debug_dirpath:\n\u001b[1;32m    190\u001b[0m     cp\u001b[39m.\u001b[39mwrite_xyz(\n\u001b[1;32m    191\u001b[0m         Path(debug_dirpath)\u001b[39m.\u001b[39mjoinpath(\n\u001b[1;32m    192\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39miteration\u001b[39m\u001b[39m{\u001b[39;00mit\u001b[39m:\u001b[39;00m\u001b[39m03d\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m_preoptim_correspondences.xyz\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    193\u001b[0m         )\n\u001b[1;32m    194\u001b[0m     )\n",
      "\u001b[0;31mSimpleICPException\u001b[0m: Too few correspondences! At least 6 correspondences are needed to estimate the 6 rigid body transformation parameters. The current number of correspondences is 0."
     ]
    }
   ],
   "source": [
    "from icp import test\n",
    "\n",
    "valDataset = SceneNet(1024, \"val\", icp=True, r=r, t=t, filter=True)\n",
    "print(len(valDataset))\n",
    "r_icp, t_icp = test(valDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==FINAL TEST==\n",
      "A--------->B\n",
      "EPOCH:: -1, Loss: 0.019120, Cycle Loss: 0.000000, MSE: 0.108258, RMSE: 0.329026, MAE: 0.244658, rot_MSE: 18.999233, rot_RMSE: 4.358811, rot_MAE: 3.614784, trans_MSE: 0.015213, trans_RMSE: 0.123343, trans_MAE: 0.108211\n",
      "B--------->A\n",
      "EPOCH:: -1, Loss: 0.019120, MSE: 0.108258, RMSE: 0.329026, MAE: 0.242663, rot_MSE: 3.591077, rot_RMSE: 1.895014, rot_MAE: 1.783000, trans_MSE: 0.015933, trans_RMSE: 0.126227, trans_MAE: 0.108450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# import open3d as o3d\n",
    "# import numpy as np\n",
    "# from torch.utils.data import Dataset\n",
    "# from transformation import transformation\n",
    "# from scipy.spatial.transform import Rotation\n",
    "# class TUM(Dataset):\n",
    "#         def __init__(self, size, r=None, t=None):\n",
    "#                 self.pcd1 = o3d.io.read_point_cloud(\"scenenet/val/0/71/1050_after_filtering.pcd\")\n",
    "#                 # print(self.index)\n",
    "\n",
    "#                 self.pcd2 = o3d.io.read_point_cloud(\"scenenet/val/0/71/1075_after_filtering.pcd\")\n",
    "\n",
    "#                 index1 = np.random.randint(len(self.pcd1.points), size=size)\n",
    "#                 index2 = np.random.randint(len(self.pcd2.points), size=size)\n",
    "\n",
    "#                 self.points1 = np.array(self.pcd1.points)[index1]\n",
    "#                 self.points2 = np.array(self.pcd2.points)[index2]\n",
    "                \n",
    "#                 self.points1 = transform(self.points1, r[42], t[42])\n",
    "#                 self.points1 = self.points1[np.newaxis,:]\n",
    "                \n",
    "    \n",
    "#         def __getitem__(self, index):\n",
    "#                 points1 = self.points1[index]\n",
    "#                 T = transformation(71, 1050, 1075)\n",
    "#                 R_ab = T[:3,:3]\n",
    "#                 R_ba = R_ab.T\n",
    "#                 translation_ab = T[:3,3]\n",
    "#                 translation_ba = -R_ba.dot(translation_ab)\n",
    "\n",
    "\n",
    "#                 euler_ab = npmat2euler(R_ab)\n",
    "#                 euler_ba = npmat2euler(R_ba)\n",
    "                \n",
    "#                 return points1.T.astype('float32'), self.points2.T.astype('float32'), R_ab.astype('float32'), \\\n",
    "#         translation_ab.astype('float32'), R_ba.astype('float32'), translation_ba.astype('float32'), \\\n",
    "#         euler_ab.astype('float32'), euler_ba.astype('float32')\n",
    "\n",
    "#         def __len__(self):\n",
    "#                 return len(self.points1)\n",
    "# def npmat2euler(mats, seq='zyx'):\n",
    "#     eulers = []\n",
    "#     r = Rotation.from_matrix(mats)\n",
    "#     eulers.append(r.as_euler(seq, degrees=True))\n",
    "#     return np.asarray(eulers, dtype='float32')\n",
    "# data = TUM(15000, r, t)\n",
    "# r_icp, t_icp = test(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.999362   -0.01426313 -0.03274392]\n",
      " [ 0.01678179  0.9968136   0.07798077]\n",
      " [ 0.03152734 -0.07848052  0.996417  ]]\n",
      "[ 0.2539836  -0.06697565  0.05225628]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "614c6f978ef44b90abce3a95082d67e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb09f9d656dc43409307d0e84deb7ee5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3096e302bf6545bdb94c2e210e2ffd2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "valDataset = SceneNet(20000, \"val\", icp=True, r=r, t=t, filter=True)\n",
    "src, target, rotation_ab, translation_ab, rotation_ba, translation_ba, euler_ab, euler_ba = valDataset[42]\n",
    "print(rotation_ab)\n",
    "print(translation_ab)\n",
    "# print(points1.shape)\n",
    "transformed_src = transform_point_cloud(torch.tensor(src).double(), torch.tensor(r_icp[0]).unsqueeze(0).double(), torch.tensor(t_icp[0]).unsqueeze(0).double()).T\n",
    "transformed_src2 = transform_point_cloud(torch.tensor(src), torch.tensor(rotation_ab).unsqueeze(0), torch.tensor(translation_ab).unsqueeze(0)).T\n",
    "# transformed_src1 = transform_point_cloud(torch.tensor(src), r1, t1).T\n",
    "# visualize_pointcloud(target.T, .03, transformed_src1)\n",
    "visualize_pointcloud(target.T, .03, transformed_src)\n",
    "visualize_pointcloud(target.T, .03, transformed_src2)\n",
    "visualize_pointcloud(target.T, .03, src.T)\n",
    "\n",
    "export_pointcloud_to_obj('71_icp_filter.obj', target.T, np.array(transformed_src))\n",
    "# export_pointcloud_to_obj('24_icp.obj', target.T, np.array(transformed_src))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Export to disk\"\"\"\n",
    "\n",
    "\n",
    "def export_mesh_to_obj(path, vertices, faces, vertices2):\n",
    "    \"\"\"\n",
    "    exports mesh as OBJ\n",
    "    :param path: output path for the OBJ file\n",
    "    :param vertices: Nx3 vertices\n",
    "    :param faces: Mx3 faces\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    # write vertices starting with \"v \"\n",
    "    # write faces starting with \"f \"\n",
    "\n",
    "    # ###############\n",
    "    # DONE: Implement\n",
    "    v = \"\"\n",
    "    f = \"\"\n",
    "    v2 = \"\"\n",
    "    file = open(path, 'w+')\n",
    "\n",
    "    if vertices is not None:\n",
    "        for vertice in vertices:\n",
    "            v = v + \"v \"\n",
    "            for i in vertice:\n",
    "                v = v + str(i) + \" \"\n",
    "            v = v + \"0.098039 0.8117647 0.\\n\"\n",
    "            # v = v + \"\\n\"\n",
    "        \n",
    "    count = 1\n",
    "    if faces is not None:\n",
    "        for face in faces:\n",
    "            f = f + \"f \"\n",
    "            for i in face:\n",
    "                f = f + str(i+1) + \" \"\n",
    "            f = f + \"\\n\"\n",
    "\n",
    "    if vertices2 is not None:\n",
    "        for vertice2 in vertices2:\n",
    "            v2 = v2 + \"v \"\n",
    "            for i in vertice2:\n",
    "                v2 = v2 + str(i) + \" \"\n",
    "            v2 = v2 + \"0.717647 0.717647 0.717647\\n\"  \n",
    "            # v2 = v2 + \"\\n\"    \n",
    "    file.write(v)\n",
    "    file.write(v2)\n",
    "    file.write(f)\n",
    "    file.close()\n",
    "        \n",
    "    # ###############\n",
    "\n",
    "\n",
    "def export_pointcloud_to_obj(path, pointcloud, pointcloud2=None):\n",
    "    \"\"\"\n",
    "    export pointcloud as OBJ\n",
    "    :param path: output path for the OBJ file\n",
    "    :param pointcloud: Nx3 points\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    # ###############\n",
    "    # DONE: Implement\n",
    "    export_mesh_to_obj(path, pointcloud, None, pointcloud2)\n",
    "    # ###############\n",
    "\n",
    "# print(rigid_body_transformation_params)\n",
    "# valDataset = SceneNet(10000, \"val\", icp=True, r=r, t=t)\n",
    "# for i in range(len(valDataset)):\n",
    "#     src, target, rotation_ab, translation_ab, rotation_ba, translation_ba, euler_ab, euler_ba = valDataset[i]\n",
    "#     transformed_src = transform_point_cloud(torch.tensor(src).double(), torch.tensor(r_icp[i]).unsqueeze(0).double(), torch.tensor(t_icp[i]).unsqueeze(0).double()).T\n",
    "#     export_pointcloud_to_obj('56_'+str(i)+'.obj', target.T, np.array(transformed_src))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('python39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "beda123ca6d46414026d3c59f732de1f5fb19d6ba2f32753cc4223591eed0a9d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
